<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Sean&#39;s Blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.seanjiang.cn/"/>
  <updated>2019-03-07T01:16:54.000Z</updated>
  <id>https://www.seanjiang.cn/</id>
  
  <author>
    <name>sean</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>ambaria安装HDP</title>
    <link href="https://www.seanjiang.cn/ambaria%E5%AE%89%E8%A3%85HDP.html"/>
    <id>https://www.seanjiang.cn/ambaria安装HDP.html</id>
    <published>2019-03-07T01:13:50.000Z</published>
    <updated>2019-03-07T01:16:54.000Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;Hadoop的生态非常的庞大，如果要对其一一搭建，并配置好相应的配置文件，需要耗费很大的精力和时间。利用Ambari + HDP能帮助我们快速搭建Hadoop平台，同时Ambari提供了监控集群的功能，能在其上面方便的添加Hadoop生态的组件以及相关的分布式框架，如spark,kafka等等。&lt;/p&gt;
    
    </summary>
    
      <category term="Hadoop" scheme="https://www.seanjiang.cn/categories/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="https://www.seanjiang.cn/tags/Hadoop/"/>
    
      <category term="Ambari" scheme="https://www.seanjiang.cn/tags/Ambari/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop的搭建</title>
    <link href="https://www.seanjiang.cn/Hadoop%E7%9A%84%E6%90%AD%E5%BB%BA.html"/>
    <id>https://www.seanjiang.cn/Hadoop的搭建.html</id>
    <published>2019-02-25T14:11:00.000Z</published>
    <updated>2019-02-25T14:24:30.000Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;Hadoop的搭建此次分为伪分布式和分布式，伪分布式分为windows和mac Os、Linux&lt;/p&gt;
&lt;h2 id=&quot;伪分布式&quot;&gt;&lt;a href=&quot;#伪分布式&quot; class=&quot;headerlink&quot; title=&quot;伪分布式&quot;&gt;&lt;/a&gt;伪分布式&lt;/h2&gt;&lt;p&gt;Hadoop的伪分布式搭建需要提前安装好jdk1.8，选用hadoop3.0.0版本，官方提供的二进制和源码下载网址：&lt;a href=&quot;https://archive.apache.org/dist/hadoop/common/hadoop-3.0.0/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://archive.apache.org/dist/hadoop/common/hadoop-3.0.0/&lt;/a&gt; ，此次的搭建使用二进制包安装，不涉及源码的编译，所以下载的文件为hadoop-3.0.0.tar.gz。&lt;/p&gt;
&lt;h3 id=&quot;Windows&quot;&gt;&lt;a href=&quot;#Windows&quot; class=&quot;headerlink&quot; title=&quot;Windows&quot;&gt;&lt;/a&gt;Windows&lt;/h3&gt;&lt;p&gt;首先将下载好hadoop-3.0.0.tar.gz压缩包，解压到合适的目录下（目录位置用于配置环境变量，用户可以自行选择），为了接下来方便配置的讲解，假设本次例子解压目录为：E:\hadoop-3.0.0，后文的hadoop的xx目录都是该目录下的子目录。&lt;/p&gt;
    
    </summary>
    
      <category term="Hadoop" scheme="https://www.seanjiang.cn/categories/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="https://www.seanjiang.cn/tags/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title>InnoDB数据页结构及其与聚簇索引的关系</title>
    <link href="https://www.seanjiang.cn/InnoDB%E6%95%B0%E6%8D%AE%E9%A1%B5%E7%BB%93%E6%9E%84%E5%8F%8A%E5%85%B6%E4%B8%8E%E8%81%9A%E7%B0%87%E7%B4%A2%E5%BC%95%E7%9A%84%E5%85%B3%E7%B3%BB.html"/>
    <id>https://www.seanjiang.cn/InnoDB数据页结构及其与聚簇索引的关系.html</id>
    <published>2018-12-24T04:35:57.000Z</published>
    <updated>2018-12-24T04:39:30.000Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;表空间&quot;&gt;&lt;a href=&quot;#表空间&quot; class=&quot;headerlink&quot; title=&quot;表空间&quot;&gt;&lt;/a&gt;表空间&lt;/h2&gt;&lt;p&gt;InnoDB中数据都存放在一个空间中，就是表空间。在文件系统中就是idb文件，每个idb文件都是一个表空间。它们之间通过表空间id来区分，在默认情况下，InnoDB使用的是共享表空间，所有数据存放在一个共享表空间ibdata1中。共享表空间可以通过参数&lt;code&gt;innodb_data_file_path&lt;/code&gt;进行配置。&lt;/p&gt;
&lt;p&gt;可以同时配置多个文件组成一个共享表空间，如&lt;/p&gt;
&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;innodb_data_file_path=/data/ibdata1:2000M;/data/ibdata2:2000M:autoextend&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;这里配置了/data/ibdata1和/data/ibdata2两个文件组成表空间，如果两个文件在不同磁盘上，能降低各个磁盘的负载，可以提高数据库的性能。同时，两个文件名后跟了存储大小，表示文件的最大存放空间，而autoextend表示/data/ibdata2若用完了2000M，文件可以自动增长。&lt;/p&gt;
    
    </summary>
    
      <category term="Mysql" scheme="https://www.seanjiang.cn/categories/Mysql/"/>
    
    
      <category term="数据页" scheme="https://www.seanjiang.cn/tags/%E6%95%B0%E6%8D%AE%E9%A1%B5/"/>
    
      <category term="聚簇索引" scheme="https://www.seanjiang.cn/tags/%E8%81%9A%E7%B0%87%E7%B4%A2%E5%BC%95/"/>
    
  </entry>
  
  <entry>
    <title>布隆过滤器-Bloom Filter</title>
    <link href="https://www.seanjiang.cn/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8-Bloom-Filter.html"/>
    <id>https://www.seanjiang.cn/布隆过滤器-Bloom-Filter.html</id>
    <published>2018-12-18T15:06:16.000Z</published>
    <updated>2018-12-18T15:10:42.000Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;​    Bloom Filter是由 Burton Howard Bloom在1970提出的，用来判断一个元素是否存在集合中的概率算法。经过Bloom Filter判断过不在集合中的元素就一定不在集合中，若判断结果是在集合中，则可能会误判，即该元素可能不在集合中。换句话说，可能会误判，但绝不可能漏判。元素可以添加到集合中，但不会被删除（尽管可以通过“计数”过滤器来解决）; 添加到集合中的元素越多，误判的概率就越大。Bloom Filter将元素映射到位数组中，所以极大的节省空间。&lt;/p&gt;
    
    </summary>
    
      <category term="算法" scheme="https://www.seanjiang.cn/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="Bloom Filter" scheme="https://www.seanjiang.cn/tags/Bloom-Filter/"/>
    
  </entry>
  
  <entry>
    <title>超平面</title>
    <link href="https://www.seanjiang.cn/%E8%B6%85%E5%B9%B3%E9%9D%A2.html"/>
    <id>https://www.seanjiang.cn/超平面.html</id>
    <published>2018-12-10T13:35:24.000Z</published>
    <updated>2018-12-10T15:58:30.000Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;什么是超平面&quot;&gt;&lt;a href=&quot;#什么是超平面&quot; class=&quot;headerlink&quot; title=&quot;什么是超平面&quot;&gt;&lt;/a&gt;什么是超平面&lt;/h2&gt;&lt;h3 id=&quot;数学中的超平面&quot;&gt;&lt;a href=&quot;#数学中的超平面&quot; class=&quot;headerlink&quot; title=&quot;数学中的超平面&quot;&gt;&lt;/a&gt;数学中的超平面&lt;/h3&gt;&lt;p&gt;&lt;em&gt;以下内容均来自：&lt;a href=&quot;https://www.cnblogs.com/dengdan890730/p/5554787.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.cnblogs.com/dengdan890730/p/5554787.html&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;在&lt;a href=&quot;https://zh.wikipedia.org/wiki/%E6%95%B8%E5%AD%B8&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;数学&lt;/a&gt;中，&lt;strong&gt;超平面（Hyperplane）&lt;/strong&gt;是n维欧氏空间中余维度等于1的线性子空间。这是平面中的直线、空间中的平面之推广.&lt;/p&gt;
&lt;p&gt;$n$维超平面的方程定义为：&lt;/p&gt;
&lt;p&gt;​                    $a_1x_1+…+a_nx_n=b$，其中$a_1,…,a_n$是不全为0的常熟&lt;/p&gt;
&lt;p&gt;​                                    即$w^Tx+b=0，$&lt;/p&gt;
    
    </summary>
    
      <category term="算法" scheme="https://www.seanjiang.cn/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="超平面" scheme="https://www.seanjiang.cn/tags/%E8%B6%85%E5%B9%B3%E9%9D%A2/"/>
    
  </entry>
  
  <entry>
    <title>HBase客户端的写缓存BufferedMutator</title>
    <link href="https://www.seanjiang.cn/HBase%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%9A%84%E5%86%99%E7%BC%93%E5%AD%98BufferedMutator.html"/>
    <id>https://www.seanjiang.cn/HBase客户端的写缓存BufferedMutator.html</id>
    <published>2018-11-28T14:35:16.000Z</published>
    <updated>2018-11-28T14:37:20.000Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;客户端的写缓存&quot;&gt;&lt;a href=&quot;#客户端的写缓存&quot; class=&quot;headerlink&quot; title=&quot;客户端的写缓存&quot;&gt;&lt;/a&gt;客户端的写缓存&lt;/h2&gt;&lt;p&gt;HBase的每一个put操作实际上是一个RPC操作，将客户端的数据传输到服务器再返回结果，这只适用于小数据量的操作，如果数据量多的话，每次put都需要建立一次RPC的连接（TCP连接），而建立连接传输数据是需要时间的，因此减少RPC的调用可以提高数据传输的效率，减少建立连接的时间和IO消耗。&lt;/p&gt;
&lt;p&gt;HBase的客户端API提供了写缓存区，put的数据一开始放在缓存区内，当数量到达指定的容量或者用户强制提交是才将数据一次性提交到HBase的服务器。这个缓冲区可以通过调用 &lt;code&gt;HTable.setAutoFlush(false)&lt;/code&gt; 来开启。而新版HBbase的API中使用了BufferedMutator替换了老版的缓冲区，通过BufferedMutator对象提交的数据自动存放在缓冲区中。&lt;/p&gt;
    
    </summary>
    
      <category term="HBase" scheme="https://www.seanjiang.cn/categories/HBase/"/>
    
    
      <category term="BufferedMutator" scheme="https://www.seanjiang.cn/tags/BufferedMutator/"/>
    
  </entry>
  
  <entry>
    <title>HBase 简介</title>
    <link href="https://www.seanjiang.cn/HBase%20%E7%AE%80%E4%BB%8B.html"/>
    <id>https://www.seanjiang.cn/HBase 简介.html</id>
    <published>2018-11-28T14:33:25.000Z</published>
    <updated>2018-11-28T14:50:00.000Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;数据模型&quot;&gt;&lt;a href=&quot;#数据模型&quot; class=&quot;headerlink&quot; title=&quot;数据模型&quot;&gt;&lt;/a&gt;数据模型&lt;/h2&gt;&lt;p&gt;在Hbase中，数据同样是存储在表中，有行和列。但是hbase和关系型数据库（RDBMS）有很大的区别，hbase更像是多维度的map。&lt;/p&gt;
&lt;p&gt;hbase的同样有着表（table）, 行（row）,列（Column），根据表、行、列可以定位到一个单元格（cell）上,这样看来hbase和关系型数据库形式一样，其实不是的，hbase的列包括列簇（column family）和列限定符（column qualifier），一般将列限定符成为列，一行有固定的列簇（由表结构决定），一个列簇包含一系列的列，列没有固定的结构，每一行的列簇下的列可以不相同，列由添加数据决定，可以将hbase的表想象成一个Map&amp;lt;row, Map&amp;lt;column family,Map&lt;column qualifier,=&quot;&quot; value=&quot;&quot;&gt;&amp;gt;&amp;gt;,由行、列簇寻找一个key不固定的map。而且相同单元格会存储着不同的版本值，每一次存储新值会添加时间戳Timestamp，并不会覆盖掉上次值，一个hbase表默认能存储一个版本值，若第四次设置新增，则会把第一次的值覆盖掉。因此一个单元格的定位需要row,family,qualifier和timestamp来确定。&lt;/column&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="HBase" scheme="https://www.seanjiang.cn/categories/HBase/"/>
    
    
      <category term="HBase" scheme="https://www.seanjiang.cn/tags/HBase/"/>
    
  </entry>
  
  <entry>
    <title>简单集群时间同步</title>
    <link href="https://www.seanjiang.cn/%E7%AE%80%E5%8D%95%E9%9B%86%E7%BE%A4%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5.html"/>
    <id>https://www.seanjiang.cn/简单集群时间同步.html</id>
    <published>2018-11-22T14:25:05.000Z</published>
    <updated>2019-02-27T14:02:10.000Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;最近集群的Hbase的其中几个节点总是连接不上，最后发现是集群之间的系统时间不同步导致的(hbase的时间戳决定节点之间的时间必须同步)。决定使用的ntp来解决集群之间的系统时间同步问题。&lt;/p&gt;
&lt;h3 id=&quot;安装ntp&quot;&gt;&lt;a href=&quot;#安装ntp&quot; class=&quot;headerlink&quot; title=&quot;安装ntp&quot;&gt;&lt;/a&gt;安装ntp&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;yum install -y ntp&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&quot;ntp服务器配置&quot;&gt;&lt;a href=&quot;#ntp服务器配置&quot; class=&quot;headerlink&quot; title=&quot;ntp服务器配置&quot;&gt;&lt;/a&gt;ntp服务器配置&lt;/h3&gt;&lt;p&gt;集群之间的时间同步同样采用sever/client的方式，将其中一个节点做为ntp的服务器,其余作为客户端通过ntp服务来向ntp服务器同步时间。需要选定一台作为ntp server，修该ntp的配置文件。&lt;/p&gt;
    
    </summary>
    
      <category term="Linux" scheme="https://www.seanjiang.cn/categories/Linux/"/>
    
    
      <category term="ntp" scheme="https://www.seanjiang.cn/tags/ntp/"/>
    
      <category term="集群" scheme="https://www.seanjiang.cn/tags/%E9%9B%86%E7%BE%A4/"/>
    
  </entry>
  
  <entry>
    <title>MapReduce 多路径输出</title>
    <link href="https://www.seanjiang.cn/MapReduce-%E5%A4%9A%E8%B7%AF%E5%BE%84%E8%BE%93%E5%87%BA.html"/>
    <id>https://www.seanjiang.cn/MapReduce-多路径输出.html</id>
    <published>2018-11-20T14:28:51.000Z</published>
    <updated>2018-11-20T14:31:30.000Z</updated>
    
    <summary type="html">
    
      &lt;h3 id=&quot;mapreduce中实现多路径输出主要使用MulitipleOutputs类&quot;&gt;&lt;a href=&quot;#mapreduce中实现多路径输出主要使用MulitipleOutputs类&quot; class=&quot;headerlink&quot; title=&quot;mapreduce中实现多路径输出主要使用MulitipleOutputs类&quot;&gt;&lt;/a&gt;mapreduce中实现多路径输出主要使用MulitipleOutputs类&lt;/h3&gt;&lt;p&gt;通过两个例子可以掌握&lt;/p&gt;
&lt;h4 id=&quot;输入样例-mulitipleInput-txt&quot;&gt;&lt;a href=&quot;#输入样例-mulitipleInput-txt&quot; class=&quot;headerlink&quot; title=&quot;输入样例 mulitipleInput.txt&quot;&gt;&lt;/a&gt;输入样例 mulitipleInput.txt&lt;/h4&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;file1 001&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;file2 002&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;file3 003&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;file2 004&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;file1 005&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;file1 006&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;file3 007&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="Hadoop" scheme="https://www.seanjiang.cn/categories/Hadoop/"/>
    
    
  </entry>
  
  <entry>
    <title>Hadoop 小文件的处理</title>
    <link href="https://www.seanjiang.cn/Hadoop-%E5%B0%8F%E6%96%87%E4%BB%B6%E7%9A%84%E5%A4%84%E7%90%86.html"/>
    <id>https://www.seanjiang.cn/Hadoop-小文件的处理.html</id>
    <published>2018-11-20T14:25:05.000Z</published>
    <updated>2018-11-20T14:27:20.000Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;hadoop的HDFS和MapReduce本身都是用户处理大量数据的大文件，对于小文件来说，由于namenode会在记录每个block对象，如果存在大量的小文件，会占用namenode的大量内存空间，而且HDFS存储文件是按block来存储，即使一个文件的大小不足一个block的大小，文件还是会占用一个block的存储空间，所以大量的小文件会对HDFS的存储和访问都带来不利的影响。&lt;br&gt;  hadoop对于小文件的处理主要有Hadoop Archive，Sequence file和CombineFileInputFormat三种方式。&lt;/p&gt;
    
    </summary>
    
      <category term="Hadoop" scheme="https://www.seanjiang.cn/categories/Hadoop/"/>
    
    
  </entry>
  
  <entry>
    <title>mapreduce 排序</title>
    <link href="https://www.seanjiang.cn/mapreduce-%E6%8E%92%E5%BA%8F.html"/>
    <id>https://www.seanjiang.cn/mapreduce-排序.html</id>
    <published>2018-11-20T14:23:16.000Z</published>
    <updated>2018-11-20T14:27:24.000Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;mapreduce的排序主要分部分排序、全排序和辅助排序（二次排序） 可以直接在reduce中在对数据进行排序，但是这对于reduce的负担太重，数据处理的时间消耗也会大大增加&lt;/p&gt;
&lt;p&gt;mapreduce机制中排序只会针对键进行排序，所以如果想对某个数据进行排序，一定要将其设置为map输出的键，排序主要发生在map的spill和合并spill file阶段和reduce拉取复制map端的数据后合并成reduce文件时。&lt;/p&gt;
    
    </summary>
    
      <category term="Hadoop" scheme="https://www.seanjiang.cn/categories/Hadoop/"/>
    
    
      <category term="MapReduce" scheme="https://www.seanjiang.cn/tags/MapReduce/"/>
    
      <category term="排序" scheme="https://www.seanjiang.cn/tags/%E6%8E%92%E5%BA%8F/"/>
    
  </entry>
  
  <entry>
    <title>HDFS扩容</title>
    <link href="https://www.seanjiang.cn/hdfd%E6%89%A9%E5%AE%B9.html"/>
    <id>https://www.seanjiang.cn/hdfd扩容.html</id>
    <published>2018-11-20T14:21:21.000Z</published>
    <updated>2018-11-23T14:33:20.000Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;hdfs的存储容量不足，需要放入新磁盘扩容&lt;br&gt;扩容有两种方式，一种是linux层面的，一种是hdfs层面的&lt;br&gt;hdfs的datanode存储的目录可以查看hdfs-site.xml的dfs.datanode.data.dir的值&lt;/p&gt;
    
    </summary>
    
      <category term="Hadoop" scheme="https://www.seanjiang.cn/categories/Hadoop/"/>
    
    
      <category term="HDFS" scheme="https://www.seanjiang.cn/tags/HDFS/"/>
    
  </entry>
  
  <entry>
    <title>非整数0-1背包问题</title>
    <link href="https://www.seanjiang.cn/%E9%9D%9E%E6%95%B4%E6%95%B00-1%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98.html"/>
    <id>https://www.seanjiang.cn/非整数0-1背包问题.html</id>
    <published>2018-11-20T14:12:40.000Z</published>
    <updated>2018-11-28T14:48:38.000Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;0-1背包问题通常情况下物品的重量是整数的，采用动态规划可以解决，在解决物品重量非整数情况下的背包问题之前，我们先来回顾整数背包问题，并从中寻找解决非整数背包问题的方法。&lt;/p&gt;
&lt;p&gt;问题定义：有n种物品和一个容量为$c$的背包，第$i$件物品的重量为$wi$，价格为$vi$,求出哪种物品组合放入背包使物品价值总和最大。&lt;/p&gt;
&lt;h2 id=&quot;整数0-1背包问题&quot;&gt;&lt;a href=&quot;#整数0-1背包问题&quot; class=&quot;headerlink&quot; title=&quot;整数0-1背包问题&quot;&gt;&lt;/a&gt;整数0-1背包问题&lt;/h2&gt;&lt;p&gt;设$p(i,j)$表示在容量为j情况下，将物品$i，i+1…n$组合的放入背包的最优解的值&lt;/p&gt;
&lt;p&gt;则其转移方程为&lt;/p&gt;
&lt;p&gt;如果 $j&amp;gt;=w_i$ ，$p(i,j) = max(p(i+1,j), p(i+1,j-w_i )+v_i )$&lt;/p&gt;
&lt;p&gt;如果 $j&amp;lt;w_i$ , $p(i,j) = p(i+1,j)$&lt;/p&gt;
    
    </summary>
    
      <category term="算法" scheme="https://www.seanjiang.cn/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="背包问题" scheme="https://www.seanjiang.cn/tags/%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop的RPC分析</title>
    <link href="https://www.seanjiang.cn/Hadoop%E7%9A%84RPC%E5%88%86%E6%9E%90.html"/>
    <id>https://www.seanjiang.cn/Hadoop的RPC分析.html</id>
    <published>2018-11-20T12:57:52.000Z</published>
    <updated>2019-02-25T14:11:42.000Z</updated>
    
    <summary type="html">
    
      &lt;h3 id=&quot;RPC&quot;&gt;&lt;a href=&quot;#RPC&quot; class=&quot;headerlink&quot; title=&quot;RPC&quot;&gt;&lt;/a&gt;RPC&lt;/h3&gt;&lt;p&gt;RPC就是远程过程调用,具体什么是RPC，看一个例子就会明白。&lt;br&gt;比如客户端有一个RPC协议类Protocol。&lt;/p&gt;
&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;interfce Protocol&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; a, &lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; b)&lt;/span&gt;&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;但是客户端没有其实现的具体类，该类在服务端&lt;br&gt;&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;Class ProtocolImpl implenets Protocol&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; a, &lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; b)&lt;/span&gt;&lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; a + b;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;则客户端需要调用ProtocolImpl的add方法，需要将调用的方法及其参数等信息发送给服务端，服务端解析信息，调用ProtocolImpl的add方法，将结果在传输给客户端，而RPC的目的就是使客户端仿佛在调用自身的方法来得到该方法的结果。&lt;br&gt;在这其中，Protocol就是一个RPC的协议，这个协议其实就是一个接口类，接口中的方法就是对外提供的远程调用方法。&lt;/p&gt;
    
    </summary>
    
      <category term="Hadoop" scheme="https://www.seanjiang.cn/categories/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="https://www.seanjiang.cn/tags/Hadoop/"/>
    
      <category term="RPC" scheme="https://www.seanjiang.cn/tags/RPC/"/>
    
  </entry>
  
  <entry>
    <title>字符串编辑距离</title>
    <link href="https://www.seanjiang.cn/%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%BC%96%E8%BE%91%E8%B7%9D%E7%A6%BB.html"/>
    <id>https://www.seanjiang.cn/字符串编辑距离.html</id>
    <published>2018-11-19T16:15:16.000Z</published>
    <updated>2018-11-20T15:19:40.000Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;编辑距离（Edit Distance），这里指的是Levenshtein距离，也就是字符串S1通过插入、修改、删除三种操作最少能变换成字符串S2的次数。接下来介绍利用动态规划来求解字符串的编辑距离。&lt;/p&gt;
&lt;p&gt;定义：$s_1$和$s_2$表示两字符串，$dist(i, j)$表示字符串$s_1$的前$i$个字符串和$s_2$的前$j$个字符串的编辑距离，$s_1(i)$和$s_2(j)$分别表示$s1$的第$i$个字符和$s2$的第$j$字符。&lt;/p&gt;
    
    </summary>
    
      <category term="算法" scheme="https://www.seanjiang.cn/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="字符串" scheme="https://www.seanjiang.cn/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"/>
    
      <category term="动态规划" scheme="https://www.seanjiang.cn/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
  </entry>
  
</feed>
