<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Sean&#39;s Blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.seanjiang.cn/"/>
  <updated>2019-07-29T09:31:14.428Z</updated>
  <id>https://www.seanjiang.cn/</id>
  
  <author>
    <name>sean</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>分布式一致性协议介绍</title>
    <link href="https://www.seanjiang.cn/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E5%8D%8F%E8%AE%AE%E4%BB%8B%E7%BB%8D.html"/>
    <id>https://www.seanjiang.cn/分布式一致性协议介绍.html</id>
    <published>2019-07-29T09:25:05.000Z</published>
    <updated>2019-07-29T09:31:14.428Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;一致性&quot;&gt;&lt;a href=&quot;#一致性&quot; class=&quot;headerlink&quot; title=&quot;一致性&quot;&gt;&lt;/a&gt;一致性&lt;/h2&gt;&lt;p&gt;分布式存储系统通常通过维护多个副本来进行容错，提高系统的可用性。但是分布式存储存在一个问题，如何保证相同时刻存储的数据是一样的，这就是一致性。它是构建具有容错性的分布式系统的基础，一致性保证每个结点存储的数据是一致的，这样即使部分结点宕机也能取得正确的副本数据。目前的一致性一致性协议通常基于replicated state machines，各个节点从一个相同初始化state出发，经过同样的操作序列(log)，最后到达相同的state&lt;/p&gt;
    
    </summary>
    
      <category term="算法" scheme="https://www.seanjiang.cn/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="分布式" scheme="https://www.seanjiang.cn/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="一致性" scheme="https://www.seanjiang.cn/tags/%E4%B8%80%E8%87%B4%E6%80%A7/"/>
    
  </entry>
  
  <entry>
    <title>java线程池</title>
    <link href="https://www.seanjiang.cn/java%E7%BA%BF%E7%A8%8B%E6%B1%A0.html"/>
    <id>https://www.seanjiang.cn/java线程池.html</id>
    <published>2019-04-10T13:05:02.000Z</published>
    <updated>2019-04-10T12:09:11.000Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;线程池是多并发编程中经常用到，了解是线程池的使用和原理是java程序员的必修课。编写多线程的程序推荐使用线程池而不是自己创建线程，因为线程池中的线程可以复用，复用线程可以降低线程创建和销毁的资源消耗，线程池帮助管理、调度、监控线程，可以防止无限制的创建线程，消耗完系统资源&lt;/p&gt;
&lt;h2 id=&quot;简单使用&quot;&gt;&lt;a href=&quot;#简单使用&quot; class=&quot;headerlink&quot; title=&quot;简单使用&quot;&gt;&lt;/a&gt;简单使用&lt;/h2&gt;&lt;p&gt;几种常用的线程池：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;newCachedThreadPool，可缓存的线程池，线程池容量几乎为无限(Interger. MAX_VALUE)，当一个新线程任务提交，如果线程池没有空闲的线程，则创建一个新线程执行，否则使用空闲线程。&lt;/li&gt;
&lt;li&gt;newFixedThreadPool，定长的线程池，线程池维持定长的线程，即使没有任务运行也不会关闭线程，当新任务提交，线程池中线程都在执行，则将任务放入阻塞队列中排队等待空闲线程运行。&lt;/li&gt;
&lt;li&gt;newScheduledThreadPool，定长的线程池，支持定时及周期性执行任务，newFixedThreadPool的特殊化，线程池容量为1&lt;/li&gt;
&lt;li&gt;newSingleThreadExecutor，线程池只有一个线程，所有任务按照提交的先后顺序执行&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="Java" scheme="https://www.seanjiang.cn/categories/Java/"/>
    
    
  </entry>
  
  <entry>
    <title>ReentrantLock</title>
    <link href="https://www.seanjiang.cn/ReentrantLock.html"/>
    <id>https://www.seanjiang.cn/ReentrantLock.html</id>
    <published>2019-04-10T12:09:25.000Z</published>
    <updated>2019-04-10T12:20:50.940Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;了解了java的队列式同步器AQS的基本实现，接下来可以看看java中频繁使用的可重入锁ReentrantLock。ReentrantLock是基于AQS实现的，内部类Sync继承了AQS，提供了公平锁和非公平锁。同synchronized相比，ReentrantLock是代码实现的锁，而synchronized是虚拟机上实现的锁，都是可重入的排他锁，即一个线程占有锁，其他线程必须等待锁的释放，同一个线程多次进入已将占有的锁，在效率方面，之前是ReentrantLock 效率更高，但后来java对synchronized进行了优化，效率目前来说差不多，ReentrantLock使用起来比synchronized更加灵活，synchronized使用来说更加方便，不用担心加锁释放锁的代码。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>java同步器-AQS</title>
    <link href="https://www.seanjiang.cn/java%E5%90%8C%E6%AD%A5%E5%99%A8-AQS.html"/>
    <id>https://www.seanjiang.cn/java同步器-AQS.html</id>
    <published>2019-03-15T14:09:29.000Z</published>
    <updated>2019-03-15T14:11:33.410Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;AQS，即AbstractQueuedSynchronized，抽象的队列式同步器，它是一个用于构建锁和同步器的基础框架，java中很多锁和同步器的实现都依赖AQS,比如ReentrantLock、 ReadWriteLock、Semaphore、CountDownLatch等。然而这些锁都没有直接来继承AQS,而是定义了一个Sync类去继承AQS.因为锁面向的是使用用户,而同步器面向的则是线程控制,那么在锁的实现中聚合同步器而不是直接继承AQS就可以很好的隔离二者所关注的事情.&lt;/p&gt;
&lt;p&gt;AQS的实现是基于CLH队列，CLH队列的提出是用于自旋锁，但在AQS中，JUC并发包的作者（Doug Lea）将其用于阻塞锁。在了解AQS之前首先来看看CAS和CLH队列。&lt;/p&gt;
    
    </summary>
    
      <category term="Java" scheme="https://www.seanjiang.cn/categories/Java/"/>
    
    
  </entry>
  
  <entry>
    <title>红黑树-转载整理</title>
    <link href="https://www.seanjiang.cn/%E7%BA%A2%E9%BB%91%E6%A0%91-%E8%BD%AC%E8%BD%BD%E6%95%B4%E7%90%86.html"/>
    <id>https://www.seanjiang.cn/红黑树-转载整理.html</id>
    <published>2019-03-15T14:08:09.000Z</published>
    <updated>2019-03-15T14:11:42.800Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;红黑树是一种自平衡二叉查找树，其每个结点都有一个存储位来表示结点的颜色，RED或者BLACK。红黑树的实现结构复杂，但是在红黑树上的查找，增加和删除的时间复杂度都为O(logn)，因此红黑树的应用广泛，如Java的HashMap当冲突链表长度大于8时，转为红黑树；TreeMap使用红黑树结构等。&lt;/p&gt;
    
    </summary>
    
      <category term="算法" scheme="https://www.seanjiang.cn/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="红黑树" scheme="https://www.seanjiang.cn/tags/%E7%BA%A2%E9%BB%91%E6%A0%91/"/>
    
  </entry>
  
  <entry>
    <title>mapreduce过程-shuffle和sort</title>
    <link href="https://www.seanjiang.cn/mapreduce%E8%BF%87%E7%A8%8B-shuffle%E5%92%8Csort.html"/>
    <id>https://www.seanjiang.cn/mapreduce过程-shuffle和sort.html</id>
    <published>2019-03-07T13:47:42.000Z</published>
    <updated>2019-03-07T13:56:41.340Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;MapReduce作为Hadoop三大核心组件之一，是一种处理大数据的分布式运算框架。虽然当前优秀的分布式运算框架有很多，如spark,flink等，其有着MapReduce没有的流式处理模型，但是MapReduce在批量计算有着独有的优势，了解其内部的运行机制，对于大数据处理技术人员和学习人员都着重要的意义。&lt;/p&gt;
    
    </summary>
    
      <category term="Hadoop" scheme="https://www.seanjiang.cn/categories/Hadoop/"/>
    
    
  </entry>
  
  <entry>
    <title>关于动态规划的想法</title>
    <link href="https://www.seanjiang.cn/%E5%85%B3%E4%BA%8E%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E7%9A%84%E6%83%B3%E6%B3%95.html"/>
    <id>https://www.seanjiang.cn/关于动态规划的想法.html</id>
    <published>2019-03-07T01:38:01.000Z</published>
    <updated>2019-03-07T04:45:03.550Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;动态规划是经常用到的算法，一般是通过递推，将一个复杂的问题分解为简单的最小问题求解，即存在着最优子结构。从求解子问题一步步推出原始问题的解。我将目前遇到的动态规划的问题按照开辟数组的维度分为一维和二维两类，背包问题不属于这类，因为背包问题相关的问题也是通过动态规划，但是比较复杂，单独放在外面。以上是我个人对于遇到的动态规范的分类，纯属个人想法，还有树形动态规划，后续遇到会加入进去。&lt;/p&gt;
    
    </summary>
    
      <category term="算法" scheme="https://www.seanjiang.cn/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="动态规划" scheme="https://www.seanjiang.cn/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
  </entry>
  
  <entry>
    <title>读HashMap源码</title>
    <link href="https://www.seanjiang.cn/%E8%AF%BBHashMap%E6%BA%90%E7%A0%81.html"/>
    <id>https://www.seanjiang.cn/读HashMap源码.html</id>
    <published>2019-03-07T01:35:42.000Z</published>
    <updated>2019-03-14T07:10:54.090Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;HashMap是Java中常用的数据结构，是集合类中的重要存在，其中包含了散列表、链表和红黑树。散列表解决冲突的方法是链地址法，即将散列值相同的元素存放在一个链表中。当冲突过多，链表过长会造成查找效率降低，因此java8中在HashMap中引入红黑树进行优化，当某个散列值下的链表长度过长（长度大于8），会将其转变为红黑树存储，优化查询。涉及到红黑树的操作不会再这里细讲&lt;/p&gt;
    
    </summary>
    
      <category term="Java" scheme="https://www.seanjiang.cn/categories/Java/"/>
    
    
  </entry>
  
  <entry>
    <title>ambaria安装HDP</title>
    <link href="https://www.seanjiang.cn/ambaria%E5%AE%89%E8%A3%85HDP.html"/>
    <id>https://www.seanjiang.cn/ambaria安装HDP.html</id>
    <published>2019-03-07T01:13:50.000Z</published>
    <updated>2019-03-07T01:16:54.000Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;Hadoop的生态非常的庞大，如果要对其一一搭建，并配置好相应的配置文件，需要耗费很大的精力和时间。利用Ambari + HDP能帮助我们快速搭建Hadoop平台，同时Ambari提供了监控集群的功能，能在其上面方便的添加Hadoop生态的组件以及相关的分布式框架，如spark,kafka等等。&lt;/p&gt;
    
    </summary>
    
      <category term="Hadoop" scheme="https://www.seanjiang.cn/categories/Hadoop/"/>
    
    
      <category term="Ambari" scheme="https://www.seanjiang.cn/tags/Ambari/"/>
    
      <category term="Hadoop" scheme="https://www.seanjiang.cn/tags/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop的搭建</title>
    <link href="https://www.seanjiang.cn/Hadoop%E7%9A%84%E6%90%AD%E5%BB%BA.html"/>
    <id>https://www.seanjiang.cn/Hadoop的搭建.html</id>
    <published>2019-02-25T14:11:00.000Z</published>
    <updated>2019-02-25T14:24:30.000Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;Hadoop的搭建此次分为伪分布式和分布式，伪分布式分为windows和mac Os、Linux&lt;/p&gt;
&lt;h2 id=&quot;伪分布式&quot;&gt;&lt;a href=&quot;#伪分布式&quot; class=&quot;headerlink&quot; title=&quot;伪分布式&quot;&gt;&lt;/a&gt;伪分布式&lt;/h2&gt;&lt;p&gt;Hadoop的伪分布式搭建需要提前安装好jdk1.8，选用hadoop3.0.0版本，官方提供的二进制和源码下载网址：&lt;a href=&quot;https://archive.apache.org/dist/hadoop/common/hadoop-3.0.0/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://archive.apache.org/dist/hadoop/common/hadoop-3.0.0/&lt;/a&gt; ，此次的搭建使用二进制包安装，不涉及源码的编译，所以下载的文件为hadoop-3.0.0.tar.gz。&lt;/p&gt;
&lt;h3 id=&quot;Windows&quot;&gt;&lt;a href=&quot;#Windows&quot; class=&quot;headerlink&quot; title=&quot;Windows&quot;&gt;&lt;/a&gt;Windows&lt;/h3&gt;&lt;p&gt;首先将下载好hadoop-3.0.0.tar.gz压缩包，解压到合适的目录下（目录位置用于配置环境变量，用户可以自行选择），为了接下来方便配置的讲解，假设本次例子解压目录为：E:\hadoop-3.0.0，后文的hadoop的xx目录都是该目录下的子目录。&lt;/p&gt;
    
    </summary>
    
      <category term="Hadoop" scheme="https://www.seanjiang.cn/categories/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="https://www.seanjiang.cn/tags/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title>InnoDB数据页结构及其与聚簇索引的关系</title>
    <link href="https://www.seanjiang.cn/InnoDB%E6%95%B0%E6%8D%AE%E9%A1%B5%E7%BB%93%E6%9E%84%E5%8F%8A%E5%85%B6%E4%B8%8E%E8%81%9A%E7%B0%87%E7%B4%A2%E5%BC%95%E7%9A%84%E5%85%B3%E7%B3%BB.html"/>
    <id>https://www.seanjiang.cn/InnoDB数据页结构及其与聚簇索引的关系.html</id>
    <published>2018-12-24T04:35:57.000Z</published>
    <updated>2018-12-24T04:39:30.000Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;表空间&quot;&gt;&lt;a href=&quot;#表空间&quot; class=&quot;headerlink&quot; title=&quot;表空间&quot;&gt;&lt;/a&gt;表空间&lt;/h2&gt;&lt;p&gt;InnoDB中数据都存放在一个空间中，就是表空间。在文件系统中就是idb文件，每个idb文件都是一个表空间。它们之间通过表空间id来区分，在默认情况下，InnoDB使用的是共享表空间，所有数据存放在一个共享表空间ibdata1中。共享表空间可以通过参数&lt;code&gt;innodb_data_file_path&lt;/code&gt;进行配置。&lt;/p&gt;
&lt;p&gt;可以同时配置多个文件组成一个共享表空间，如&lt;/p&gt;
&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;innodb_data_file_path=/data/ibdata1:2000M;/data/ibdata2:2000M:autoextend&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;这里配置了/data/ibdata1和/data/ibdata2两个文件组成表空间，如果两个文件在不同磁盘上，能降低各个磁盘的负载，可以提高数据库的性能。同时，两个文件名后跟了存储大小，表示文件的最大存放空间，而autoextend表示/data/ibdata2若用完了2000M，文件可以自动增长。&lt;/p&gt;
    
    </summary>
    
      <category term="Mysql" scheme="https://www.seanjiang.cn/categories/Mysql/"/>
    
    
      <category term="数据页" scheme="https://www.seanjiang.cn/tags/%E6%95%B0%E6%8D%AE%E9%A1%B5/"/>
    
      <category term="聚簇索引" scheme="https://www.seanjiang.cn/tags/%E8%81%9A%E7%B0%87%E7%B4%A2%E5%BC%95/"/>
    
  </entry>
  
  <entry>
    <title>布隆过滤器-Bloom Filter</title>
    <link href="https://www.seanjiang.cn/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8-Bloom-Filter.html"/>
    <id>https://www.seanjiang.cn/布隆过滤器-Bloom-Filter.html</id>
    <published>2018-12-18T15:06:16.000Z</published>
    <updated>2018-12-18T15:10:42.000Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;​    Bloom Filter是由 Burton Howard Bloom在1970提出的，用来判断一个元素是否存在集合中的概率算法。经过Bloom Filter判断过不在集合中的元素就一定不在集合中，若判断结果是在集合中，则可能会误判，即该元素可能不在集合中。换句话说，可能会误判，但绝不可能漏判。元素可以添加到集合中，但不会被删除（尽管可以通过“计数”过滤器来解决）; 添加到集合中的元素越多，误判的概率就越大。Bloom Filter将元素映射到位数组中，所以极大的节省空间。&lt;/p&gt;
    
    </summary>
    
      <category term="算法" scheme="https://www.seanjiang.cn/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="Bloom Filter" scheme="https://www.seanjiang.cn/tags/Bloom-Filter/"/>
    
  </entry>
  
  <entry>
    <title>超平面</title>
    <link href="https://www.seanjiang.cn/%E8%B6%85%E5%B9%B3%E9%9D%A2.html"/>
    <id>https://www.seanjiang.cn/超平面.html</id>
    <published>2018-12-10T13:35:24.000Z</published>
    <updated>2018-12-10T15:58:30.000Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;什么是超平面&quot;&gt;&lt;a href=&quot;#什么是超平面&quot; class=&quot;headerlink&quot; title=&quot;什么是超平面&quot;&gt;&lt;/a&gt;什么是超平面&lt;/h2&gt;&lt;h3 id=&quot;数学中的超平面&quot;&gt;&lt;a href=&quot;#数学中的超平面&quot; class=&quot;headerlink&quot; title=&quot;数学中的超平面&quot;&gt;&lt;/a&gt;数学中的超平面&lt;/h3&gt;&lt;p&gt;&lt;em&gt;以下内容均来自：&lt;a href=&quot;https://www.cnblogs.com/dengdan890730/p/5554787.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.cnblogs.com/dengdan890730/p/5554787.html&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;在&lt;a href=&quot;https://zh.wikipedia.org/wiki/%E6%95%B8%E5%AD%B8&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;数学&lt;/a&gt;中，&lt;strong&gt;超平面（Hyperplane）&lt;/strong&gt;是n维欧氏空间中余维度等于1的线性子空间。这是平面中的直线、空间中的平面之推广.&lt;/p&gt;
&lt;p&gt;$n$维超平面的方程定义为：&lt;/p&gt;
&lt;p&gt;​                    $a_1x_1+…+a_nx_n=b$，其中$a_1,…,a_n$是不全为0的常熟&lt;/p&gt;
&lt;p&gt;​                                    即$w^Tx+b=0，$&lt;/p&gt;
    
    </summary>
    
      <category term="算法" scheme="https://www.seanjiang.cn/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="超平面" scheme="https://www.seanjiang.cn/tags/%E8%B6%85%E5%B9%B3%E9%9D%A2/"/>
    
  </entry>
  
  <entry>
    <title>HBase客户端的写缓存BufferedMutator</title>
    <link href="https://www.seanjiang.cn/HBase%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%9A%84%E5%86%99%E7%BC%93%E5%AD%98BufferedMutator.html"/>
    <id>https://www.seanjiang.cn/HBase客户端的写缓存BufferedMutator.html</id>
    <published>2018-11-28T14:35:16.000Z</published>
    <updated>2018-11-28T14:37:20.000Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;客户端的写缓存&quot;&gt;&lt;a href=&quot;#客户端的写缓存&quot; class=&quot;headerlink&quot; title=&quot;客户端的写缓存&quot;&gt;&lt;/a&gt;客户端的写缓存&lt;/h2&gt;&lt;p&gt;HBase的每一个put操作实际上是一个RPC操作，将客户端的数据传输到服务器再返回结果，这只适用于小数据量的操作，如果数据量多的话，每次put都需要建立一次RPC的连接（TCP连接），而建立连接传输数据是需要时间的，因此减少RPC的调用可以提高数据传输的效率，减少建立连接的时间和IO消耗。&lt;/p&gt;
&lt;p&gt;HBase的客户端API提供了写缓存区，put的数据一开始放在缓存区内，当数量到达指定的容量或者用户强制提交是才将数据一次性提交到HBase的服务器。这个缓冲区可以通过调用 &lt;code&gt;HTable.setAutoFlush(false)&lt;/code&gt; 来开启。而新版HBbase的API中使用了BufferedMutator替换了老版的缓冲区，通过BufferedMutator对象提交的数据自动存放在缓冲区中。&lt;/p&gt;
    
    </summary>
    
      <category term="HBase" scheme="https://www.seanjiang.cn/categories/HBase/"/>
    
    
      <category term="BufferedMutator" scheme="https://www.seanjiang.cn/tags/BufferedMutator/"/>
    
  </entry>
  
  <entry>
    <title>HBase 简介</title>
    <link href="https://www.seanjiang.cn/HBase%20%E7%AE%80%E4%BB%8B.html"/>
    <id>https://www.seanjiang.cn/HBase 简介.html</id>
    <published>2018-11-28T14:33:25.000Z</published>
    <updated>2019-05-25T03:13:31.650Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;数据模型&quot;&gt;&lt;a href=&quot;#数据模型&quot; class=&quot;headerlink&quot; title=&quot;数据模型&quot;&gt;&lt;/a&gt;数据模型&lt;/h2&gt;&lt;p&gt;在Hbase中，数据同样是存储在表中，有行和列。但是hbase和关系型数据库（RDBMS）有很大的区别，hbase更像是多维度的map。&lt;/p&gt;
&lt;p&gt;hbase的同样有着表（table）, 行（row）,列（Column），根据表、行、列可以定位到一个单元格（cell）上,这样看来hbase和关系型数据库形式一样，其实不是的，hbase的列包括列簇（column family）和列限定符（column qualifier），一般将列限定符成为列，一行有固定的列簇（由表结构决定），一个列簇包含一系列的列，列没有固定的结构，每一行的列簇下的列可以不相同，列由添加数据决定，可以将hbase的表想象成一个Map&amp;lt;row, Map&amp;lt;column family,Map&lt;column qualifier,=&quot;&quot; value=&quot;&quot;&gt;&amp;gt;&amp;gt;,由行、列簇寻找一个key不固定的map。而且相同单元格会存储着不同的版本值，每一次存储新值会添加时间戳Timestamp，并不会覆盖掉上次值，一个hbase表默认能存储一个版本值，若第四次设置新增，则会把第一次的值覆盖掉。因此一个单元格的定位需要row,family,qualifier和timestamp来确定。&lt;/column&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="HBase" scheme="https://www.seanjiang.cn/categories/HBase/"/>
    
    
      <category term="HBase" scheme="https://www.seanjiang.cn/tags/HBase/"/>
    
  </entry>
  
  <entry>
    <title>简单集群时间同步</title>
    <link href="https://www.seanjiang.cn/%E7%AE%80%E5%8D%95%E9%9B%86%E7%BE%A4%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5.html"/>
    <id>https://www.seanjiang.cn/简单集群时间同步.html</id>
    <published>2018-11-22T14:25:05.000Z</published>
    <updated>2019-02-27T14:02:10.000Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;最近集群的Hbase的其中几个节点总是连接不上，最后发现是集群之间的系统时间不同步导致的(hbase的时间戳决定节点之间的时间必须同步)。决定使用的ntp来解决集群之间的系统时间同步问题。&lt;/p&gt;
&lt;h3 id=&quot;安装ntp&quot;&gt;&lt;a href=&quot;#安装ntp&quot; class=&quot;headerlink&quot; title=&quot;安装ntp&quot;&gt;&lt;/a&gt;安装ntp&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;yum install -y ntp&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&quot;ntp服务器配置&quot;&gt;&lt;a href=&quot;#ntp服务器配置&quot; class=&quot;headerlink&quot; title=&quot;ntp服务器配置&quot;&gt;&lt;/a&gt;ntp服务器配置&lt;/h3&gt;&lt;p&gt;集群之间的时间同步同样采用sever/client的方式，将其中一个节点做为ntp的服务器,其余作为客户端通过ntp服务来向ntp服务器同步时间。需要选定一台作为ntp server，修该ntp的配置文件。&lt;/p&gt;
    
    </summary>
    
      <category term="Linux" scheme="https://www.seanjiang.cn/categories/Linux/"/>
    
    
      <category term="ntp" scheme="https://www.seanjiang.cn/tags/ntp/"/>
    
      <category term="集群" scheme="https://www.seanjiang.cn/tags/%E9%9B%86%E7%BE%A4/"/>
    
  </entry>
  
  <entry>
    <title>MapReduce 多路径输出</title>
    <link href="https://www.seanjiang.cn/MapReduce-%E5%A4%9A%E8%B7%AF%E5%BE%84%E8%BE%93%E5%87%BA.html"/>
    <id>https://www.seanjiang.cn/MapReduce-多路径输出.html</id>
    <published>2018-11-20T14:28:51.000Z</published>
    <updated>2018-11-20T14:31:30.000Z</updated>
    
    <summary type="html">
    
      &lt;h3 id=&quot;mapreduce中实现多路径输出主要使用MulitipleOutputs类&quot;&gt;&lt;a href=&quot;#mapreduce中实现多路径输出主要使用MulitipleOutputs类&quot; class=&quot;headerlink&quot; title=&quot;mapreduce中实现多路径输出主要使用MulitipleOutputs类&quot;&gt;&lt;/a&gt;mapreduce中实现多路径输出主要使用MulitipleOutputs类&lt;/h3&gt;&lt;p&gt;通过两个例子可以掌握&lt;/p&gt;
&lt;h4 id=&quot;输入样例-mulitipleInput-txt&quot;&gt;&lt;a href=&quot;#输入样例-mulitipleInput-txt&quot; class=&quot;headerlink&quot; title=&quot;输入样例 mulitipleInput.txt&quot;&gt;&lt;/a&gt;输入样例 mulitipleInput.txt&lt;/h4&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;file1 001&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;file2 002&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;file3 003&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;file2 004&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;file1 005&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;file1 006&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;file3 007&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="Hadoop" scheme="https://www.seanjiang.cn/categories/Hadoop/"/>
    
    
  </entry>
  
  <entry>
    <title>Hadoop 小文件的处理</title>
    <link href="https://www.seanjiang.cn/Hadoop-%E5%B0%8F%E6%96%87%E4%BB%B6%E7%9A%84%E5%A4%84%E7%90%86.html"/>
    <id>https://www.seanjiang.cn/Hadoop-小文件的处理.html</id>
    <published>2018-11-20T14:25:05.000Z</published>
    <updated>2019-05-26T12:56:02.127Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;hadoop的HDFS和MapReduce本身都是用户处理大量数据的大文件，对于小文件来说，由于namenode会在记录每个block对象，如果存在大量的小文件，会占用namenode的大量内存空间，而且HDFS存储文件是按block来存储，即使一个文件的大小不足一个block的大小，文件还是会占用一个block的存储空间，所以大量的小文件会对HDFS的存储和访问都带来不利的影响。&lt;br&gt;  hadoop对于小文件的处理主要有Hadoop Archive，Sequence file和CombineFileInputFormat三种方式。&lt;/p&gt;
    
    </summary>
    
      <category term="Hadoop" scheme="https://www.seanjiang.cn/categories/Hadoop/"/>
    
    
  </entry>
  
  <entry>
    <title>mapreduce 排序</title>
    <link href="https://www.seanjiang.cn/mapreduce-%E6%8E%92%E5%BA%8F.html"/>
    <id>https://www.seanjiang.cn/mapreduce-排序.html</id>
    <published>2018-11-20T14:23:16.000Z</published>
    <updated>2018-11-20T14:27:24.000Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;mapreduce的排序主要分部分排序、全排序和辅助排序（二次排序） 可以直接在reduce中在对数据进行排序，但是这对于reduce的负担太重，数据处理的时间消耗也会大大增加&lt;/p&gt;
&lt;p&gt;mapreduce机制中排序只会针对键进行排序，所以如果想对某个数据进行排序，一定要将其设置为map输出的键，排序主要发生在map的spill和合并spill file阶段和reduce拉取复制map端的数据后合并成reduce文件时。&lt;/p&gt;
    
    </summary>
    
      <category term="Hadoop" scheme="https://www.seanjiang.cn/categories/Hadoop/"/>
    
    
      <category term="MapReduce" scheme="https://www.seanjiang.cn/tags/MapReduce/"/>
    
      <category term="排序" scheme="https://www.seanjiang.cn/tags/%E6%8E%92%E5%BA%8F/"/>
    
  </entry>
  
  <entry>
    <title>HDFS扩容</title>
    <link href="https://www.seanjiang.cn/hdfd%E6%89%A9%E5%AE%B9.html"/>
    <id>https://www.seanjiang.cn/hdfd扩容.html</id>
    <published>2018-11-20T14:21:21.000Z</published>
    <updated>2018-11-23T14:33:20.000Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;hdfs的存储容量不足，需要放入新磁盘扩容&lt;br&gt;扩容有两种方式，一种是linux层面的，一种是hdfs层面的&lt;br&gt;hdfs的datanode存储的目录可以查看hdfs-site.xml的dfs.datanode.data.dir的值&lt;/p&gt;
    
    </summary>
    
      <category term="Hadoop" scheme="https://www.seanjiang.cn/categories/Hadoop/"/>
    
    
      <category term="HDFS" scheme="https://www.seanjiang.cn/tags/HDFS/"/>
    
  </entry>
  
</feed>
