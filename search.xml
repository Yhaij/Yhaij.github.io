<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[MySQL锁算法]]></title>
    <url>%2FMySQL%E9%94%81%E7%AE%97%E6%B3%95.html</url>
    <content type="text"><![CDATA[锁的类型Mysql提供了两种标准的行级锁：共享锁和排他锁。 共享锁和排他锁可以理解成读锁和写锁，读写锁之间只有读锁和读锁之间不互斥，写锁和写锁，读锁和写锁之间都会互斥。 查看MySQL中的锁情况，可以通过库INFORMATION_SCHEMA中的INNODB_TRX、INNODB_LOCKS、INNODB_LOCK_WAITS表来查看具体锁情况。包括当前事务的状态，事务的ID，事务的sql，线程id，等待事务的锁id，事务开始时间，事务锁定的索引，事务锁定的行数量，数据锁定的页数量，事务锁定的主键值等 一致性非锁定读（快照读）在事务中简单的SELECT操作就是快照读，不包括SELECT…FOR UPDATE和SELECT…LOCK IN SHARE MODE方式，这两种会触触发当前读，下文会讲到 一致性非锁定读的实现是采用多版本并发控制MVCC (Multi Version Concurrency Control)来实现，其基本思想是对于不同的事务创建不同的快照，每个事务读取对应的快照，从而隔离事务之间对记录修改的影响。 MVCC方法作用于Read committed和Repeatable read这两种隔离级别上，在不同隔离级别上快照建立的时间不同。对于Read committed，每次select会创建一个快照，而对于Repeatable read是当事务中的第一个select时才会创建快照。 MVCC的具体实现innodb中聚簇索引包含了两个隐藏的值，trx_id和roll_pointer两个字段，trx_id记录了对记录进行修改的事务ID，每新建一个事务，该事务的trx_id会自增1。roll_pointer记录了修改之前的记录的指针，之前版本的记录会放进undo日志当中，roll_pointer指向的就是undo日志老版本记录的位置。 Read committed和Repeatable read在MVCC上使用的不同就是创建快照的时间不同，这里的快照记录了当前活动的事务的id，通过以下判断当前记录的trx_id和快照中的活动事务ID列表来决定读取的记录 要访问的记录trx_id比快照中的活动事务ID最小值都要小时，说明该记录在之前的事务已经提交了，可以访问 要访问的记录trx_id在照中的活动事务ID最小值和最大值之间，则需要判断trx_id是否在活动事务列表中，如果在则说明事务还未提交，无法访问，需要通过roll_pointer寻找上一条记录。如果不在，则说明事务已经提交，可以访问 要访问的记录trx_id比快照中的活动事务ID最大值都要大时，说明该记录是创建快照之后生成的，不能访问，需要通过roll_pointer寻找上一条记录。 不断通过trx_id和活动事务列表判断直到寻找到可以访问的记录。 一致性锁定读（当前读）当前读,读取的是最新的记录, 同时会对记录增加锁，阻塞其他事务修改记录。SELECT…FOR UPDATE和SELECT…LOCK IN SHARE MODE就是当前锁的操作，前一个会获得排他锁，后一个是共享锁。 SELECT…FOR UPDATE能够很好的解决丢失更新的问题，丢失更新的问题如下： 1、事务A查询一行数据，保存在本地进行修改，还未update 2、事务B查询相同的一行数据，保存在本地进行修改，还未update 3、事务A update本地修改好的数据并提交 3、事务B update本地修改好的数据并提交 这种情况理论是没有问题的，但是在逻辑上事务B会覆盖事务A的提交，事务A发生了丢失更新 事务A中执行SELECT…FOR UPDATE会获取排他锁，阻塞其余事务修改操作，这时事务Aupdate并提交才会释放锁，因此在事务A中是不会出现丢失更新的，其他事务在事务A不提交会阻塞在查询记录的sql上。 一致性锁定读是基于next-key lock实现的，next-key lock是包括Record Lock和gap Lock的，Record Lock是行锁，锁定具体一行记录，gap Lock是间隙锁，锁定两行记录之间的间隙。什么是间隙和行记录呢？如下 12345表A，有字段a,b,c,primary key为a,b列上建立普通索引a b c1 2 32 5 83 6 9 则表A有三条记录，Record Lock是锁在这些记录上的，字段b的间隙有(-$\infty$, 2),(2 5),(5, 6),(6,+$\infty$)，间隙就是排序后字段各个值的中间，间隙锁主要是用于锁住间隙，这样插入间隙之间字段值就需要获得间隙锁才能执行。间隙锁只有在Read Repeatable、Serializable隔离级别，能够使用间隙锁很好的防止幻读。 一致性锁定读使用next-key lock来实现。 例如在上述表A，在事务A中SELECT * FROM A WHER a = 2 FOR UPDATE，会使用next-key lock来锁住，由于字段a是主键，在唯一索引上，并且where 条件=或者in，next-key lock会降级成Record Lock，因为可以确定唯一的记录。 如果是在事务A中执行SELECT FROM A WHER b = 2 FOR UPDATE或SELECT FROM A WHER b &gt; 2 and b &lt; 5 FOR UPDATE，当对索引（不包括唯一索引）上进行wherr时，会对命中的记录加Record Lock，包括的范围（间隙(2，5)）加上gap Lock，同时对下一个间隙（(5，6)）也要加上gap Lock。此时其他事务对b=2的记录更新或者inser into字段b的值范围在2到5都会阻塞，因为b=2的记录和间隙(2 5),(5, 6)都被锁住了 如果是在事务A中执行SELECT * FROM A WHER c = 2 FOR UPDATE，则会多全表进行gap Lock，因为字段c上没有索引，进行当前读会在全表上使用间隙锁，这个尽量避免 幻读解决通过MVCC和next-key lock看起来已经很好解决了幻读问题，其实mysql的Repeatable read可以说是解决了幻读问题，但是也可以说做的还不够，官方给出的回答是 123只要在一个事务中，第二次select多出了row就算幻读。a事务先select，b事务insert确实会加一个gap锁，但是如果b事务commit，这个gap锁就会释放（释放后a事务可以随意dml操作），a事务再select出来的结果在MVCC下还和第一次select一样，接着a事务不加条件地update，这个update会作用在所有行上（包括b事务新加的），a事务再次select就会出现b事务中的新行，并且这个新行已经被update修改了，实测在RR级别下确实如此。如果这样理解的话，Mysql的RR级别确实防不住幻读 参考https://baijiahao.baidu.com/s?id=1629409989970483292&amp;wfr=spider&amp;for=pc 《MySQL技术内幕-InnoDB存储结构》]]></content>
  </entry>
  <entry>
    <title><![CDATA[分布式一致性协议介绍]]></title>
    <url>%2F%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E5%8D%8F%E8%AE%AE%E4%BB%8B%E7%BB%8D.html</url>
    <content type="text"><![CDATA[一致性分布式存储系统通常通过维护多个副本来进行容错，提高系统的可用性。但是分布式存储存在一个问题，如何保证相同时刻存储的数据是一样的，这就是一致性。它是构建具有容错性的分布式系统的基础，一致性保证每个结点存储的数据是一致的，这样即使部分结点宕机也能取得正确的副本数据。目前的一致性一致性协议通常基于replicated state machines，各个节点从一个相同初始化state出发，经过同样的操作序列(log)，最后到达相同的state 二阶段提交转载自：两阶段提交协议 两段式提交分为两个阶段： 阶段1：请求阶段（Prepare Phase）。在请求阶段，协调者通知事务参与者准备提交或者取消事务，然后进入表决过程。在表决过程中，参与者将告知协调者自己的决策：同意（事务参与者本地执行成功）或者取消（事务参与者本地执行失败） 阶段2：提交阶段（Commit Phase）。在提交阶段，协调者将基于第一个阶段的投票结果进行决策：提交或者取消。当且仅当所有的参与者同意提交事务协调者才通知所有的参与者提交事务，否则协调者通知所有的参与者取消事务。参与者在接收到协调者发来的消息后将执行相应的操作 两段式提交协议是阻塞协议，执行过程中需要锁住其他更新，节点在阶段1之后需要阻塞直到阶段2完成，浪费大量资源，并且不能容错，比如在阶段1之后阶段2之前，leader发生故障，则其余节点会永远进入阻塞状态 Raft协议转载自：Raft协议论文的中文扩展版和Raft协议详解 Raft协议主要分三方面：Leader的选举，Log的复制和集群成员变化。Raft协议保证节点的日志一样，并且按照相同的顺序执行，日志根据增加的先后会维持一个nextIndex，各个节点可以比较LogIndex来比较日志的新旧 Leader的选举Raft 通过选举一个leader，然后给予他全部的管理复制日志的责任来实现一致性。领导人从客户端接收日志条目，把日志条目复制到其他follower，并且当保证安全性的时候（当日志被一半以上follower执行）告诉其他的follower应用日志条目到他们的状态机中。拥有一个leader大大简化了对复制日志的管理。例如，leader可以决定新的日志条目需要放在日志中的什么位置而不需要和其他服务器商议，并且数据都从leader流向follower。一个leader可以宕机，可以和其他follower失去连接，这时一个新的leader会被选举出来。 每一个leader正常运行期间都会维持一个term，每当进行一次leader选举，term就会增加1 leader会定时向follower发送心跳包，一旦一个follower长时间没有接受到leader的心跳，就会认为leader失去连接，需要选举一个新leader，此时这个follower会将term加1开始选举投票，此时该follower会变为一个candidate并给自己投一票，同时发送RequestVoteRPC消息给其他follower follower会根据该消息比较自身的term和LogIndex来决定是否投票给candidate： 如果term不小于自身的term 如果candidate日志不比自身日志旧，则投票给他 如果接受到多个candidate的同个term的消息，按照先来先服务原则，一个term只会投一次 candidate收到follower的消息会有以下三种情况： 如果一半以上的服务器同意，则转态变为leader，并且发送心跳包PRC（包含term）给所有服务器。当一个服务器接受到心跳包，发现其中的term比自身的大时，并且如果当前state为leader或者candidate时，将自己的状态切成follower。如果比自身小时，则拒绝这个RPC 如果收到另一个candidate的消息，并且其term比自身的大，则状态变为follower 没有选出leader。比如各个节点都为candidate，将票投给自己，则candidate会有一个投票超时时间（election timeout）从150ms-300ms之间随机取，超时之后term增加重新选举 Log的复制通常leader会接受客户端的请求，每个请求包含一条需要被replicated state machines执行的命令。leader会把它作为一个log entry append到日志中，然后给follower发AppendEntriesRPC请求。当Leader确定一个log entry被safely replicated了（大多数副本已经将该命令写入日志当中），就apply这条log entry到状态机中然后返回结果给客户端。如果某个Follower宕机了或者运行的很慢，或者网络丢包了，则会一直给这个Follower发AppendEntriesRPC直到日志一致。 当一条日志是commited时，leader才可以将它应用到状态机中。Raft保证一条commited的log entry已经持久化了并且会被所有的节点执行。 但是leader在刚刚被选举出来之时，可能会存在各个服务器之间日志不统一，需要一个机制将follower统一成leader的日志。新选举出的leader和follower的日志可能会存在如下不同 新的leader可能会比follower多出log(a ~ b)，也可能会少(c ~ d)，也可能既多有少(e~f)。 因此，需要有一种机制来让leader和follower对log达成一致，leader会为每个follower维护一个nextIndex，表示leader给各个follower发送的下一条log entry在log中的index，初始化为leader的最后一条log entry的下一个位置。leader给follower发送AppendEntriesRPC消息，带着(term_id, (nextIndex-1))， term_id即(nextIndex-1)这个槽位的log entry的term_id，follower接收到AppendEntriesRPC后，会从自己的log中找是不是存在这样的log entry，如果不存在，就给leader回复拒绝消息，然后leader则将nextIndex减1，再重复，直到AppendEntriesRPC消息被接收。 以leader和b为例： 初始化，nextIndex为11，leader给b发送AppendEntriesRPC(6,10)，b在自己log的10号槽位中没有找到term_id为6的log entry。则给leader回应一个拒绝消息。接着，leader将nextIndex减一，变成10，然后给b发送AppendEntriesRPC(6, 9)，b在自己log的9号槽位中同样没有找到term_id为6的log entry。循环下去，直到leader发送了AppendEntriesRPC(4,4)，b在自己log的槽位4中找到了term_id为4的log entry。接收了消息。随后，leader就可以从槽位5开始给b推送日志了。 不过这个以上的机制需要不够完善，无法解决如下问题 在 (a) 中，S1 是leader，部分follower复制了索引位置2的日志条目 在 (b) 中，S1 崩溃了，然后 S5 在任term3 里通过 S3、S4 和自己的选票赢得选举，然后从客户端接收了一条不一样的日志条目放在了索引 2 处 然后到 (c)，S5 又崩溃了；S1 重新启动，选举成功，开始复制日志。在这时，来自term 2 的那条日志已经被复制到了集群中的大多数机器上，由于超过一半的节点已经同步了索引位置 2 的日志，因此该日志被commit到状态机中 接着S1 在 (d) 中又崩溃了，S5 可以重新被选举成功（通过来自 S2，S3 和 S4 的选票），然后覆盖了他们在索引 2 处的日志，即覆盖了已经commit到状态机中的日志 为了防止上述的错误，导致节点维持的日志和转态机中提交的不同，增加了一个限制，只允许leader提交包含当前term的日志，这样(c)中S1索引位置 2 的日志即使被大多数follower同步也无法commit到状态机中，因为当期的term为4，必须S1在term4的日志才会被commit(同时term4之前的日志也会被commit)，如(e)的情况，此时即使S1再下线，重新选主时S5不可能成为Leader，因为它没有包含大多数节点已经拥有的索引位置4的日志 集群成员变化集群的拓扑结构发生变化会影响一致性，Raft通过如下过程改变集群的变化。假设在Raft中，老集群配置用Cold表示，新集群配置用Cnew表示，整个集群拓扑变化的流程如下： 当集群成员配置改变时，leader收到人工发出的重配置命令从Cold切成Cnew； Leader副本在本地生成一个新的log entry，其内容是Cold $\cup$ Cnew，代表当前时刻新旧拓扑配置共存，写入本地日志，同时将该log entry推送至其他Follower节点 Follower副本收到log entry后更新本地日志，并且此时就以该配置作为自己了解的全局拓扑结构， 如果多数Follower确认了Cold $\cup$ Cnew这条日志的时候，Leader就Commit这条log entry； 接下来Leader生成一条新的log entry，其内容是全新的配置Cnew，同样将该log entry写入本地日志，同时推送到Follower上； Follower收到新的配置日志Cnew后，将其写入日志，并且从此刻起，就以该新的配置作为系统拓扑，并且如果发现自己不在Cnew这个配置中会自动退出 Leader收到多数Follower的确认消息以后，给客户端发起命令执行成功的消息 为什么需要弄这样一个两阶段协议，而不能直接从Cold切换至Cnew？这是因为，如果直接这么简单粗暴的来做的话，可能会产生多主。简单说明下： 假设一个集群存在三个节点S1，S2和S3，S1为Leader，其余为follower，此时新增两个节点S4，S5。S1如果直接将新的拓扑结构复制给S2后还没来得及复制个S3就下线了，此时需要选举，S2和S3都变成candidate发起投票，此时S1上线，将票投给S3，S4和S5将票投给S2。由于S3保留的是旧的拓扑结构，因此S2和S3都认为自己当选Leader，产生了两个Leader。这是由于整个集群节点所看到的集群拓扑结构不同引起的。 ZAB协议Zookeeper原子广播协议（Zookeeper Atomic Broadcast），简称ZAB协议，是zookeeper的一致性协议，zookeeper是分布式协调系统，很多分布式系统通过zookeeper来实现HA，解决一致性问题。而zookeeper本身是通过ZAB协议来保持一致性。ZAB协议主要分三部分：原子阶段，快速选举阶段和恢复阶段。ZAB协议中的一个重要数据是zxid，其分为两部分前32位代表epoch，每一次选举会加1，后32位代表事务id，每产生一个事务加1 原子阶段zookeeper广播是一个优化的二阶段提交的过程： 所有的写请求都是提交到leader上，即使客户端连接follower提交写请求，follower也会将请求传递给leader。 leader收到写请求，会将zxid自增1赋值给每一个事务（zxid维持日志执行的顺序性） leader和每一个follower都维持了一个先进先出队列，leader将zxid和事务作为一个提案（proposal）放入每个队列中。 follower从队列中获得提案，将提案写入磁盘（放在history），返回给leader一个ACK leader接受到关于zxid的提案的一半数量以上的ACK，则在本地提交该提案，应用到状态机中，并给所有follower发送commit命令 follower接受到commit命令会提交关于zxid的提案，同时应用到状态机中，如果follower之前（history中）还有没有执行的zxid小的提案，则按顺序提交 leader和follower之间队列的存在是解决二阶段提交阻塞的一种有效的方式，将leader和follower解耦，leader只要将提案放入队列，follower只需从队列读取提案返回给leader结果即可 快速选举阶段恢复阶段是针对leader挂掉的情况下的机制，ZAB协议在leader挂掉的情况通过保证以下两种情况来解决一致性问题： 确保已经被commit的事务最终应用到状态机 确保被leader提出还没有commit的事务全部丢弃 为了保证上述两个要求，ZAB协议的选举会选举出具有最新（最大）的zxid的事务的节点作为准leader。 当发现leader挂掉时，集群就开始选举。 选举开始阶段，每个节点都参与选举，首先投自己一票，然后给其余节点分发自己的选票，同时维持一个线程用来接受记录其他节点发来的选票信息，对选票情况进行判断，选出leader。 每个节点接受到其他节点的选票记录通过epoch（zxid的前32位），事务id（zxid后32位）和severid来进行比较，如果epoch相等则继续比较zxid，如果zxid相等则继续比较severid，如果其余节点的选票比自己的大，则更新自己的选票，否则坚持自己的选票，同时记录本次的选票到选票表中，将最新的选票发送给其他节点。 最终当没有新的选票产生，则统计选票表中的选票记录，如果半数节点都投票给同一个节点，则选举该节点为leader 恢复阶段选举出准leader之后需要同步leader和follower之间的事务，准leader将epoch加1，更新lastZxid，准leader接受到follower的同步请求时，会返送lastZxid，follower接受到lastZxid，如果比自身小则需要同leader同步最新事务，否则说明自身的事务未提交，直接丢弃 ZAB和Raft的区别 在请求处理时，Raft通过AppendEntries RPC将follower少的日志批量添加，ZAB通过简化的二阶段提交，leader和follower之间维持一个队列实现异步 Raft在选举leader只后就开始处理请求，因此raft需要增加了一个限制来防止上述的错误。而ZAB是选举准leader之后，同步完之后开始处理请求 参考两阶段提交协议 Raft协议论文的中文扩展版 Raft协议详解 Zab：Zookeeper 中的分布式一致性协议介绍 Raft对比ZAB协议 ZooKeeper 一致性协议 ZAB 原理分析！ Zookeeper一致性协议Zab详解]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>一致性</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java线程池]]></title>
    <url>%2Fjava%E7%BA%BF%E7%A8%8B%E6%B1%A0.html</url>
    <content type="text"><![CDATA[前言线程池是多并发编程中经常用到，了解是线程池的使用和原理是java程序员的必修课。编写多线程的程序推荐使用线程池而不是自己创建线程，因为线程池中的线程可以复用，复用线程可以降低线程创建和销毁的资源消耗，线程池帮助管理、调度、监控线程，可以防止无限制的创建线程，消耗完系统资源 简单使用几种常用的线程池： newCachedThreadPool，可缓存的线程池，线程池容量几乎为无限(Interger. MAX_VALUE)，当一个新线程任务提交，如果线程池没有空闲的线程，则创建一个新线程执行，否则使用空闲线程。 newFixedThreadPool，定长的线程池，线程池维持定长的线程，即使没有任务运行也不会关闭线程，当新任务提交，线程池中线程都在执行，则将任务放入阻塞队列中排队等待空闲线程运行。 newScheduledThreadPool，定长的线程池，支持定时及周期性执行任务，newFixedThreadPool的特殊化，线程池容量为1 newSingleThreadExecutor，线程池只有一个线程，所有任务按照提交的先后顺序执行 使用例子 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public class TreadPoolTest &#123; public static void executeThread(ExecutorService es)&#123; for (int i = 0; i &lt; 10;i++)&#123; es.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(2000); System.out.println(Thread.currentThread().getName()); &#125;catch (InterruptedException e)&#123; &#125; &#125; &#125;); &#125; &#125; public static void cachedThreadPoolTest() &#123; ExecutorService es = Executors.newCachedThreadPool(); executeThread(es); es.shutdown(); &#125; public static void fixedThreadPoolTest()&#123; ExecutorService es = Executors.newFixedThreadPool(3); executeThread(es); es.shutdown(); &#125; public static void singleThreadPoolTest()&#123; ExecutorService es = Executors.newSingleThreadExecutor(); executeThread(es); es.shutdown(); &#125; public static void scheduleThreadPoolTest1()&#123; ScheduledExecutorService es = Executors.newScheduledThreadPool(5); for (int i = 0;i &lt; 10;i++)&#123; es.scheduleAtFixedRate(new Runnable() &#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName()); &#125; &#125;, 1, 3, TimeUnit.SECONDS); &#125; es.shutdown(); &#125; public static void scheduleThreadPoolTest2()&#123; ScheduledExecutorService es = Executors.newScheduledThreadPool(1); es.scheduleAtFixedRate(new Runnable() &#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName()); &#125; &#125;, 1, 3, TimeUnit.SECONDS); &#125; public static void main(String[] args) &#123;// cachedThreadPoolTest(); // fixedThreadPoolTest();// singleThreadPoolTest();// scheduleThreadPoolTest1();// scheduleThreadPoolTest2(); &#125;&#125; 线程池实现线程池类的关系图： Executor接口：定义了运行新任务的execute接口 ExecutorService接口：继承了Executor接口，增加添加了一些用来管理执行器生命周期和任务生命周期的方法、支持Future任务的方法 AbstractExecutorService抽象类：实现了一些ExecutorService的通用接口 ThreadPoolExecutor类：实现了线程池的完整的方法 Scheduled相关的类：有关定期执行任务 Executors：是个工厂类，内部实际上是根据不同的线程池选择不同的参数生产ThreadPoolExecutor对象 因此线程池的实现方法主要在ThreadPoolExecutor，接下来会重点分析ThreadPoolExecutor来了解java线程池的实现 Executors当我们使用线程池通常是通过Executors的静态方法得到上述的几种线程池，其实Executors是个工厂类，内部是返回ThreadPoolExecutor的实例化对象,ScheduledThreadPoolExecutor提供定时启动线程执行任务的线程池，这里先不做介绍。 1234567891011121314151617181920212223public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125;public static ExecutorService newSingleThreadExecutor() &#123; // 确保单线程不被破坏 return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125;public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125;public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &#123; return new ScheduledThreadPoolExecutor(corePoolSize);&#125; 可以看出是通过在实例化ThreadPoolExecutor对象时传入不同的参数得到不同的线程池，接下来我们具体看ThreadPoolExecutor类 ThreadPoolExecutor常用变量ctl是ThreadPoolExecutor的重要变量，记录了线程池的运行状态runState和线程池有效的线程数workerCount(这里的workerCount指的正在运行任务的线程数，不算入空闲的线程数)。 ctl是一个AtomicInteger类，其后29位记录workerCount的数量，因此总共可以记录(2^29)-1 (约5亿)，第30位记录了线程池的运行状态，总共有五种状态： RUNNING：接受新任务并且能够处理阻塞队列中的任务 SHUTDOWN：不能接受新任务但是能够继续处理阻塞队列中的任务，当线程池处于RUNNING状态时，调用shutdown()方法进入该状态，这时线程池不接受新的任务，但是任然会继续处理完池中正在运行的任务和阻塞队列中的任务 STOP：不能接受新任务也不处理队列中的任务，并且会中断正在运行的任务，当线程池处于RUNNING状态时，调用shutdownNow()方法进入该状态 TIDYING：所有的任务都结束，线程池的数量为0，由SHUTDOWN或STOP状态转化而来，线程池进入该状态会调用terminated()的钩子方法 TERMINATED：terminated()方法调用完毕，线程池生命周期结束 线程池状态转化图： 线程池同时维护了线程的集合（其中存放Worker对象，即线程池中线程的封装对象）和一个ReentrantLock锁，后文会看到其使用 123private final ReentrantLock mainLock = new ReentrantLock();private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;(); 构造函数1234567891011121314151617181920212223242526272829303132333435// 线程池的重要参数，前三位表示线程池的状态，后29位表示池中的线程数private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));private static final int COUNT_BITS = Integer.SIZE - 3;private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1;// runState is stored in the high-order bitsprivate static final int RUNNING = -1 &lt;&lt; COUNT_BITS;private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;private static final int STOP = 1 &lt;&lt; COUNT_BITS;private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS;private static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; &#125;private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125;private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125;public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime, TimeUnit unit,BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory,RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.acc = System.getSecurityManager() == null ? null : AccessController.getContext(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125; 构造函数传入的字段主要为： corePoolSize：线程池的核心线程数，线程池维持的定长线程数，如果线程池的线程数量小于线程池的核心线程数，即使线程上没有任务也不会关闭 maximumPoolSize：线程池中的最大的线程数量 keepAliveTime：当线程池中的线程大于corePoolSize，空闲线程将会等待新任务，如果等待时间超过keepAliveTime，将会结束该空闲线程 unit：keepAliveTime的时间单位 workQueue：阻塞队列，当任务超过corePoolSize，将会进入等待队列，该队列是一个阻塞队列 threadFactory：用来创建新线程的工厂类，用户可以传入定制的threadFactory来创建定制的线程 handler：线程池的饱和策略，当线程池线程数量大于等于maximumPoolSize并且等待队列满时，新的任务将会交给handler处理 当新的任务提交时，先后会通过与corePoolSize，workQueue，maximumPoolSize，handler判断任务的去向 如果线程池的线程数小于corePoolSize，则会创建新线程运行任务，即使线程池中还有空闲线程。 如果线程池的线程数大于等于corePoolSize 如果等待队列中还没满，则将其放入等待队列中 如果等待队列满 如果线程池的线程数小于maximumPoolSize，则创建新线程运行任务 如果线程池的线程数大于等于maximumPoolSize，则交给handler来处理 线程池的线程如果执行完任务处于空闲状态时： 如果线程池的线程数小于corePoolSize，则继续保留空闲线程，等待新任务 如果线程池的线程数大于等于corePoolSize，则空闲线程等待新任务，等待时间超过keepAliveTime，则会回收空闲线程 任务提交任务通过execute方法提交 ，如上述所说的，如果线程池中线程个数小于corePoolSize，调用addWorker判断并新建一个线程执行任务，否则尝试将任务放入等待队列中，如果等待队列满了，则需要和线程池的最大容量比较，如果比其小，则新建一个线程运行，addWorker方法中的第二个参表示比较是corePoolSize还是maximumPoolSize，从下文的adddWorker方法中可以看到。如果都失败，则调用reject方法将任务交给handle处理。 1234567891011121314151617181920212223public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); // 如果线程池中线程数量小于corePoolSize，新建一个线程 if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; // 如果线程池的转态为RUNNING,则将任务放入等待队列 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; // 如果等待队列已经满了 else if (!addWorker(command, false)) reject(command);&#125; addWorker用于创建一个新的线程用来执行任务，firstTask是线程的第一个任务，core为true时表示当前线程池的线程数量小于corePoolSize，false表示数量大于corePoolSize且小于maximumPoolSize，因为不论是线程池的数量小于corePoolSize，还是等待队列满，线程池的线程数量大于corePoolSize且小于maximumPoolSize都需要创建新线程，这是两种情况下创建新线程。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); /** * 当线程池的状态大于SHUTDOWN时，说明线程池已经不再接受新任务了 * 当一下条件任何一个不满足时，则返回false * rs == SHUTDOWN:线程池的状态为SHUTDOWN， * firstTask == null:新任务为空 * ! workQueue.isEmpty()：等待队列不为空 * 当rs == SHUTDOWN时，此时不能接受新任务，因此如果新任务不为空，返回false， * 如果队列为空说明队列中已经的没有新任务，此时准备转移到TIDYING状态，队列不需要添加新的任务，返回false * 即在rs &gt;= SHUTDOWN时,除非是线程池处于SHUTDOWN转态，且任务为空，并且等待队列不为空，否则一律不创建新线程 */ if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; // 循环通过CAS修改workerCount for (;;) &#123; int wc = workerCountOf(c); // 根据core,比较corePoolSize或者maximumPoolSize的值，大于则返回false if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; // 修改workerCount的值，加1，成功则跳出外层循环 if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl // 状态改变，需要回到第一层for循环重头开始判断 if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; // 将任务封装成Worker对象 w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; // 加锁，同步，防止在运行新建线程的过程线程池的状态发生了变化 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); // 如果线程池处于RUNNING状态，或者处于SHUTDOWN状态且任务为空，则加入线程到工作集中 if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); // 将其加入到工作集合中 workers.add(w); int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; // 如果确认加入，则启动该线程 if (workerAdded) &#123; t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted;&#125; addWorker方法用于新建一个线程，启动并加入到workers当中 通过addWorker方法看来，只有当线程池中线程的数量符合要求，并且线程池的状态处于RUNNING或者处于SHUTDOWN并且新任务为空的时候才会新建线程运行任务，新线程在运行之前需要加锁并判断是否符合运行条件，加锁防止线程池的状态在这之间发生了变化，最后通过t.start()启动新线程，实际上Worker是一个Runnable,t是新建Worker对象w的Thread封装，start启动的是Worker线程,运行worker的run方法，通过接下来查看Worker代码可以看到。 Worker1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162private final class Worker extends AbstractQueuedSynchronizer implements Runnable&#123; private static final long serialVersionUID = 6138294804551838833L; /** Thread this worker is running in. Null if factory fails. */ final Thread thread; /** Initial task to run. Possibly null. */ Runnable firstTask; /** Per-thread task counter */ volatile long completedTasks; /** * Creates with given first task and thread from ThreadFactory. * @param firstTask the first task (null if none) */ Worker(Runnable firstTask) &#123; setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; // 传入Worker对象创建新线程 this.thread = getThreadFactory().newThread(this); &#125; /** Delegates main run loop to outer runWorker */ public void run() &#123; runWorker(this); &#125; protected boolean isHeldExclusively() &#123; return getState() != 0; &#125; protected boolean tryAcquire(int unused) &#123; if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; protected boolean tryRelease(int unused) &#123; setExclusiveOwnerThread(null); setState(0); return true; &#125; public void lock() &#123; acquire(1); &#125; public boolean tryLock() &#123; return tryAcquire(1); &#125; public void unlock() &#123; release(1); &#125; public boolean isLocked() &#123; return isHeldExclusively(); &#125; void interruptIfStarted() &#123; Thread t; if (getState() &gt;= 0 &amp;&amp; (t = thread) != null &amp;&amp; !t.isInterrupted()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; &#125; &#125;&#125; 可以看到Worker实现了Runnable，在构造函数中通过getThreadFactory().newThread(this)创建了新线程，因此在addWorker方法中启动的实际上是Worker对象的线程，线程调用start启动实际上是运行run方法中的代码，Worker中的run方法中调用了runWorker方法，在看runWorker方法之前，我们先来看Worker还继承了AQS,使用AQS实现独占锁的功能。 为什要设置锁：因为Worker对象不管是在初始化还是在运行过程当中都不希望被中断，使用AQS独占锁在获取独占锁之后，线程是不会被中断，只有线程运行结束才会进行中断的判断(详见AQS独占锁实现)，同时我们可以通过判断线程是否占有独占锁来判断线程是否在运行，通过isHeldExclusively方法返回false说明所已经被占有，线程正在运行。 为什么不用ReentrantLock：通过tryAcquire方法可以看到，Worker的锁是不可重入的，这是因为我们不希望任务在调用像setCorePoolSize这样的线程池控制方法时重新获取锁。如果使用ReentrantLock，它是可重入的，这样如果在任务中调用了如setCorePoolSize这类线程池控制的方法，会中断正在运行的线程。 同时Worker在初始化时是不能被中断，也不能获得其锁，getState(-1)，所以在runWorker方法中一开始需要unlock。 接下来让我们看看runWorker方法，了解线程池中的线程是怎么被复用的 runWorker123456789101112131415161718192021222324252627282930313233343536373839404142434445464748final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); // 获得第一个任务 Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try &#123; // 如果任务的为空，则从等待队列中获取一个任务，从这可以看出，第一个任务是可以为空的， // 如果第一个任务为空，则启动的线程会从等待队列中获取任务，但是等待队列中的任务都是不能为空的，getTask返回空说明获取任务失败：可能是线程池结束，也可能是等待任务时间超过keepAliveTime while (task != null || (task = getTask()) != null) &#123; // w.lock(); // 如果线程池的状态不为RUNNING和SHUTDOWN,则需要中断线程 if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; // 空方法，用于用户继承，在任务开始前添加操作 beforeExecute(wt, task); Throwable thrown = null; try &#123; // 运行任务，任务虽然是Runnable形式，但是并不是作为一个线程来运行 // 而是在Worker线程中，对一个个任务调run方法 task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; // 空方法，用于用户继承，在任务结束后添加操作 afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; processWorkerExit(w, completedAbruptly); &#125;&#125; runWorker方法是将worker中的任务作为第一个任务，while循环不断从等待队列取出任务执行，在循环中的过程： 首先判断线程池的状态是不是STOP或者后续转态，如果是且线程不是中断转态，则需要中断线程，if语句的写法有点看不懂。 调用beforeExecute方法，执行任务运行前的操作 调用任务的run方法，执行任务 调用afterExecute方法，执行任务结束后的操作 ThreadPoolExecutor中的beforeExecute和afterExecute方法都为空，留给子类实现在任务执行前后的操作。最后如果等待队列没有元素或者等待任务超过了等待的最长时间，退出循环，执行processWorkerExit方法。 可以从上面看出，虽然传入的任务是Runnable类型，但是实际运行并没有将任务作为一个独立的线程运行(没有将任务封装成Thread,调用start运行)，而是worker对象的线程不断从等待队列中获取任务，运行任务的run方法，线程池就是通过这样的方式复用线程：启用一个线程，调用任务的run方法，而不是将任务当成线程启动。 接下来我们来看从等待队列获取任务的方法getTask getTask1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * 如果getTask方法返回null,则在runWorker中就会退出循环，销毁线程 */private Runnable getTask() &#123; boolean timedOut = false; // Did the last poll() time out? for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // 如果线程池转态为STOP或者之后的状态，返回null // 如果线程池的转态为SHUTDOWN，并且等待队列为空，返回null // 返回null,则外部线程就会被销毁，因此线程池的线程数量减1 if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; decrementWorkerCount(); return null; &#125; int wc = workerCountOf(c); // 获取任务是否有等待的最长时间的标志 // allowCoreThreadTimeOut默认为false，可以由allowCoreThreadTimeOut来设置 boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; // 如果线程池数量过多或者获取任务时间超时，返回null // 但是要保证线程的数量大于一个如果在等待队列不为空的情况下 // 返回null,则外部线程就会被销毁，因此线程池的线程数量减1 if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; if (compareAndDecrementWorkerCount(c)) return null; continue; &#125; try &#123; // 如果设置等待超时，则调用阻塞队列的poll,在等待时间内获取，否则获取为null Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; timedOut = true; &#125; catch (InterruptedException retry) &#123; timedOut = false; &#125; &#125;&#125; 在getTask中线程的获取任务的最大等待时间实际上转变为阻塞队列调用poll上设置的最长等待时间。 回到runWorker的最后，我们来看如何销毁线程 processWorkerExit12345678910111213141516171819202122232425262728293031323334private void processWorkerExit(Worker w, boolean completedAbruptly) &#123; // 如果线程被中断，无法对线程操作，工作线程数减1 if (completedAbruptly) // If abrupt, then workerCount wasn't adjusted decrementWorkerCount(); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // 统计的完成的任务数，从workers中移除线程 completedTaskCount += w.completedTasks; workers.remove(w); &#125; finally &#123; mainLock.unlock(); &#125; // 每一个线程的结束都需要判断线程池是否可以结束 tryTerminate(); int c = ctl.get(); // 如果线程池处于RUNNING或者SHUTDOWN状态 if (runStateLessThan(c, STOP)) &#123; // 如果线程是正常结束的，进入if if (!completedAbruptly) &#123; // 设置最小线程数，保证线程池处于上述转态下有线程运行任务 int min = allowCoreThreadTimeOut ? 0 : corePoolSize; if (min == 0 &amp;&amp; ! workQueue.isEmpty()) min = 1; if (workerCountOf(c) &gt;= min) return; // replacement not needed &#125; // 如果线程被中断或者线程正常结束后小于线程池的维持的线程数，新启动一个线程 addWorker(null, false); &#125;&#125; 如果线程是正常结束，只要从worker集合中移除就好了，线程池维持的工作线程数量如果是线程正常结束，已经getTask减去1了，如果线程是中断意外结束的，需要在processWorkerExit中减去1(if (completedAbruptly){decrementWorkerCount()})。 每一个线程结束之后都需要调用tryTerminate判断是否线程池可以结束，尝试将线程池的转态转为TERMINATED，后文的tryTerminate方法中可以看到 最后要确保线程池中线程的数量，对于中断意外退出线程的情况，需要新建一个线程 如果没有设置过allowCoreThreadTimeOut，则要保证线程池中的线程数量不小于corePoolSize，否则需要新建一个线程 12345678910111213141516171819202122232425262728293031323334353637// 常数将线程池的转态转为TERMINATEDfinal void tryTerminate() &#123; for (;;) &#123; int c = ctl.get(); // 如果线程池的转态为RUNNING或者线程池已经处于结束转态 // 或者线程池处于SHUTDOWN但是等待队列中还有任务，都不需要操作，直接返回 if (isRunning(c) || runStateAtLeast(c, TIDYING) || (runStateOf(c) == SHUTDOWN &amp;&amp; ! workQueue.isEmpty())) return; // 运行到这说明线程池的状态处于STOP或者处于SHUTDOWN且等待队列中没有任务了 // 如果线程池中的还有线程，需要全部中断 if (workerCountOf(c) != 0) &#123; // Eligible to terminate interruptIdleWorkers(ONLY_ONE); return; &#125; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // 将状态转移到TIDYING if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) &#123; try &#123; // 调用terminated，运行完之后线程池的状态变为TERMINATED terminated(); &#125; finally &#123; ctl.set(ctlOf(TERMINATED, 0)); termination.signalAll(); &#125; return; &#125; &#125; finally &#123; mainLock.unlock(); &#125; // else retry on failed CAS &#125;&#125; 其余方法剩下的线程池的方法不一一细讲，介绍一下方法的作用 shutdown：将线程池的状态转为SHUTDOWN，不接受新任务，中断空闲线程，但是会将正在执行的任务和等待队列中的任务执行完 shutdownNow：将线程池的状态转为SHUTDOWN，不接受新任务，并将线程池运行的线程全部中断，等待队列清空 getTaskCount：线程池已经执行和未执行的任务总数 getCompletedTaskCount：线程池已经执行完的线程数 getLargestPoolSize：线程池中同时存在最大线程数 getPoolSize：线程池当前的线程数量 getActiveCount：当前线程池中正在执行任务的线程数量 总结线程池中任务提交处理和线程的处理方式： 当一个新任务通过execute提交 首先判断线程池线程数量，如果小于corePoolSize，则创建一个新线程处理，该任务作为其第一个任务 如果大于corePoolSize并且等待队列中未满，放入等待队列中 如果大于corePoolSize并且等待队列中已经满了，则需要和maximumPoolSize比较 如果大于maximumPoolSize，则交给饱和策略handle处理 如果小于maximumPoolSize，则创建一个新线程处理，该任务作为其第一个任务 当创建一个新的Worker对象线程时： 在新建一个Worker对象之前首先需要将workCount通过CAS加1，接着新建一个Worker对象，将其放入workers中 Worker初始化将自身对象传入Thread中，创建一个新线程，调用start,启动线程 线程不断从等待队列中取出任务，调用其run运行任务 在从等待队列中取任务会发生阻塞，如果当前线程池数量大于corePoolSize或者设置allowCoreThreadTimeOut为true，当阻塞时间超过keepAliveTime，就销毁线程 每一个线程结果判断线程池是否可以结束，如果是则转移线程池的转态到TERMINATED，同时需要判断线程池的线程是否小于corePoolSize或者设置allowCoreThreadTimeOut为true下的1，如果小则addWorker 参考深入理解Java线程池：ThreadPoolExecutor]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ReentrantLock]]></title>
    <url>%2FReentrantLock.html</url>
    <content type="text"><![CDATA[前言了解了java的队列式同步器AQS的基本实现，接下来可以看看java中频繁使用的可重入锁ReentrantLock。ReentrantLock是基于AQS实现的，内部类Sync继承了AQS，提供了公平锁和非公平锁。同synchronized相比，ReentrantLock是代码实现的锁，而synchronized是虚拟机上实现的锁，都是可重入的排他锁，即一个线程占有锁，其他线程必须等待锁的释放，同一个线程多次进入已将占有的锁，在效率方面，之前是ReentrantLock 效率更高，但后来java对synchronized进行了优化，效率目前来说差不多，ReentrantLock使用起来比synchronized更加灵活，synchronized使用来说更加方便，不用担心加锁释放锁的代码。 公平锁和非公平锁先来看看公平锁和非公平锁的不同： 公平锁：顾名思义，就是完全按照线程请求锁的先后顺序来获得锁，先到先得，如果等待锁的队列中还要其他线程，必须排在其后面等待 非公平锁：在线程请求锁的同时，该锁被释放，则该线程会直接获得锁，无需经过等待队列，如果请求锁的同时锁被占有，则和公平锁一致，需要在等待队列中排队等候 公平锁和非公平锁各有各的应用场景，因为一个线程从唤醒到持有锁执行任务之间有着严重的延迟，假设一个线程A释放锁，需要唤醒其后继节点的线程B，B在从唤醒到持有锁有一段时间的延迟中，有一个线程C尝试获取锁，如果采用非公平锁，这时C会获得锁，如果C执行时间很短，在B唤醒前已经执行完毕，则B唤醒则直接获得锁执行，但如果C执行时间很长，在B唤醒前无法执行完毕，则B唤醒后获取锁失败会被重新挂起。 因此对于那些线程持有锁的时间较长的情况，采用公平锁更合适，减少不必要的唤醒（在非公平锁下唤醒得不到锁被重新挂起）带来的消耗，对于线程持有锁时间较短的情况，非公平锁可以提高效率，即不影响等待队列中线程运行，同时能运行完插队的线程。 总的来说，公平锁保证线程请求资源上的绝对公平，但是频繁的切换上下文，非公平锁可以降低上下文切换，降低性能开销，有更大的吞吐量，但是非公平锁有可能造成饥饿现象。 ReentrantLockReentrantLock是可重入独占锁，其内部是通过调用内部类Sync的方法实现对锁的控制，Sync是继承了AQS类，其使用了模板方法，子类只需实现tryAcquire和tryRelease方法返回获取锁和释放锁是否成功的boolean即可，如果获取锁线程会被挂起在同步队列中（在AQS中实现）因此ReentrantLock中Sync只需考虑判断是否获取锁成功以及判断是否释放锁，同时可以通过setExclusiveOwnerThread设置线程为独占锁的线程（传入null代表无线程占有锁，一般在释放锁时调用），AQS类的详细解读可以看java同步器-AQS。 非公平锁的实现ReentrantLock考虑到系统的性能，默认是采用非公平锁，从其构造函数可以看出 12345678// 默认为非公平锁public ReentrantLock() &#123; sync = new NonfairSync();&#125;public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125; NonfairSync就是ReentrantLock中非公平锁的实现，其继承了Sync。 12345678910111213141516171819202122232425262728293031323334353637383940414243abstract static class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = -5179523762034025860L; abstract void lock(); final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; // 如果抢占锁成功，直接 if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; // 如果是同一个线程，则可重入，state加1 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false; &#125; ...&#125;static final class NonfairSync extends Sync &#123; private static final long serialVersionUID = 7316153563782823691L; final void lock() &#123; // 当前没有线程持有锁，当前线程可直接尝试获取锁 if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); &#125; protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125;&#125; 可以看到非公平锁lock()过程是，首先通过CAS设置State,如果设置成功，则说明获取锁成功，失败再调用acquire，调用tryAcquire方法，tryAcquire方法使用父类Sync的nonfairTryAcquire，这也是一次尝试通过CAS设置State,如果设置成功，则说明获取锁成功。可以看到如果有线程占有锁，会进行判断当前线程和占有锁的线程是否为同一个线程，如果是，state加1，获取锁成功，这里实现了可重入的功能。而state是判断能否释放锁的依据。 公平锁的实现1234567891011121314151617181920212223242526272829static final class FairSync extends Sync &#123; private static final long serialVersionUID = -3000897897090466540L; final void lock() &#123; acquire(1); &#125; protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; // 即使当前没有线程持有锁，如果等待队列中还有元素，也无法获得锁，需要等待 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; // 如果请求锁的线程是当前持有锁的线程，则返回true,实现可重入锁，state加1 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false; &#125;&#125; 其实公平锁和非公平锁的实现几乎类似，公平锁的lock方法直接调用acquire方法，没有非公平锁的抢占的操作，acquire最终会调用tryAcquire尝试获取锁（AQS中的实现），公平锁的tryAcquire方法在获取线程时比非公平锁多了一个hasQueuedPredecessors判断，判断等待队列中是否有前驱节点，如果有则不去尝试获取锁，直接判断获取失败。 释放锁1234567891011121314protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; // c==0代表重入已经全部释放 if (c == 0) &#123; free = true; // 设置持有独占锁的信息为空 setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; 释放锁的过程是相同的，由于是可重入锁，state记录线程重入的次数，所以每当线程释放一次锁state减1，直到state的为0时代表线程重入锁已经全部释放，这时候可以释放锁给其他线程。由于tryRelease调用会减少state，所以是不允许未获得锁的线程释放锁的（即没有调用lock方法就调用release方法），否则会造成出错。]]></content>
  </entry>
  <entry>
    <title><![CDATA[java同步器-AQS]]></title>
    <url>%2Fjava%E5%90%8C%E6%AD%A5%E5%99%A8-AQS.html</url>
    <content type="text"><![CDATA[前言AQS，即AbstractQueuedSynchronized，抽象的队列式同步器，它是一个用于构建锁和同步器的基础框架，java中很多锁和同步器的实现都依赖AQS,比如ReentrantLock、 ReadWriteLock、Semaphore、CountDownLatch等。然而这些锁都没有直接来继承AQS,而是定义了一个Sync类去继承AQS.因为锁面向的是使用用户,而同步器面向的则是线程控制,那么在锁的实现中聚合同步器而不是直接继承AQS就可以很好的隔离二者所关注的事情. AQS的实现是基于CLH队列，CLH队列的提出是用于自旋锁，但在AQS中，JUC并发包的作者（Doug Lea）将其用于阻塞锁。在了解AQS之前首先来看看CAS和CLH队列。 CAS在讲CAS之前，不得不提起乐观锁和悲观锁。乐观锁和悲观锁的区别也看做阻塞同步和非阻塞同步的区别。 悲观锁悲观锁可以看做是当多个线程竞争同一个资源（比如一个共享数据），其中一个线程最先获得资源的锁时，会认为其他线程对该资源的操作都会对其造成影响，为确保不造成任何影响，将其他线程在获取资源时都阻塞，直到持有锁的线程操作完毕释放锁，唤醒阻塞的线程抢占锁。独占锁是一种悲观锁，synchronized就是一种独占锁。独占锁是一种悲观锁，synchronized就是一种独占锁独占锁是一种悲观锁，synchronized就是一种独占锁。 乐观锁悲观锁保证了同步互斥，但是线程的阻塞和唤醒（即挂起和恢复）是存在着很大的开销的，如果每个线程执行的操作很短，即持有锁后很快就释放，则其余等待线程就需要频繁的阻塞和唤醒。这样同步互斥的代价就会很高，因此引入了乐观锁，乐观锁也是非阻塞同步，也就是说乐观锁无需阻塞线程来保证同步互斥，乐观锁的思想是每个线程不加锁没有冲突去完成对资源的操作，如果发生冲突（如修改资源时发现已经被别的线程修改）则重试，直到没有成功为止。乐观锁思想的实现有CAS、多版本并发控制（mvcc）等。 CASCAS（compare and set，比较和交换）是一种无锁的非阻塞算法的是实现。CAS是CPU指令级的操作，是原子操作。当多个线程同时通过CAS同时修改一个值时，只有一个线程会成功，其他线程都会失败，都是失败线程不会终止，而是尝试再次修改，直到成功为止。 CAS修改一个值的操作涉及到三个变量：内存值V，旧的预期值A，修改的新值B。每一个线程拿着旧的预期值和修改的新值调用CAS,如果旧的预期值和内存值相同，则将新增赋值给内存值，否则什么也不做。 因此每一个线程应用CAS实现的乐观锁算法为： 1234do&#123; A = copy(V) // 在当前线程修改值时可能已经有一个线程修改掉内存值，造成失败&#125;while(!compareAndSet(A, B)) 但是CAS存在ABA问题，实际上 JDK 对 ABA 问题提供的解决方案是加入 AtomicStampedReference 这个类，为变量加上版本来解决 ABA 问题。 乐观锁、悲观锁、CAS的参考https://www.cnblogs.com/Mainz/p/3546347.html https://blog.csdn.net/truelove12358/article/details/54963791 CLH队列（转载）CLH队列的提出是用于自旋锁的，从各个自旋锁的发展可以看到CLH自旋锁的↔️，以下内容是转载自：https://www.jianshu.com/p/0f6d3530d46b 以 synchronized 为代表的阻塞同步，因为阻塞线程会恢复线程的操作都需要涉及到操作系统层面的用户态和内核态之间的切换，这对系统的性能影响很大。自旋锁的策略是当线程去获取一个锁时，如果发现该锁已经被其它线程占有，那么它不马上放弃 CPU 的执行时间片，而是进入一个“无意义”的循环，查看该线程是否已经放弃了锁。 但自旋锁适用于临界区比较小的情况，如果锁持有的时间过长，那么自旋操作本身就会白白耗掉系统的性能。 以下为一个简单的自旋锁实现： 123456789101112131415import java.util.concurrent.atomic.AtomicReference;public class SpinLock &#123; private AtomicReference&lt;Thread&gt; owner = new AtomicReference&lt;Thread&gt;(); public void lock() &#123; Thread currentThread = Thread.currentThread(); // 如果锁未被占用，则设置当前线程为锁的拥有者 while (!owner.compareAndSet(null, currentThread)) &#123;&#125; &#125; public void unlock() &#123; Thread currentThread = Thread.currentThread(); // 只有锁的拥有者才能释放锁 owner.compareAndSet(currentThread, null); &#125;&#125; 上述的代码中， owner 变量保存获得了锁的线程。这里的自旋锁有一些缺点，第一个是没有保证公平性，等待获取锁的线程之间，无法按先后顺序分别获得锁；另一个，由于多个线程会去操作同一个变量 owner，在 CPU 的系统中，存在着各个 CPU 之间的缓存数据需要同步，保证一致性，这会带来性能问题。 公平的自旋为了解决公平性问题，可以让每个锁拥有一个服务号，表示正在服务的线程，而每个线程尝试获取锁之前需要先获取一个排队号，然后不断轮询当前锁的服务号是否是自己的服务号，如果是，则表示获得了锁，否则就继续轮询。下面是一个简单的实现： 123456789101112131415161718192021import java.util.concurrent.atomic.AtomicInteger;public class TicketLock &#123; private AtomicInteger serviceNum = new AtomicInteger(); // 服务号 private AtomicInteger ticketNum = new AtomicInteger(); // 排队号 public int lock() &#123; // 首先原子性地获得一个排队号 int myTicketNum = ticketNum.getAndIncrement(); // 只要当前服务号不是自己的就不断轮询 while (serviceNum.get() != myTicketNum) &#123; &#125; return myTicketNum; &#125; public void unlock(int myTicket) &#123; // 只有当前线程拥有者才能释放锁 int next = myTicket + 1; serviceNum.compareAndSet(myTicket, next); &#125;&#125; 虽然解决了公平性的问题，但依然存在前面说的多 CPU 缓存的同步问题，因为每个线程占用的 CPU 都在同时读写同一个变量 serviceNum，这会导致繁重的系统总线流量和内存操作次数，从而降低了系统整体的性能。 MCS 自旋锁MCS 的名称来自其发明人的名字：John Mellor-Crummey和Michael Scott。 MCS 的实现是基于链表的，每个申请锁的线程都是链表上的一个节点，这些线程会一直轮询自己的本地变量，来知道它自己是否获得了锁。已经获得了锁的线程在释放锁的时候，负责通知其它线程，这样 CPU 之间缓存的同步操作就减少了很多，仅在线程通知另外一个线程的时候发生，降低了系统总线和内存的开销。实现如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;public class MCSLock &#123; public static class MCSNode &#123; volatile MCSNode next; volatile boolean isWaiting = true; // 默认是在等待锁 &#125; volatile MCSNode queue;// 指向最后一个申请锁的MCSNode private static final AtomicReferenceFieldUpdater&lt;MCSLock, MCSNode&gt; UPDATER = AtomicReferenceFieldUpdater .newUpdater(MCSLock.class, MCSNode.class, &quot;queue&quot;); public void lock(MCSNode currentThread) &#123; MCSNode predecessor = UPDATER.getAndSet(this, currentThread);// step 1 if (predecessor != null) &#123; predecessor.next = currentThread;// step 2 while (currentThread.isWaiting) &#123;// step 3 &#125; &#125; else &#123; // 只有一个线程在使用锁，没有前驱来通知它，所以得自己标记自己已获得锁 currentThread.isWaiting = false; &#125; &#125; public void unlock(MCSNode currentThread) &#123; if (currentThread.isWaiting) &#123;// 锁拥有者进行释放锁才有意义 return; &#125; if (currentThread.next == null) &#123;// 检查是否有人排在自己后面 if (UPDATER.compareAndSet(this, currentThread, null)) &#123;// step 4 // compareAndSet返回true表示确实没有人排在自己后面 return; &#125; else &#123; // 突然有人排在自己后面了，可能还不知道是谁，下面是等待后续者 // 这里之所以要忙等是因为：step 1执行完后，step 2可能还没执行完 while (currentThread.next == null) &#123; // step 5 &#125; &#125; &#125; currentThread.next.isWaiting = false; currentThread.next = null;// for GC &#125;&#125; MCS 的能够保证较高的效率，降低不必要的性能消耗，并且它是公平的自旋锁。 CLH 自旋锁CLH 锁与 MCS 锁的原理大致相同，都是各个线程轮询各自关注的变量，来避免多个线程对同一个变量的轮询，从而从 CPU 缓存一致性的角度上减少了系统的消耗。 CLH 锁的名字也与他们的发明人的名字相关：Craig，Landin and Hagersten。 CLH 锁与 MCS 锁最大的不同是，MCS 轮询的是当前队列节点的变量，而 CLH 轮询的是当前节点的前驱节点的变量，来判断前一个线程是否释放了锁。 实现如下所示： 123456789101112131415161718192021222324import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;public class CLHLock &#123; public static class CLHNode &#123; private volatile boolean isWaiting = true; // 默认是在等待锁 &#125; private volatile CLHNode tail ; private static final AtomicReferenceFieldUpdater&lt;CLHLock, CLHNode&gt; UPDATER = AtomicReferenceFieldUpdater . newUpdater(CLHLock.class, CLHNode .class , "tail" ); public void lock(CLHNode currentThread) &#123; CLHNode preNode = UPDATER.getAndSet( this, currentThread); if(preNode != null) &#123;//已有线程占用了锁，进入自旋 while(preNode.isWaiting ) &#123; &#125; &#125; &#125; public void unlock(CLHNode currentThread) &#123; // 如果队列里只有当前线程，则释放对当前线程的引用（for GC）。 if (!UPDATER .compareAndSet(this, currentThread, null)) &#123; // 还有后续线程 currentThread.isWaiting = false ;// 改变状态，让后续线程结束自旋 &#125; &#125;&#125; 从上面可以看到，MCS 和 CLH 相比，CLH 的代码比 MCS 要少得多；CLH是在前驱节点的属性上自旋，而MCS是在本地属性变量上自旋；CLH的队列是隐式的，通过轮询关注上一个节点的某个变量，隐式地形成了链式的关系，但CLHNode并不实际持有下一个节点，MCS的队列是物理存在的，而 CLH 的队列是逻辑上存在的；此外，CLH 锁释放时只需要改变自己的属性，MCS 锁释放则需要改变后继节点的属性。 CLH 队列是 J.U.C 中 AQS 框架实现的核心原理，在AQS中将CLH的自旋改为阻塞，下一个节点根据上一个节点的属性上阻塞。 AQSAQS是通过一个先进先出的双端队列来维护线程同步状态的管理，当线程获得锁失败时，会将线程阻塞并加入到队列的末尾，队列头持有锁，如果头结点释放锁会将后继节点释放，并作为头结点。 Node既然是队列，我们先来看看队列中的节点（node）,队列中的节点存放的是一个个线程，其实AQS中并没有维护一个明确的队列，是通过各个节点存放的next和prev指针记录队列中的位置，AQS维护着head和tail来存放队列中头和尾。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546private transient volatile Node head;private transient volatile Node tail;static final class Node &#123; /** Marker to indicate a node is waiting in shared mode */ static final Node SHARED = new Node(); /** Marker to indicate a node is waiting in exclusive mode */ static final Node EXCLUSIVE = null; static final int CANCELLED = 1; static final int SIGNAL = -1; static final int CONDITION = -2; static final int PROPAGATE = -3; volatile int waitStatus; volatile Node prev; volatile Node next; Node nextWaiter; /** * Returns true if node is waiting in shared mode. */ final boolean isShared() &#123; return nextWaiter == SHARED; &#125; final Node predecessor() throws NullPointerException &#123; Node p = prev; if (p == null) throw new NullPointerException(); else return p; &#125; Node() &#123;&#125; Node(Thread thread, Node mode) &#123; // Used by addWaiter this.nextWaiter = mode; this.thread = thread; &#125; Node(Thread thread, int waitStatus) &#123; // Used by Condition this.waitStatus = waitStatus; this.thread = thread; &#125;&#125; Node的状态有5种，分1，-1，-2，-3，分别代表的意义： CANCELLED(1)：表示该节点的线程因为超时或者中断而退出，节点一旦进入该状态就不会转移到其他状态，相应的节点会在队列中被移除。 SIGNAL(-1):表示其后继节点将会被挂起，在当前节点释放锁后，其后继节点会被唤醒。 CONDITION(-2):当前节点处于条件等待状态，不会被当成队列中的节点，直到被唤醒，其值设置为0，进入阻塞状态 PROPAGATE(-3):传播共享锁 0:新加入队列的节点 nextWaiter来标记节点是否是共享模式。 同步状态AQS内部的同步状态是通过state表示，state被volatile修饰，其修改对所有线程可见。 12345678910111213private volatile int state;/*获取当前同步状态*/protected final int getState() &#123;return state;&#125;/*设置当前同步状态*/protected final void setState(int newState) &#123;state = newState;&#125;/*使用Unsafe的CAS操作设置当前同步状态，该方法操作能保证原子性*/protected final boolean compareAndSetState(int expect, int update) &#123; // See below for intrinsics setup to support this return unsafe.compareAndSwapInt(this, stateOffset, expect, update);&#125; 同步状态 state的具体语义与具体使用者有关。如在Semaphore中state表示可获取的信号量，当调用acquire方法成功获取一次后state值将减一，用完调用release方法释放后state的值将加一 ; 在CountDownLatch中 state表示调用await的方法的线程还要等待调用多少次countDown方法，该线程才能继续执行; 在ReentrantLock中state表示，线程调用lock方法的次数。 模板模式下，AQS子类通过设置state来实现获取锁acquire和释放锁release的方法。可以看下文的AQS的使用看到用法。 独占模式在获取锁的时候，分为独占模式(exclusive mode)和共享模式(shared mode)，独占模式是只有一个线程能获取到锁，但是共享模式可以允许多个线程同时获取到锁。比如ReentrantLock就是一个独占锁，只能有一个线程获得锁，而WriteAndReadLock的读锁则能由多个线程同时获取，但它的写锁则只能由一个线程持有。 ASQ类使用了模板方法设计模式，具体的如何获取锁和释放锁是交由子类具体实现，AQS中只有获取锁和释放锁时队列中节点的变化和队列的调整。接下来先来看独占模式下锁的获取和释放。 获取锁123456public final void acquire(int arg) &#123;// 尝试获得锁，如果获得锁或者将当前节点设置为独占模式加入到队列末尾，退出，否则触发中断 if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125; 这里首先尝试获取锁，tryAcquire交由子类实现，如果获取锁失败，则将其加入到等待队列中，并设置为独占模式。 123456789101112131415161718192021private Node addWaiter(Node mode) &#123; //根据当前线程封装成node,其模式为独占模式 Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; // 判断队列中有无元素 if (pred != null) &#123; node.prev = pred; // compareAndSetTail是判断队列末尾是否为pred,是则加入node,返回true // 这里可能有别的元素在此过程中插入，队列末尾不是pred // 则会退出if,进入enq循环CAS插入 if (compareAndSetTail(pred, node)) &#123; pred.next = node; // 插入队尾结束，返回 return node; &#125; &#125; // 队列中无元素或者插入失败，进入enq插入，for循环，直到插入为止 enq(node); return node;&#125; 可以看到首先获得队列尾部节点，尝试用CAS插入节点，如果队列尾部节点为空(即队列中节点)或者通过CAS时发生冲突失败(即在插入当中有别的元素插入，队尾元素改变)，则调用enq插入。 1234567891011121314151617private Node enq(final Node node) &#123; // 不断尝试，直到插入为止 for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize // 队列中无元素，通过CAS设置头节点 if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; enq方法尝试通过CAS乐观锁算法循环插入，直到成功为止，如果队列中无节点，则设置为队列头。在加入到等待队列过程中，可能已经有线程释放锁，还需要判断线程是否能重新获得锁，否则需要挂起，即阻塞线程。 12345678910111213141516171819202122232425final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; // 获取前驱节点 final Node p = node.predecessor(); // 判断前驱节点释放为头结点，并尝试获得锁 // 如果成功，则设置当前节点为头结点，否则判断是否需要挂起 if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; // 判断是否需要挂起 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 如果没获取到锁,则判断是否应该挂起,而这个判断则得通过它的前驱节点的waitStatus来确定: 1234567891011121314private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; if (ws == Node.SIGNAL) return true; if (ws &gt; 0) &#123; do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; 首先判断其前驱节点是否是挂起状态，如果是则直接得到需要挂 如果不是则判断是否是CANCELLED(1)状态(大于0)，是则将前驱队列从队列中删除，找到一个不为CANCELLED状态的节点作为前驱节点，返回false，等待acquireQueued的下一次循环挂起 如果不是，则将前驱节点设置为挂起状态，返回false，等待acquireQueued的下一次循环挂起 真正挂起线程在parkAndCheckInterrupt函数中,其中调用了LockSupport的park挂起线程，只有通过shouldParkAfterFailedAcquire判断需要挂起线程，才会调用parkAndCheckInterrupt。 12345private final boolean parkAndCheckInterrupt() &#123; // 底层调用操作系统挂起线程 LockSupport.park(this); return Thread.interrupted();&#125; 可以看到线程在走到这里被操作系统挂起，直到系统唤醒才会继续执行，继续执行将会回到acquireQueued方法中的for循环，判断前驱节点是否为头结点并尝试获得锁。在系统挂着线程是无法中断的，只能是线程被唤醒，查看自身的中断状态，才知道是否被中断，如果中断，则最后会调用selfInterrupt方法。 总的来说，AQS中解决通过问题都是通过CAS乐观锁算法解决，获取锁的过程是 首先尝试获取锁tryAcquire，如果失败则需要添加到队列尾部 队列尾部通过CAS循环插入 插入到尾部的线程需要判断前驱是否为头结点，是则尝试获取锁 获取锁失败或者前驱不是头结点，则需要挂起线程，找到一个前驱不为CANCELLED的节点，如果不为挂起状态，则将前驱设为挂着状态，接着通过LockSupport挂起当前线程 线程等待唤醒，如果唤醒，则继续acquireQueued中的for循环，判断前驱节点是否为头结点，是则tryAcquire尝试获得锁，所以所有线程获得锁都必须通过子类编写的具体的tryAcquire方法 其中如果唤醒线程发现被中断，则acquireQueued返回结果为false，调用selfInterrupt中断 释放锁123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; 首先通过模板方法的子类实现的tryRelease释放锁，接着讲后继节点变为头结点，通过unparkSuccessor唤醒头结点的线程。 1234567891011121314private void unparkSuccessor(Node node) &#123; int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread);&#125; 如果头结点不为空，且不为CANCELLED状态，则直接通过LockSupport的unpark唤醒节点，否则需要从尾部开始向前寻找第一个不为CANCELLED状态的节点唤醒。 为什么不往下(next)寻找可用的节点，而是从尾部往前寻找，因为next的节点也可能为空或者CANCELLED状态。 共享模式共享模式的实现和独占模式差不多，有时间会继续更新 LockSupportLockSupport是唤醒和阻塞线程的类，底层是通过UNSAFE类调用系统内核进行线程的阻塞和唤醒。 LockSupport中parks是阻塞线程方法(有很多重载方法，可以设置等待时间等)， unparks是唤醒线程。 AQS使用jdk的AQS类中给出了一个使用AQS实现互斥锁的简单例子。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879class Mutex implements Lock, java.io.Serializable &#123; // Our internal helper class private static class Sync extends AbstractQueuedSynchronizer &#123; // 返回锁是否被持有 protected boolean isHeldExclusively() &#123; return getState() == 1; &#125; // 如果state为0，则获取锁，将state通过CAS设置为1 public boolean tryAcquire(int acquires) &#123; assert acquires == 1; // Otherwise unused if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; // 释放锁，将state设置为0 protected boolean tryRelease(int releases) &#123; assert releases == 1; // Otherwise unused if (getState() == 0) throw new IllegalMonitorStateException(); setExclusiveOwnerThread(null); setState(0); return true; &#125; // Provides a Condition Condition newCondition() &#123; return new ConditionObject(); &#125; // Deserializes properly private void readObject(ObjectInputStream s) throws IOException, ClassNotFoundException &#123; s.defaultReadObject(); setState(0); // reset to unlocked state &#125; &#125; // The sync object does all the hard work. We just forward to it. private final Sync sync = new Sync(); // 获取锁，失败则加入CLH队列中 public void lock() &#123; sync.acquire(1); &#125; // 获取锁，失败不会加入到CLH队列中，只会返回false public boolean tryLock() &#123; return sync.tryAcquire(1); &#125; public void unlock() &#123; sync.release(1); &#125; public Condition newCondition() &#123; return sync.newCondition(); &#125; public boolean isLocked() &#123; return sync.isHeldExclusively(); &#125; public boolean hasQueuedThreads() &#123; return sync.hasQueuedThreads(); &#125; public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1); &#125; public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(timeout)); &#125;&#125; Mutex通过修改AQS的state来标志锁是被持有还是被释放。注意lock和tryLock是不同的，这两个方法都会尝试获取锁，但是lock调用AQS的acquire方法，未获取的锁，会进入CLH队列中挂起等待轮到头结点唤醒，tryLock调用tryAcquire方法，未获取到锁，不会被挂起。 1234567891011121314151617181920212223242526272829303132333435363738public class MutexTest &#123; public static void main (String [] args) &#123; Mutex lock = new Mutex(); new Thread(new Runnable() &#123; @Override public void run() &#123; lock.lock(); try &#123; Date now = new Date(); System.out.println(" thread1 running now:" + now); Thread.sleep(3000); System.out.println(" thread1 running finish"); &#125; catch (InterruptedException e) &#123; Thread.currentThread().interrupt(); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; lock.lock(); try &#123; Date now = new Date(); System.out.println(" thread2 running now:" + now); Thread.sleep(3000); System.out.println(" thread1 running finish"); &#125; catch (InterruptedException e) &#123; Thread.currentThread().interrupt(); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125;).start(); &#125;&#125; 可以看到结果,线程2在线程1释放锁后获得锁 1234thread1 running now:Wed Mar 13 21:53:04 CST 2019thread1 running finishthread2 running now:Wed Mar 13 21:53:07 CST 2019thread2 running finish 参考【死磕Java并发】—–J.U.C之AQS（一篇就够了） 深入学习java同步器AQS 线程安全实现与CLH队列 《深入理解java虚拟机》]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[红黑树-转载整理]]></title>
    <url>%2F%E7%BA%A2%E9%BB%91%E6%A0%91-%E8%BD%AC%E8%BD%BD%E6%95%B4%E7%90%86.html</url>
    <content type="text"><![CDATA[前言红黑树是一种自平衡二叉查找树，其每个结点都有一个存储位来表示结点的颜色，RED或者BLACK。红黑树的实现结构复杂，但是在红黑树上的查找，增加和删除的时间复杂度都为O(logn)，因此红黑树的应用广泛，如Java的HashMap当冲突链表长度大于8时，转为红黑树；TreeMap使用红黑树结构等。 二叉查找树在了解红黑树之前要先明白二叉查找树，因为红黑树是特殊的二叉查找树，有着二叉查找树特点。 性质二叉查找树上的结点必须按二叉查找树的性质进行存储： 如果一个结点拥有左子树，则左子树上的所有结点的值都小于该结点的值 如果一个结点拥有右子树，则右子树上的所有结点的值都大于该结点的值 表示 T：树的头结点 每个结点都有key、left、right、p属性，分别代表结点值、左结点、右结点和父结点 查找由于二叉查找树的性质，如果查找值比结点的值小进入左子树查找，否则进入右子树查找 12345678910TREE-SEARCH(T, k) x = T while x != NULL if x.key == k return x else if x.key &gt; k x = x.right else x = x.left return NULL 插入同样是根据二叉查找树的性质，找到合适的叶子节点插入 12345678910111213141516TREE-INSERT(T, z) x = T // y记录要插入的父节点 while x != NULL y = x else if x.key &gt; z.key x = x.right else x = x.left z.p = y if y == NULL T = z else if z.key &gt; y.key y.right = z else y.left = z 删除删除分三种情况： 如果删除的节点是叶子节点，则直接删除 如果删除的节点只有一个孩子节点，则将孩子节点代替删除的节点位置 如果删除的节点有左右子树，则找到其前驱节点或者后继节点代替删除节点位置，前驱节点或者后继节点必定只有一个孩子节点，接着按照情况2删除前驱节点或者后继节点 12345678910111213141516171819202122232425262728// 用y结点代替x结点REPLACE(T, x, y) if x.p == NULL T = y else if x.p.left == x x.p.left = y else x.p.right = y if y != NULL y.p = x.p // 删除z结点TREE-DELETE(T, z) if z.right == NULL REPLACE(T, z, z.left) else if z.left == NULL REPLACE(T, z, z.right) else y = z.right while y.left != NULL y = y.left REPLACE(T, y, y.right) y.right = z.right y.right.p = y REPLACE(T, z, y) y.left = z.left y.left.p = y 红黑树讲完二叉查找树终于轮到我们在主角，红黑树。由于当二叉查找树插入的节点值按照顺序，则形成的二叉树和链表相同，无法提高查找的效率，因此引入红黑树。 性质 每个结点都有颜色属性，不是黑色就是红色 根节点是黑色的 每一个叶结点都是黑色的，叶结点值为NULL，不存储值 如果一个结点是红色的，则它的两个叶子结点都是黑色的 对于每一个结点，从该结点到其所有后代叶结点的路径经过的黑结点数目相同（黑结点的数目称为该节点的黑高） 一棵有n个结点的红黑树的高度至多为2lg(n+1) 表示在二叉查找树的基础上每个结点加入color属性，表示结点的颜色。 认为所有的叶子结点都为NULL，就是指向空指针，颜色可以人为认为为黑色。 旋转子树的左旋转和右旋转是红黑树中的常用操作,分为左旋转和右旋转，如下图 1234567891011121314// 左旋转LEFT-ROTAET(T, p) y = p.right p.right = y.left if y.left != NULL y.left.p = p y.p = p.p if p.p == NULL T = y else if p == p.p.left p.p.left = y else p.p.right = y y.left = p p.p = y 右旋的代码和左旋的差不多，就是left换成right 查找红黑树的查找和二叉查找树的查找过程是一样的，由于一棵有n个结点的红黑树的高度至多为2lg(n+1)，所以查找的时间复杂度为Olg(n) 插入红黑是的插入而二叉查找树的插入是一样的，但是插入到红黑树的节点的颜色赋值为RED，这样有可能会破坏红黑树的性质，需要进行后续的修复。 123TREE-INSERT(T, z)z.color = REDRB-INSERT-FIXUP(T, z) 修复之所以需要修复是因为将插入的节点颜色变为红色，可能会违反红黑树的性质，需要修复的情况只会出现在插入的点是根节点或者插入节点的父节点是红色，违反了红黑树的第二条和第四条性质。如果插入的节点父节点是黑色，不会违反任何性质。 插入修复分四种情况： 情况1：如果插入为根节点 情况2：如果当前结点的父结点是红色且祖父结点的另一个子结点（叔叔结点）是红色 情况3：当前节点的父节点是红色,叔叔节点是黑色，当前节点是其父节点的右子 情况4：当前节点的父节点是红色,叔叔节点是黑色，当前节点是其父节点的左子 123456789101112131415161718RB-INSERT-FIXUP(T, z) while z.p.color == RED if z.p == z.p.p.left y = z.p.p.right //y始终指向其叔叔节点 if y.color == RED z.p.color = BLACK //Case 2 y.color = BLACK //Case 2 z.p.p.color = RED //Case 2 z = z.p.p //Case 2 else if z == z.p.right z = z.p //Case 3 LEFT-ROTATE(T, z) //Case 3 z.p.color = BLACK //Case 4 z.p.p.color = RED //Case 4 RIGHT-ROTATE(T, z.p.p) //Case 4 else (same as then clause with "right" and "left" exchanged) // 如果当前节点的父节点是祖父节点的右节点，情况一样，调换left和right即可 T.root.color ← BLACK //Case1 如果插入为根节点 直接将其颜色改为黑色即可，代码的最后一句 如果当前结点的父结点是红色且祖父结点的另一个子结点（叔叔结点）是红色 当前节点的父节点和叔叔节点涂黑，祖父结点涂红，由于把祖父节点变红，这样又是一个将节点变红需要修复问题，所有针对祖父节点再次判断情况（z指向z的祖父重新进入循环）。 12345if y.color == RED z.p.color = BLACK //Case 2 y.color = BLACK //Case 2 z.p.p.color = RED //Case 2 z = z.p.p //Case 2 示意图插入节点4 当前节点的父节点是红色,叔叔节点是黑色，当前节点是其父节点的右子 当前节点的父节点做为新的当前节点，以新当前节点为支点左旋。这样就会将该情况转为情况4 示意图：再插入节点4后经过情况2的处理，转为对4的祖父进行修复，进入当前(情况3)修复，转为情况4 当前节点的父节点是红色,叔叔节点是黑色，当前节点是其父节点的左子 父节点变为黑色，祖父节点变为红色，在祖父节点为支点右旋 示意图由情况三旋转转为当前情况后处理 删除红黑树的删除和二叉查找树的删除几乎相同，不同的是需要处理颜色，当删除节点无左子树或右子树时，直接删除，而当删除节点有左子树和右子树时，需要将后继节点代替删除节点，同时颜色赋值为删除节点的颜色，后继节点直接删除，相当于删除的是后继节点。 当删除的节点（当删除节点有左子树和右子树时，删除的是其后继节点）颜色是黑色时需要修复，因为删除黑色的节点必定会破坏性质5，除非树中只有一个根节点。 修复123456789101112131415161718192021222324RB-DELETE-FIXUP(T, x)while x != T and x.color == BLACK if x == x.p.eft w = x.p.right if w.color == RED color[w] = BLACK //Case 1 x.p.color = RED //Case 1 LEFT-ROTATE(T, x.p) //Case 1 w = x.p.right //Case 1 if w.left.color = BLACK and w.right.color = BLACK w.color = RED //Case 2 x = p[x] //Case 2 else if w.right.color = BLACK w.left.color = BLACK //Case 3 w.color = RED //Case 3 RIGHT-ROTATE(T, w) //Case 3 w = right[p[x]] //Case 3 w.color = color[p[x]] //Case 4 x.p.color = BLACK //Case 4 w.right.color = BLACK //Case 4 LEFT-ROTATE(T, p[x]) //Case 4 x = T //Case 4 else (same as then clause with "right" and "left" exchanged) x.color = BLACK “我们从被删节点后来顶替它的那个节点开始调整，并认为它有额外的一重黑色。这里额外一重黑色是什么意思呢，我们不是把红黑树的节点加上除红与黑的另一种颜色，这里只是一种假设，我们认为我们当前指向它，因此空有额外一种黑色，可以认为它的黑色是从它的父节点被删除后继承给它的，它现在可以容纳两种颜色，如果它原来是红色，那么现在是红+黑，如果原来是黑色，那么它现在的颜色是黑+黑。有了这重额外的黑色，原红黑树性质5就能保持不变。现在只要恢复其它性质就可以了，做法还是尽量向根移动和穷举所有可能性。”–saturnman。 先解决两种简单的情况： 当前节点颜色是红+黑，直接将该节点改为黑色 当前节点颜色是黑+黑且是根节点， 那么就可以结束 接下里重点解决下面三种情况： 情况1：当前节点颜色是黑+黑且兄弟节点为红色(此时父节点和兄弟节点的子节点分为黑) (01) 将兄弟节点设为黑色。 (02) 将父节点设为红色。 (03) 对父节点进行左旋。 (04) 左旋后，重新设置兄弟节点为新的当前节点。 这样做可以将情况1转为情况2、3或4 示意图： 情况2：当前节点颜色是黑+黑且兄弟是黑色且兄弟节点的两个子节点全为黑色 (01) 将兄弟节点设为红色。 (02) 设置父节点为新的当前节点 示意图： 情况3：当前节点颜色是黑+黑，兄弟节点是黑色，兄弟的左子是红色，右子是黑色 (01) 将兄弟节点的左孩子设为“黑色”。 (02) 将兄弟节点设为“红色”。 (03) 对兄弟节点进行右旋。 (04) 右旋后，重新设置兄弟节点为新的当前节点。 示意图： 情况4：当前节点颜色是黑+黑色，它的兄弟节点是黑色，但是兄弟节点的右子是红色，兄弟节点左子的颜色任意 (01) 将父节点的颜色赋值给 兄弟节点。 (02) 将父节点设为黑色。 (03) 将兄弟节点的右子节点设为黑色。 (04) 对父节点进行左旋。 (05) 把根节点设置成新的当前节点，处理完毕 示意图： 红黑树的复杂度一棵有n个结点的红黑树的高度至多为2lg(n+1)，因此查找的时间复杂度为O(lg n) 红黑树在最坏情况下基本动态集合操作的时间复杂度是O(lgn) 红黑树与AVL树（平衡二叉树）AVL树是严格的平衡二叉树，必须满足左右子树的高度差不超过1，因此维持平衡的代价要高于红黑树，但是由于AVL树的平衡性好于二叉树，因此在查找方面要由于红黑树。 因此如果插入删除不频繁，只是对查找要求较高，那么AVL是较优于红黑树的。 如果插入删除较为频繁，红黑树维持平衡的代价要远小于AVL树，红黑树具有优势。 参考《算法导论》 https://zh.wikipedia.org/wiki/%E7%BA%A2%E9%BB%91%E6%A0%91 https://my.oschina.net/edwardge/blog/1833893 https://blog.csdn.net/v_july_v/article/details/6105630]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>红黑树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mapreduce过程-shuffle和sort]]></title>
    <url>%2Fmapreduce%E8%BF%87%E7%A8%8B-shuffle%E5%92%8Csort.html</url>
    <content type="text"><![CDATA[前言MapReduce作为Hadoop三大核心组件之一，是一种处理大数据的分布式运算框架。虽然当前优秀的分布式运算框架有很多，如spark,flink等，其有着MapReduce没有的流式处理模型，但是MapReduce在批量计算有着独有的优势，了解其内部的运行机制，对于大数据处理技术人员和学习人员都着重要的意义。 MapReduce从其名字上可以看出，有Map和Reduce两个步骤，确实在MapReduce中分map端和reduce端，而连接着map端和reduce端的操作就是shuffle。接下来将详细介绍map端和reduce端以及shuffle，来了解Mapreduce是如何处理数据。（其中将不和涉及到Mapreduce任务是如何提交，启动，如何分配资源执行MapReduce任务，因为在hadoop2.0之后引入了资源调度框架yarn，这些事情已经全部都交yarn，MapReduce作业运行机制将在yarn中讲解。这里只讲MapReduce如何处理数据）。可以看到其过程的官方描述图如下 文件输入文件的切分MapReduce的输入文件，即处理数据，一般是存储在HDFS上，在将其输入到Map进行处理之前，会有一步文件切分的动作，将文件切分成多片（split），这将决定map的数量。因为一个MapReduce的任务会有很多个map，map的数量并不是由集群由多少台机器或者机器的配置决定的，而是由输入分片split的数量决定，一个split由一个map来处理，每一个map操作只处理一个输入分片。默认的split大小就是HDFS的block大小，也就是默认情况下，文件在HDFS上占多少个block，对其用MapReduce处理时就有多少个map。 用户可以通过调整分片大小来改变分片的数量，从而决定map的数量。分片大小的计算方式，可以在FileInputFormat的computeSplitSize()方法中看到： max(minsize, min(maxsize, blockSize)) 式子里的参数分别由三个配置参数设置： 参数 配置参数 类型 默认值 minsize mapreduce.input.fileinputformat.split.minsize int 1 maxsize mapreduce.input.fileinputformat.split.maxsize long Long.MAX_VALUE blockSize dfs.blocksize Long 128M 文件的切分并不是实际上把文件拆成一个个小文件，而是split其实就是记录文件块所在的host位置及其起始和末尾偏移量。 host选择文件切分之后，为了避免文件和map在不同机器上需要通过网络传输文件，需要选择合适的host，因为map在执行时会尽量选择本地的split数据处理，因此选择合适的host尤其重要。 但是由于split可能不会等于block的大小，一个split可能会分布在不同的block上，所以无法完全做到map处理本地数据。 host选择的原则是优先让空闲资源处理本节点上的数据，如果节点上没有可处理的数据，则处理同一个机柜上的数据，最坏的情况是处理其他机柜上的数据（当然必须在同一数据中心）。 host选择算法具体可以看： https://blog.csdn.net/xingliang_li/article/details/53285447 《Hadoop技术内幕-深入解析MapReduce架构设计与实现原理》 Map端Map端根据输入的数据和用户定制的map函数处理数据，默认采用TextInputFormat，按行记录迭代调用map函数。经map函数处理完的数据（通过context.write(key,value)输出）会经过partition方法产生一个对应到reduced的分区号，将&lt;key,value,numPartitions&gt;输出到一个环形缓冲区中。 PartitionPartition的作用是对map的输出结果计算一个分区号，标记输出数据应该对应到哪一个Reduce来处理。默认的Partiton是HashPartition，对map输出的key取hash值，再对reduce的数量取模。 Partition方法可以通过Job.setPartitionerClass(Class&lt;? extends Partitioner&gt; cls)的方法设定自定义的Partition类，继承Partitioner类，覆盖getPartition方法即可。 环形缓冲区（也是内存缓冲区）环形缓冲区的默认大小为100M,可以通过参数mapreduce.task.io.sort.mb来调整其大小，当缓冲区中被放入数据达到一定的阈值（默认为缓冲区大小的80%，通过mapreduce.map.sort.spill.precent设置）就会启动一个后台线程将内容溢写spill到磁盘中。在spill到磁盘的过程中，map的输出还会持续的写入的缓冲区中，如果此时map写入过快，spill还未完成，缓冲区已经满了，就会发生阻塞知道spill完成。 spillspill是当环形缓冲区中数据到达阈值时，写入到磁盘的过程。在写入磁盘之前，需要按照分区号numPartition对数据进行分组，每一组的分区号相同，对于每一组的中的数据按照key值进行排序，这次排序采用的快速排序，因此spill到磁盘的数据应该是分好组，按照组排下来，每一组中的元素是按照key排序好的。 每次spill就会产生一个分组排序好的spill文件，这样一次map可能会产生多个spill文件，但是最后一个map的输出之后产生一个文件，因此在map结束之后需要对所有的spill文件进行一次merge。 merge将一个map从环形缓冲区spill到磁盘中，一个map可能产生多个spill文件，需要经过merge产生一个文件。考虑到分区号是数据交给哪个reduce的凭证，因此merge之后的单个文件也是分组排序好的，组中的元素分区号相同，并且按照key排序。因此merge是按照分区号对多个文件按照归并排序进行排序，归并一个能合并多个文件，最多合并的文件个数默认是10个，由配置参数mapreduce.task.io.sort.factor控制。 Combine如果设置过Combine，combine的触发主要发生在两个地方： spill按照分区号分组排序号之后，将要写入到磁盘之前会触发一次combine 如果至少存在3个spill文件（通过mapreduce.map.combine.minspills设置），则会在marge的过程中触发combine combine的数据处理方法和reduce相同，对key值相同的数据调用combie方法，combine可以提前合并一部分数据，减少数据的产生传输，为reduce处理减轻压力。 Reducd端拉取合并map产生的输出的文件存储于运行map任务的tasttracker的本地磁盘中（hdfs中），reduce需要启动线程通过HTTP方式从map的输出文件中按照reduce对于的分区号复制数据，默认是5个线程（通过mapreduce.reduce.shuffle.parallelcopies设置），不需要等到map全部完成才启动复制线程，默认map完成数大于map任务总数的5%时即可开始启动复制线程，从已经完成的map任务输出的文件复制数据。复制的数据同样是放入缓冲区中。 内存缓冲区reduce端的内存缓冲区不像map端的内存缓冲区，没有固定的大小，其大小与reduce任务的jvm的最大heap的大小有关（通常通过mapred.child.java.opts来设置，比如设置为-Xmx1024m），默认其大小为最大heap的70%（通过mapreduce.reduce.shuffle.input.buffer.percent设置），所以缓冲区大小等于maxHeap of reduce * precent。 一旦缓冲区达到了阈值（通过mapreduce.reduce.shuffle.merge.precent设置）或者map输出的阈值（通过mapreduce.reduce.merge.inmem.threshold设置）就会发生spill,将数据写入磁盘。 merge由于存在多个map端的输出数据，因此需要将其merge成一个reduce输入，这里的merge指的就是合并多个map的输出。其主要发生在两个地方，当缓冲区达到阈值需要spill时，这个spill中需要merge，merge按照归并排序将多个map端的数据排序好输出到磁盘，如果有combine，combine会在写入到磁盘前触发。随着磁盘上文件增大，后台会启动线程将多个spill文件合并成更大，排序好的文件。当所有的map输出都传输完毕，就需要将所有的spill文件merge合并成一份reduce输入，和map相同，采用多路归并排序，在发生最后一次归并排序时是不落盘，直接将其结果输入到reduce中，减少一次落盘操作。 最后就是将输入给reduce，reduce的输出直接落盘到HDFS中结束。 shuffle上述过程只有Map端和Reduce端，为什么没有Shuffle，其实Shuffle就是执行map方法输出数据到reduce方法输入数据这中间的一系列过程，包括map端的spill、merge，Reduce端的拉取合并、merge等，Shuffle实际上是与Map和Reduce的过程交叉存在的。 参考MapReduce之Shuffle过程详述 《Hadoop权威指南》]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[关于动态规划的想法]]></title>
    <url>%2F%E5%85%B3%E4%BA%8E%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E7%9A%84%E6%83%B3%E6%B3%95.html</url>
    <content type="text"><![CDATA[前言动态规划是经常用到的算法，一般是通过递推，将一个复杂的问题分解为简单的最小问题求解，即存在着最优子结构。从求解子问题一步步推出原始问题的解。我将目前遇到的动态规划的问题按照开辟数组的维度分为一维和二维两类，背包问题不属于这类，因为背包问题相关的问题也是通过动态规划，但是比较复杂，单独放在外面。以上是我个人对于遇到的动态规范的分类，纯属个人想法，还有树形动态规划，后续遇到会加入进去。 一维这里的一维也可以理解为递推，即一个问题的求解一般根据其前一个子问题或前两子问题来的。 比如Fibonacci数列，LeetCode 70等。 以Fibonacci数列为例，$f(n) = f(n-1) + f(n-2)$,其中$f(1) = f(2) = 1$。这种问题一般通过递归自顶向下或者循环自底向上求解。如求Fibonacci数列的$f(n)$ 12345678910111213141516171819202122// 自顶向下，递归public long fibonacci(int n)&#123; if(n &lt;= 2)&#123; return 1; &#125;else&#123; return fibonacci(n-1) + fibonacci(n-2) &#125;&#125;// 自底向上public long fibonacci(int n)&#123; if(n &lt;= 2)&#123; return 1; &#125; long p = 1;q = 1; for(int i = 3;i &lt;= n;i++)&#123; int tmp = q; q = p + q; p = tmp; &#125; return q;&#125; 当然在递归时存在着重复计算，如$f(n-1)$需要计算0到n-2的所有子结果，而$f(n-2)$需要计算0到n-3的所有子结果，存在着0到n-3的子问题的重复计算。因此可以使用备忘录的形式，即开辟数组记录已经计算过的$f(n)$值。 12345678910111213141516171819// 修改之后的递归public long fibonacci(int n)&#123; long[] memo = new long[n+1]; for(int i = 0;i &lt;= n;i++)&#123; memo[i] = -1; &#125; return recursion(n);&#125;public long recursion(int n)&#123; if(n &lt;= 2)&#123; return 1; &#125; if(memo[n] != -1)&#123; return memo[n]; &#125; memo[n] = fibonacci(n-1) + fibonacci(n-2); return memo[n];&#125; 二维二维下的动态规划，也可以看做是区间dp，一般是将问题从最小的区间开始，不断扩展，从已知的几个相邻区间推到出现区间的值。 数组从上向下或从左往右扩展如字符串的编辑距离的求解,一开始得到各自空字符串的编辑距离（二维数组第0行和第0列），接着根据当前比较两个字符的情况和已知的区间（数组中的左元素、上元素和左上元素）得到当前区间的值。 如简单正则表达式匹配,假设$d[i][j]​$表示p字符模式从0到i的子串和s字符串从0到j的子串的匹配结果。 如果$p[i]=’*’ \&amp;\&amp;p[i-1] = s[j]$，$d[i][j]=d[i-1][j]||d[i-2][j] || d[i][j-1]$ 如果$p[i]=’*’ \&amp;\&amp;p[i-1]\neq s[j]​$，$d[i][j]=d[i-1][j]||d[i-2][j]​$ 如果$p[i]=’.’ ||p[i] ==s[j]$，$d[i][j]=true$ 不满足上述情况的，$d[i][j]=false$ 实现代码如下：s 123456789101112131415161718192021222324252627282930313233343536373839public boolean isMatch(String s, String p) &#123; boolean[][] isMacth = new boolean[p.length()+1][s.length()+1]; isMacth[0][0] = true; for(int i = 1; i &lt;= s.length();i++)&#123; isMacth[0][i] = false; &#125; for(int i = 1; i &lt;= p.length();i++)&#123; if(p.charAt(i-1) == '*')&#123; isMacth[i][0] = isMacth[i-2][0]; &#125;else &#123; isMacth[i][0] = false; &#125; &#125; for(int i = 1;i &lt;= p.length();i++)&#123; if(p.charAt(i-1) == '*')&#123; for(int j = 1; j &lt;= s.length();j++)&#123; if(compare(p.charAt(i-2), s.charAt(j-1)))&#123; isMacth[i][j] = isMacth[i][j-1]; &#125; isMacth[i][j] = isMacth[i-1][j] || isMacth[i-2][j] || isMacth[i][j]; &#125; &#125;else &#123; for(int j = 1; j &lt;= s.length(); j++)&#123; if (compare(p.charAt(i-1), s.charAt(j-1)))&#123; isMacth[i][j] = isMacth[i-1][j-1]; &#125;else &#123; isMacth[i][j] = false; &#125; &#125; &#125; &#125; return isMacth[p.length()][s.length()];&#125;public boolean compare(char a, char b)&#123; if(a == '.')&#123; return true; &#125;else return a == b;&#125; 数组从中间向左上或右下扩展如最长回文子串,假设$p[i][j]$表示字符串第$i$个字符到第$j$个字符之间的子串是否为回文子串，其递推公式为：$$p[i][j] = \begin{cases}true \quad(s[i] == s[j]\quad and\quad p[i+1][j-1] = true)\quad or \quad j-i == 1\\false \quad other\\\end{cases}$$如果$p[i][j]$为真且长度大于当前最大长度则记录长度和起始位置。 1234567891011121314151617181920212223242526public String longestPalindrome(String s) &#123; if(s == null || s.length() &lt;= 1)&#123; return s; &#125; boolean[][] p = new boolean[s.length()][s.length()]; p[s.length()-1][s.length()-1] = true; int l = 0, start = 0; for(int i = s.length()-2;i &gt;= 0;i--)&#123; p[i][i] = true; for(int j = i+1; j &lt; s.length();j++)&#123; if(s.charAt(i) == s.charAt(j))&#123; if((j-i) == 1)&#123; p[i][j] = true; &#125; if(p[i+1][j-1])&#123; p[i][j] = true; &#125; &#125; if(p[i][j] &amp;&amp; j - i &gt; l)&#123; l = j - i; start = i; &#125; &#125; &#125; return s.substring(start, start+l+1);&#125; 背包问题0-1背包问题及其相关的问题可以看大牛的《背包九讲》，里面写的很详细。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读HashMap源码]]></title>
    <url>%2F%E8%AF%BBHashMap%E6%BA%90%E7%A0%81.html</url>
    <content type="text"><![CDATA[前言HashMap是Java中常用的数据结构，是集合类中的重要存在，其中包含了散列表、链表和红黑树。散列表解决冲突的方法是链地址法，即将散列值相同的元素存放在一个链表中。当冲突过多，链表过长会造成查找效率降低，因此java8中在HashMap中引入红黑树进行优化，当某个散列值下的链表长度过长（长度大于8），会将其转变为红黑树存储，优化查询。涉及到红黑树的操作不会再这里细讲 源码解读构造函数123456789101112131415161718192021222324252627282930313233343536373839404142434445// 默认初始化容量static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4;// 最大容量static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;// 负载因子static final float DEFAULT_LOAD_FACTOR = 0.75f;final float loadFactor;//容量阈值int threshold;public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR;&#125;public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125;public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false);&#125;public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);&#125;// 返回刚好大于cap的2的n次方的值static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; initialCapacity: 初始容量 loadFactor：负载因子 threshold：容量阈值，当HashMap的存储的元素达到该值时，就会触发扩容操作 capatcity在源码中没有定义变量记录是因为其大小为table数组的长度，阈值threshold的大小由capatcity和loadFactor来决定，threshold=capatcity*loadFactor HashMap的构造函数主要是设置初始化容量和负载因子，如果采用无参数构造函数，则使用默认的初始化容量16和负载因子0.75。当采用设置了初始化容量的构造函数时，就会调用tableSizeFor方法，该方法通过位运算的方法得到一个2的n次方，该值刚好大于cap,即当用户指定一个初始化容量为2的n次方的值，实际HashMap的阈值赋值为大于该值的一个2的n次方的值，在初始化的时候，其首先按照threshold的大小开辟数组，接着经过一次赋值threshold=threshold*loadFactor（后文resize方法中可以看到）改变threshold的大小，符合上述的说法。 基本存储单元HashMap的散列表是一个数组table，其中的元素是Node类，该类继承了Map.Entry接口，其中包含了key,value,hashCode和next(存储链表中下一跳)。在java8之前是内置的Entry类，而在java8中Entry类变成了Node类。 123456789101112131415161718192021222324252627282930313233343536373839static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + "=" + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125;&#125; 红黑树中节点TreeNode 123456789101112131415161718192021222324252627282930static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; parent; // red-black tree links TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right; TreeNode&lt;K,V&gt; prev; // needed to unlink next upon deletion boolean red; TreeNode(int hash, K key, V val, Node&lt;K,V&gt; next) &#123; super(hash, key, val, next); &#125; /** * Returns root of tree containing this node. */ final TreeNode&lt;K,V&gt; root() &#123; for (TreeNode&lt;K,V&gt; r = this, p;;) &#123; if ((p = r.parent) == null) return r; r = p; &#125; &#125; // 省略后面红黑树增删，调整等方法 ...&#125;static class Entry&lt;K,V&gt; extends HashMap.Node&lt;K,V&gt; &#123; Entry&lt;K,V&gt; before, after; Entry(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; super(hash, key, value, next); &#125;&#125; 可以看到TreeNode继承LinkedHashMap.Entry，而LinkedHashMap.Entry是继承HashMap.Node,所以TheeNode是HashMap.Node的子类，对于HashMap的元素普遍操作（如遍历）都可以转为对Node的操作，无需判断table中存储从是链表还是红黑树。 查找123456789101112131415161718192021222324252627282930313233343536373839404142public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;/* * 这里将高16位和低16位进行异或运算，使产生的低16位的产生受到高16位和低16位共同 * 影响，避免当HashMap的capacity过小时，产生的散列值只受到低16位影响，同时也会增加 * hash的复杂度，当HashMap中放入hashCode分布不佳的元素，可以通过这种hash计算方法，降低 * 散列表的冲突率。 */static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;/** * HashMap中判断元素是相等，必须hash值和元素equals()方法都判断为相等 * 因为hash值不仅在查找中使用，判断元素相等时也作为一个判断依据 */final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; // （n-1）&amp; hash取的是余数即：hash%(n-1)，位运算取余的效率更高 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; //如果是红黑树，则用红黑树递归方法寻找 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); //否则用链表的方式寻找 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; (n-1)&amp; hash是用位运算计算hash%(n-1),确定key在哈希表中的位置。其hash值的运算不是直接采用HashCode，而是通过HashCode重新计算，因为当table表长度小，其散列值的产生只有低位有关，与高位无关，若加入的元素产生的hashCode低位比较相似，高位不同，则会造成大量冲突。因此将高16位与低16位做异或运算，使hash值低位受HashCode影响，使散列值分布均匀。 遍历HashMap的遍历经常是通过遍历keySet和entrySet方法产生的Set来实现的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687public Set&lt;K&gt; keySet() &#123; Set&lt;K&gt; ks = keySet; if (ks == null) &#123; ks = new KeySet(); keySet = ks; &#125; return ks;&#125;final class KeySet extends AbstractSet&lt;K&gt; &#123; public final int size() &#123; return size; &#125; public final void clear() &#123; HashMap.this.clear(); &#125; public final Iterator&lt;K&gt; iterator() &#123; return new KeyIterator(); &#125; public final boolean contains(Object o) &#123; return containsKey(o); &#125; public final boolean remove(Object key) &#123; return removeNode(hash(key), key, null, false, true) != null; &#125; public final Spliterator&lt;K&gt; spliterator() &#123; return new KeySpliterator&lt;&gt;(HashMap.this, 0, -1, 0, 0); &#125; public final void forEach(Consumer&lt;? super K&gt; action) &#123; Node&lt;K,V&gt;[] tab; if (action == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) &#123; int mc = modCount; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) action.accept(e.key); &#125; if (modCount != mc) throw new ConcurrentModificationException(); &#125; &#125;&#125;final class KeyIterator extends HashIterator implements Iterator&lt;K&gt; &#123; public final K next() &#123; return nextNode().key; &#125;&#125;abstract class HashIterator &#123; Node&lt;K,V&gt; next; // next entry to return Node&lt;K,V&gt; current; // current entry int expectedModCount; // for fast-fail int index; // current slot HashIterator() &#123; expectedModCount = modCount; Node&lt;K,V&gt;[] t = table; current = next = null; index = 0; // next指到第一个不为空的数组元素 if (t != null &amp;&amp; size &gt; 0) &#123; // advance to first entry do &#123;&#125; while (index &lt; t.length &amp;&amp; (next = t[index++]) == null); &#125; &#125; public final boolean hasNext() &#123; return next != null; &#125; final Node&lt;K,V&gt; nextNode() &#123; Node&lt;K,V&gt;[] t; Node&lt;K,V&gt; e = next; if (modCount != expectedModCount) throw new ConcurrentModificationException(); if (e == null) throw new NoSuchElementException(); if ((next = (current = e).next) == null &amp;&amp; (t = table) != null) &#123; do &#123;&#125; while (index &lt; t.length &amp;&amp; (next = t[index++]) == null); &#125; return e; &#125; public final void remove() &#123; Node&lt;K,V&gt; p = current; if (p == null) throw new IllegalStateException(); if (modCount != expectedModCount) throw new ConcurrentModificationException(); current = null; K key = p.key; removeNode(hash(key), key, null, false, false); expectedModCount = modCount; &#125;&#125; 可以看到keySet的迭代器继承HashIterator，其中KeyIterator的next方法直接调用了HashIterator的nextNode方法，nextNode是通过遍历table找到不为null的元素，接着再调用Node的next，不断从链表中遍历元素，但是其中冲突可能会用红黑树存储，对于红黑树的遍历并没有描写。这是因为上文讲到红黑树的TreeNode继承了Node，TreeNode的next存储着红黑树遍历下一跳的元素，所以只要调用Node类的next就可以遍历链表和红黑树，下文会看到ThreeNode的next的建立。 插入除去红黑树的操作，插入是HashMap较为复杂的方法，因为其设计到table的扩容，链表转为红黑树等问题，先来看代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657static final int TREEIFY_THRESHOLD = 8;public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //如果table为空，则初始化table,延迟到插入元素时进行初始化 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //如果不存在冲突，直接放入将节点放入数组中 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; // 如果头结点key相等，将头结点赋值给e if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) // 如果是红黑树，调用树的插入操作 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; // 否则为链表，遍历 for (int binCount = 0; ; ++binCount) &#123; // 遍历到尾部，插入到链表的最后一个元素 if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); // 当链表长度大于8时，变为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; // 存在相同的key，则将其赋值给e if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; // e不为空说明是替换掉相同key下的值，返回 if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; // 如果容量大于阈值，则需进行扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; 可以看到table是在插入的时候进行判断有无进行初始化并对其初始化，初始化和扩容都是调用resize方法，整个插入过程是首先检查是否初始化，无则进行初始化，接着根据插入元素的hash的散列值找到数组中的位置，如果不存在冲突则直接存入，如果是链表，则遍历链表，如果是红黑树，则遍历树，对其已存在的key，替换value，不存在则插入到链表尾部或者红黑树中。其中在插入到链表只若容量大于8，则需要将链表转为红黑树。 12345678910111213141516171819202122232425static final int MIN_TREEIFY_CAPACITY = 64;/* * 将链表转为红黑树，只有当链表长度大于8&amp;&amp;table的容量大于64时才会触发树化 */final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K,V&gt; e; if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123; TreeNode&lt;K,V&gt; hd = null, tl = null; do &#123; TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); if (tl == null) hd = p; else &#123; p.prev = tl; tl.next = p; &#125; tl = p; &#125; while ((e = e.next) != null); if ((tab[index] = hd) != null) hd.treeify(tab); &#125;&#125; 转为红黑树过程中，建立了next和prev的指向，即建立好的红黑树后，结点之间通过next和prev可以遍历整颗树，这也是遍历过程值中不需要考虑红黑树的原因，如何建立红黑树，这里不细讲，下次分析红黑树中再讲。 接着来看resiz方法怎么来初始化和扩展table。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; // 判断长度是否大于0，长度为0的表示为被初始化 if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; // 初始化指定的初始化容量 else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 当table为空时，需要初始化table，将如果指定了初始化容量，则其threshold做初始化长度，接着将threshold赋值为threshold*loadFactor，否则直接按照默认table长度为16，负载因子为0.75，阈值为16*0.75。如果已经初始化，则要对其进行扩容，将容量扩充为原来的两倍，扩充之后需要对散列表中的元素重新分配，在重新分配在java7是直接遍历元素进行重新计算散列值，但是在java8中进行了优化，将需要分配的链表或者红黑树分成两个链表，分别放入各自在新的表位置中。可以看到在代码中loHead和loTail、hiHead和hiTail分别是两个链表的头结点和尾结点，这里称为lo链表和hi链表，旧散列表中同一个链表中的元素按照hash值和旧表容量进行与运算，判断是否为0分为两类，放入两个链表中，最后两个链表分别放入新表的位置中。 其中的原理可以通过一个例子说明，假设一个HashMap，table容量为8，在余数为2的链上有key的hash值为2、10、18、26的元素。一开始元素确定在table中的位置是通过与n-1（例子中为7）取余的方式。$$n-1:00000111\\2\qquad:0000 0010\\result:00000010\\\quad\\n-1:00000111\\10\quad:0000 1010\\result:00000010$$扩展容量后为16，则其确定在散列表的中的位置同样与容量与运算（n-1变为15），如果重新与运算的话$$n-1:00001111\\2\qquad:0000 0010\\result:00000010\\\quad\\n-1:00001111\\10\quad:0000 1010\\result:00001010$$仔细观察的话，其实后三位的取与结果是一样的，不同的只有第四位上计算不同，而这取决于hash在第四位是0还是1，因此其实只要得到hash值的第四位是0还是1，就可以决定放入表中的位置。如果是0的话还是旧的位置，如果是1的话，则新位置为旧的位置加上8（2的3次方）。而确定第四位的值，只需要将hash值与旧容量值（8：0000 1000）取与运算就能得到 因此只需与oldCap取与运算，判断是否为0分两个链表，0的链表维持原来的位置，1的则加上oldCap的值作为新位置 对于红黑树的分裂放入方法也差不多 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950static final int UNTREEIFY_THRESHOLD = 6;sfinal void split(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, int index, int bit) &#123; TreeNode&lt;K,V&gt; b = this; // Relink into lo and hi lists, preserving order TreeNode&lt;K,V&gt; loHead = null, loTail = null; TreeNode&lt;K,V&gt; hiHead = null, hiTail = null; int lc = 0, hc = 0; for (TreeNode&lt;K,V&gt; e = b, next; e != null; e = next) &#123; next = (TreeNode&lt;K,V&gt;)e.next; e.next = null; if ((e.hash &amp; bit) == 0) &#123; if ((e.prev = loTail) == null) loHead = e; else loTail.next = e; loTail = e; ++lc; &#125; else &#123; if ((e.prev = hiTail) == null) hiHead = e; else hiTail.next = e; hiTail = e; ++hc; &#125; &#125; if (loHead != null) &#123; // 当链表长度小于等于6时，变成链表 if (lc &lt;= UNTREEIFY_THRESHOLD) tab[index] = loHead.untreeify(map); else &#123; tab[index] = loHead; // 当loHead为空的时候，表明所有元素全部在hiHead链表上，已经是一棵调整好的红黑树 if (hiHead != null) // (else is already treeified) loHead.treeify(tab); &#125; &#125; if (hiHead != null) &#123; if (hc &lt;= UNTREEIFY_THRESHOLD) tab[index + bit] = hiHead.untreeify(map); else &#123; tab[index + bit] = hiHead; if (loHead != null) hiHead.treeify(tab); &#125; &#125;&#125; 删除删除操作比较简单，相当于在查找的基础上删掉该元素。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public V remove(Object key) &#123; Node&lt;K,V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; else if ((e = p.next) != null) &#123; if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p) tab[index] = node.next; else p.next = node.next; ++modCount; --size; afterNodeRemoval(node); return node; &#125; &#125; return null;&#125; 在jdk8和jdk7中的区别 jdk8中引入了红黑树，将链表长度超过8的转变为红黑树，jdk7中则只使用链表 jdk8中元素插入链表在链表的尾部，而jdk7中是插入到头部，jdk8将其插入到尾部并加入红黑树，解决了jdk7的HashMap在多并发下扩容时会陷入链表成环的问题 Jdk8在扩容重新分配时使用了新的方法，与就容量取与运算结果分为两个链表或树，而jdk7是重新计算hash取余的结果 非默认序列化HashMap 并没有使用默认的序列化机制，table变量被transient修饰，无法序列化，而是通过实现readObject/writeObject两个方法自定义了序列化的内容，因为序列化 talbe 存在着两个问题： table 多数情况下是无法被存满的，序列化未使用的部分，浪费空间 同一个键值对在不同 JVM 下，所处的桶位置可能是不同的，在不同的 JVM 下反序列化 table 可能会发生错误。 在不同的jvm下会有不同的HasCode，直接序列化生产对于后续加入元素会产生错误。 参考HashMap 源码详细分析(JDK1.8) - 个人文章 - SegmentFault 思否 HashMap为何从头插入改为尾插入 - 掘金]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ambaria安装HDP]]></title>
    <url>%2Fambaria%E5%AE%89%E8%A3%85HDP.html</url>
    <content type="text"><![CDATA[前言Hadoop的生态非常的庞大，如果要对其一一搭建，并配置好相应的配置文件，需要耗费很大的精力和时间。利用Ambari + HDP能帮助我们快速搭建Hadoop平台，同时Ambari提供了监控集群的功能，能在其上面方便的添加Hadoop生态的组件以及相关的分布式框架，如spark,kafka等等。 按照环境 五台Centos7的机器 java 8 python 2.7 安装HDP 3.1和ambari 2.7.3 官方的安装文档 如果之前有ambari和hdp的环境需要重装，则重装之前需要先清理环境，参考网上的一遍博客：完全卸载HDP和Ambari 首先机器之间需要免密登陆，免密的登陆操作这里就不细说了，网上有很多教程，在安装之前最好保证机器之间时间同步，可以使用ntp服务使机器之间的时间同步，安装使用教程可以查看之前的博客：简单集群时间同步 本地仓库由于ambari和HDP的yum下载太慢，因此直接下载配置本地资源 如果没有http服务，需要先安装http服务 12yum install httpdservice httpd start 下载ambari和HDP仓库地址:Ambari Repositories、HDP 3.1.0 Repositories,下载ambari、HDP、HDP-UTILS、HDP-GPL的tat.gz的压缩包，解压文件到/var/www/html/下 在/etc/yum.repos.d/下，新建ambari.repo，添加内容 12345678[AMBARI]name=AMBARIbaseurl=http://10.1.18.221/ambari/centos7/2.7.3.0-139path=/enabled=1gpgcheck=1gpgkey=http://10.1.18.221/ambari/centos7/2.7.3.0-139/RPM-GPG-KEY/RPM-GPG-KEY-Jenkinspriority=1 新建HDP.repo，内容： 12345678[HDP-3.1]name=HDP-3.1baseurl=http://10.1.18.221/HDP/centos7/3.1.0.0-78path=/enabled=1gpgcheck=1gpgkey=http://10.1.18.221/HDP/centos7/3.1.0.0-78/RPM-GPG-KEY/RPM-GPG-KEY-Jenkinspriority=1 新建HDP-UTILS.repo，内容： 12345678[HDP-UTILS-1.1.0.22]name=HDP-UTILS-1.1.0.22baseurl=http://10.1.18.221/HDP-UTILS/centos7/1.1.0.22path=/enabled=1gpgcheck=1gpgkey=http://10.1.18.221/HDP-UTILS/centos7/1.1.0.22/RPM-GPG-KEY/RPM-GPG-KEY-Jenkinspriority=1 新建HDP-GPL.repo，内容： 1234567name=HDP-GPL-3.1.0.0baseurl=http://10.1.18.221/HDP-GPL/centos7/3.1.0.0-78path=/enabled=1gpgcheck=1gpgkey=http://10.1.18.221/HDP-GPL/centos7/3.1.0.0-78/RPM-GPG-KEY/RPM-GPG-KEY-Jenkinspriority=1 新建yum的缓存 12yum clean allyum makecache 安装Ambari首先需要关闭SELinux 1234567# 查看SELinux状态getenforce# 临时关闭（不用重启机器）setenforce 0# 修改配置文件永久关闭，需要重启机器vim /etc/selinux/config# 将SELINUX=enforcing改为SELINUX=disabled 关闭iptables 1234#停止firewallsystemctl stop firewalld.service#禁止firewall开机启动systemctl disable firewalld.service 安装ambari 1yum install -y ambari-server 配置初始化ambari 1ambari-server setup 配置安装的详细内容可以查看官方文档，以下的回应安装提示差不多是官方文档的翻译。 回应安装提示： 如果您尚未暂时禁用SELinux，则可能会收到警告。接受默认值（y），然后继续。 默认情况下，Ambari Server运行在root。(n)在Customize user account for ambari-server daemon提示符下接受默认值，继续root。如果要创建另一个用户来运行Ambari服务器，或者要分配以前创建的用户，请y在Customize user account for ambari-server daemon提示符处选择，然后提供用户名。 如果您尚未暂时禁用iptables，则可能会收到警告。输入y继续。 选择要下载的JDK版本。 输入1以下载Oracle JDK 1.8。默认情况下，Ambari Server安装程序会下载并安装Oracle JDK 1.8和随附的Java Cryptography Extension（JCE）策略文件 输入2需要提供自己安装的jdk的java_home路径 出现提示时，请查看GPL许可协议。要明确启用Ambari下载和安装LZO数据压缩库，不明白LZO的作用可以直接y，反正多安装不是什么坏处 选择n在 Enter advanced database configuration以使用Ambari的默认嵌入式PostgreSQL数据库。默认的PostgreSQL数据库名称是ambari。默认用户名和密码是ambari/bigdata。否则，要使用现有的PostgreSQL，MySQL / MariaDB或Oracle数据库与Ambari，请选择y。 启动登陆ambari 如果安装顺利，可以直接启动ambari 1ambari-server start 接着可以访问http://&lt;your.ambari.server&gt;:8080来登陆ambari,初始用户名和密码都是admin 点击Launch Install Wizard开始集群配置 集群配置填写集群名字 选择HDP的版本，在这一步由于搭建了本地源，所以使用本地源的URI 填入集群的各个节点的主机名，不是IP,要保证/etc/hosts能正常解析到各个节点,可以保持一份正确的配置，所有节点都使用相同的hosts文件 123456789cat /etc/hosts127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain610.1.18.221 master.hdu.edu.cn amdnode810.1.18.222 slave1.hdu.edu.cn node110.1.18.223 slave2.hdu.edu.cn node210.1.18.224 slave3.hdu.edu.cn node310.1.18.225 slave4.hdu.edu.cn node4 因此主机名填写如下 接着填好ambari所在主机的秘钥，进入下一步安装 接着选择安装的组件，配置组件，配置参数基本按照默认走，除了填写几个用户名和密码，就不细讲了。 建议：一开始最好不要安装大量组件，只把zookeeper,hdfs，yarn,mr2这些必要的组件安装，后期慢慢添加更多组件，如果一开始安装大量组件，需要一股脑解决大量问题，别问我怎么知道的。 安装过程中的错误 安装Hive Client报错“Failed to download file from http://master.hdu.edu.cn:8080/resources/mysql-connector-java.jar due to HTTP error: HTTP Error 404: Not Found” 解决方法：在master.hdu.edu.cn对应的节点下载关联好jdbc 1234yum install mysql-connector-java*ls -al /usr/share/java/mysql-connector-java.jarcd /var/lib/ambari-server/resources/ln -s /usr/share/java/mysql-connector-java.jar mysql-connector-java.jar 报错“ExecutionFailed: Execution of ‘ambari-python-wrap /usr/bin/hdp-select set xxx-client 3.1.0.0-78’ returned 1. symlink target /usr/hdp/current/xxx-client for tez already exists and it is not a symlink.” 解决方法，把软连接建立上去： 12rm -rf /usr/hdp/current/xxx-clientln -s /usr/hdp/3.1.0.0-78/xxx /usr/hdp/current/xxx-client 按照过程中最好联网，虽然建立了HDP的本地源，但是有些还是通过yum从远程仓库获取，如mariadb-server等 按照过程中会有很多错误，基本是查看错误的日志，排除错误原因，如yum安装不上，可以采用手动安装；缺少文件，可以从其他成功安装的集群获取文件；文件权限不对，无法读取，手动设置好需要的权限等。]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Ambari</tag>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop的搭建]]></title>
    <url>%2FHadoop%E7%9A%84%E6%90%AD%E5%BB%BA.html</url>
    <content type="text"><![CDATA[前言Hadoop的搭建此次分为伪分布式和分布式，伪分布式分为windows和mac Os、Linux 伪分布式Hadoop的伪分布式搭建需要提前安装好jdk1.8，选用hadoop3.0.0版本，官方提供的二进制和源码下载网址：https://archive.apache.org/dist/hadoop/common/hadoop-3.0.0/ ，此次的搭建使用二进制包安装，不涉及源码的编译，所以下载的文件为hadoop-3.0.0.tar.gz。 Windows首先将下载好hadoop-3.0.0.tar.gz压缩包，解压到合适的目录下（目录位置用于配置环境变量，用户可以自行选择），为了接下来方便配置的讲解，假设本次例子解压目录为：E:\hadoop-3.0.0，后文的hadoop的xx目录都是该目录下的子目录。 windows启动脚本在windows下安装hadoop,需要额外添加hadoop的window启动脚本，下载位置为：https://github.com/steveloughran/winutils ，选择相应的hadoop大版本，如本次安装为hadoop3.0.0。则需将winutils中hadoop-3.0.0\bin下的所有文件复制，粘贴到hadoop的bin目录下，即例子中的 E:\hadoop-3.0.0\bin中。 环境变量配置 修改hadoop-env.cmd文件 修改hadoop的etc\hadoop目录下hadoop-env.cmd文件，将文件中的set JAVA_HOME=%JAVA_HOME% 替换成 set JAVA_HOME=C:/Progra~1/Java/jdk1.8.0_144，用系统的JAVA_HOME的路径代替文件中JAVA_HOME的路径。 注意：本文只的jdk安装目录实际上为默认的C:/Program Files/Java/jdk1.8.0_144,但是该文件中参数的配置是不能出现空格的，如果含有空格，必须按照Windows 8.3 Pathname的路径规范书写，所以建议可以适当改变jdk的安装路径尽量不要包括空格等特殊符号。 添加环境变量 我的电脑 –&gt; 属性 –&gt; 高级系统设置中添加系统变量HADOOP_HOME，变量值为E:\hadoop-3.0.0，在path变量中添加%HADOOP_HOME%\bin; %HADOOP_HOME%\sbin; Hadoop配置文件 修改hadoop的etc\hadoop目录下core-site.xml文件，添加以下配置 123456789101112131415&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000&lt;/value&gt; &lt;/property&gt; &lt;!-- 配置Hadoop临时目录文件 --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;file:///E:/hadoop-3.0.0/data/tmp&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:///E:/hadoop-3.0.0/data/name&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改hadoop的etc\hadoop目录下hdfs-site.xml文件，添加以下配置 1234567891011121314151617181920&lt;configuration&gt; &lt;property&gt; &lt;!-- hdfs的文件的默认副本数 --&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:///E:/hadoop-3.0.0/data/dfs/namenode&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:///E:/hadoop-3.0.0/data/dfs/datanode&lt;/value&gt; &lt;/property&gt; &lt;!-- 关闭权限检查--&gt; &lt;property&gt; &lt;name&gt;dfs.permissions&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改hadoop的etc\hadoop目录下mapred-site.xml文件，添加以下配置 1234567&lt;configuration&gt; &lt;property&gt; &lt;!-- mapreduce 运行在yarn上 --&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改hadoop的etc\hadoop目录下yarn-site.xml文件，添加以下配置 12345678910&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;127.0.0.1&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 启动hadoop第一次需要格式化hdfs,使用命令hadoop namenode -format 打开cmd,输入start-dfs和start-yarn命令分别启动hdfs和yarn。 访问http://localhost:8088 和http://localhost:9870 可以看到hdfs和yarn的web界面 运行wordcount运行hadoop自带的wordcount例子，首先可以通过web界面向hdfs上传一个example.txt文件在新建的/input目录下,内容如下: 12345A Grain of SandTo see a world in a grain of sandAnd a heaven in a wild fllowerHold infinity in the palm of your handAnd eternity in an hour 运行wordcount的jar（在hadoop的share\hadoop\mapreduce目录下的hadoop-mapreduce-examples-3.0.0.jar）来统计本件中单词的数量 1E:\java\hadoop-3.0.0\share\hadoop\mapreduce&gt;hadoop jar hadoop-mapreduce-examples-3.0.0.jar wordcount /input/example.txt /out 最后可以看到hdfs上/out目录下part-r-00000的文件，内容为example文件的单词的统计 1234A 1And 2Grain 1... Mac和Linux下载解压安装包tar -zxvf hadoop-3.0.0.tar.gz。 环境变量配置 修改hadoop-env.cmd文件 修改hadoop的etc\hadoop目录下hadoop-env.cmd文件，将文件中的set JAVA_HOME=%JAVA_HOME% 替换成 set JAVA_HOME=，用系统的JAVA_HOME的路径代替文件中JAVA_HOME的路径。 添加环境变量 修改~/.bash_profile文件,在最后添加hadoop的环境变量 123vim ~/.bash_profileexport HADOOP_HOME=/Users/Cyan/coding/hadoop/hadoop-2.8.2export PATH=$PATH:$HADOOP_HOME/bin Hadoop配置文件配置文件几乎和windows的一样，除了路径的书写，根据mac和linux的路径书写来 启动Hadoop和运行wordcount和windows的一样，不重复了 遇到问题 针对mac,启动HDFS时，start-dfs.sh,报错“connection refused”，则需要在计算机系统设置中打开远程登录许可。 点击 Sharing（共享）： 勾选 Remote Login（远程登录），然后添加当前用户： 运行mapreduce程序。如wordcound,报错“错误:“找不到或无法加载主类 org.apache.hadoop.mapreduce.v2.app.MRAppMaster” 在yarn-site.xml中添加名为yarn.application.classpath的属性，值为hadoop classpath命令的输出结果 12hadoop classpath/Users/zhongyue/hadoop-3.0.0/etc/hadoop:/Users/zhongyue/hadoop-3.0.0/share/hadoop/common/lib/*:/Users/zhongyue/hadoop-3.0.0/share/hadoop/common/*:/Users/zhongyue/hadoop-3.0.0/share/hadoop/hdfs:/Users/zhongyue/hadoop-3.0.0/share/hadoop/hdfs/lib/*:/Users/zhongyue/hadoop-3.0.0/share/hadoop/hdfs/*:/Users/zhongyue/hadoop-3.0.0/share/hadoop/mapreduce/*:/Users/zhongyue/hadoop-3.0.0/share/hadoop/yarn:/Users/zhongyue/hadoop-3.0.0/share/hadoop/yarn/lib/*:/Users/zhongyue/hadoop-3.0.0/share/hadoop/yarn/* 123456vim yarn-site.xml&lt;property&gt; &lt;name&gt;yarn.application.classpath&lt;/name&gt; &lt;value&gt;/Users/zhongyue/hadoop-3.0.0/etc/hadoop:/Users/zhongyue/hadoop-3.0.0/share/hadoop/common/lib/*:/Users/zhongyue/hadoop-3.0.0/share/hadoop/common/*:/Users/zhongyue/hadoop-3.0.0/share/hadoop/hdfs:/Users/zhongyue/hadoop-3.0.0/share/hadoop/hdfs/lib/*:/Users/zhongyue/hadoop-3.0.0/share/hadoop/hdfs/*:/Users/zhongyue/hadoop-3.0.0/share/hadoop/mapreduce/*:/Users/zhongyue/hadoop-3.0.0/share/hadoop/yarn:/Users/zhongyue/hadoop-3.0.0/share/hadoop/yarn/lib/*:/Users/zhongyue/hadoop-3.0.0/share/hadoop/yarn/* &lt;/value&gt;&lt;/property&gt; 分布式hadoop分布式运行环境搭建是使用virtual Box创建三台Ubuntu虚拟机上进行的，所以会有一些ubuntu的一些配置，方便后续Hadoop的安装 更改apt源由于apt原来的源太慢，改为国内阿里的源 1234567891011121314151617181920# 备份原来的文件sudo mv /etc/apt/sources.list /etc/apt/source.list.bak# 编辑源列表文件sudo vim /etc/apt/sources.list# 添加内容deb http://mirrors.aliyun.com/ubuntu/ xenial main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ xenial-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ xenial-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ xenial-backports main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ xenial-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ xenial main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ xenial-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ xenial-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ xenial-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ xenial-proposed main restricted universe multiversedeb http://archive.canonical.com/ubuntu/ xenial partnerdeb http://extras.ubuntu.com/ubuntu/ xenial main# 更新源sudo apt-get updatesudo apt-get upgrade 固定IP地址由于虚拟机使用的是桥接网络，固定ip方便以后ssh连接 首先查看虚拟机的网卡 12345678910111213ip a1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: enp0s3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 08:00:27:42:48:cc brd ff:ff:ff:ff:ff:ff inet 192.168.31.112/24 brd 192.168.31.255 scope global enp0s3 valid_lft forever preferred_lft forever inet6 fe80::a00:27ff:fe42:48cc/64 scope link valid_lft forever preferred_lft forever 可以看到这里的网卡编号为enp0s3,接下来编辑文件 sudo vi /etc/network/interfaces,写入静态ip地址(address)，子网掩码(netmask)和网(gateway)，配置固定的DNS,dns-nameserver后面接DNS服务器地址，可根据不同地域和网络网上查询得到，8.8.8.8万能的dns,修改sudo vim /etc/resolv.conf可以改变dns,但是重启失效。最后重启网络服务 1234567891011sudo vim /etc/network/interfacesauto loiface lo inet loopbackauto enp0s3iface enp0s3 inet staticaddress 192.168.31.112netmask 255.255.255.0gateway 192.168.31.1dns-nameservers 8.8.8.8# 重启网络服务sudo /etc/init.d/networking restart ssh安装启动1234567sudo apt-get install openssh-serversudo /etc/init.d/ssh startsudo /etc/rc.local# /etc/rc.local中exit 0前加入/etc/init.d/ssh start设置/etc/init.d/ssh start# 生产ssh keyssh-keygen 将集群之间的公钥保存在authorized_keys中，形成集群机器之间的免密登陆 JDK配置下载jdk文件，jdk-8u191-linux-x64.tar.gz 解压该文件到指定目录 12mkdir /usr/lib/Javatar -zxf jdk-8u191-linux-x64.tar.gzz -C /usr/lib/Java/ 接下来配置java的环境变量,在/etc/profile的最后添加环境变量 123456vim /etc/profileexport JAVA_HOME=/usr/lib/Java/jdk1.8.0_191export JRE_HOME=$JAVA_HOME/jreexport CLASSPATH=.:$JAVA_HOME/lib:$JAVA_HOME/jre/lib:$CLASSPATHexport PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATH 最后查看是否配置成功 1234java -versionjava version "1.8.0_191"Java(TM) SE Runtime Environment (build 1.8.0_191-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode) Hadoop安装下载解压Hadoop 3.0的安装包12wget http://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-3.1.1/hadoop-3.1.1.tar.gztar -zxvf hadoop-3.1.1.tar.gz 添加环境变量修改/etc/profile，根据hadoop解压后的位置添加HADOOPCONF_DIR、HADOOP_HOME、HADOOP_HDFS_HOME，并将$HADOOP_HOME/bin和$HADOOP_HOME/sbin`追加入到path中， 12345$ vim /etc/profileexport HADOOPCONF_DIR=/usr/hadoop3.1/hadoop-3.1.1/etc/hadoopexport HADOOP_HOME=/usr/hadoop3.1/hadoop-3.1.1export HADOOP_HDFS_HOME=/usr/hadoop3.1/hadoop-3.1.1export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH 使修改的环境变量生效 1$ source /etc/profile 修改host集群域名和ip映射，方便之后配置 1234567$ cat /etc/hosts127.0.0.1 localhost# 127.0.1.1 hdp-310.1.16.111 hdp-110.1.16.112 hdp-210.1.16.113 hdp-3 这里是三台机器组成集群，ip分别是10.1.16.111/112/113，对应域名hdp-1/hdp-2/hdp-3（分别是三台机器的hostname，也可以随意取名 ），这个需要按照实际ip和hostname 来 修改hadoop的配置文件修改hadoop-env.sh${HADOOP_HOME}/etc/hadoop/hadoop-env.sh，增加JAVA_HOME，同java环境变量中的相同 1export JAVA_HOME=/usr/lib/Java/jdk1.8.0_191 core-site.xml配置${HADOOP_HOME}/etc/hadoop/core-site.xml配置hdfs中NameNode的URI(包括协议、主机名称、端口号),从上述选取一台作为namenode的节点 123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://hdp-1:9000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; hdfs-site.xml配置${HADOOP_HOME}/etc/hadoop/hdfs-site.xml，配置hafs中文件的备份数，以及namenode，datanode的存储位置，需要先创建namenode，datanode的存储位置，即下面的/data/hdp/namenode和/data/hdp/datanode 1234567891011121314&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;/data/hdp/namenode&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;/data/hdp/datanode&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; yarn-site.xml配置${HADOOP_HOME}/etc/yarn-site.xml,配置resourcemanager运行的机器，为了能够运行MapReduce程序，需要让各个NodeManager在启动时加载shuffle server，接着是resourcemanager和jobhistory的UI界面的地址，开启日志聚集和保存时间 12345678910111213141516171819202122232425262728293031323334&lt;configuration&gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;hdp-1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt; &lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt; &lt;value&gt;hdp-1:8088&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;hdp-1:19888&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt; &lt;value&gt;640800&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; mapred-site.xml${HADOOP_HOME}/etc/mapred-site.xml，配置mapreduce运行在yarn上 123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; workers${HADOOP_HOME}/etc/worker，将集群中的所有机器添加上去 123hdp-1hdp-2hdp-3 启动Hadoop首次启动需要格式化namenode 12345678# 格式化hdfs namenode -format# 启动hdfs,可以使用start-all.sh来启动hdfs和yarnstart-dfs.sh# 启动yarnstart-yarn.sh# 如果想看jobhistory，可以启动一下服务mr-jobhistory-daemon.sh start historyserver 可以通过jps查看启动了哪些组件 123456789101112# hdp-1，由于namenode和resourcemanager在其上运行11939 Jps10756 SecondaryNameNode11173 NodeManager11045 ResourceManager10581 DataNode10454 NameNode7148 JobHistoryServer# hdp-2,hdp-328848 NodeManager29491 Jps28719 DataNode 通过配置的yarn.resourcemanager.webapp.address和mapreduce.jobhistory.webapp.address,可以看到yarn的信息界面，hdfs的信息界面默认在运行namenode机器的9870端口。 以上配置只是能让Hadoop够运行以及能看到基本信息，实际生产中还需要进行更多配置，有兴趣可以从官方查看各个配置参数。]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[InnoDB数据页结构及其与聚簇索引的关系]]></title>
    <url>%2FInnoDB%E6%95%B0%E6%8D%AE%E9%A1%B5%E7%BB%93%E6%9E%84%E5%8F%8A%E5%85%B6%E4%B8%8E%E8%81%9A%E7%B0%87%E7%B4%A2%E5%BC%95%E7%9A%84%E5%85%B3%E7%B3%BB.html</url>
    <content type="text"><![CDATA[表空间InnoDB中数据都存放在一个空间中，就是表空间。在文件系统中就是idb文件，每个idb文件都是一个表空间。它们之间通过表空间id来区分，在默认情况下，InnoDB使用的是共享表空间，所有数据存放在一个共享表空间ibdata1中。共享表空间可以通过参数innodb_data_file_path进行配置。 可以同时配置多个文件组成一个共享表空间，如 1innodb_data_file_path=/data/ibdata1:2000M;/data/ibdata2:2000M:autoextend 这里配置了/data/ibdata1和/data/ibdata2两个文件组成表空间，如果两个文件在不同磁盘上，能降低各个磁盘的负载，可以提高数据库的性能。同时，两个文件名后跟了存储大小，表示文件的最大存放空间，而autoextend表示/data/ibdata2若用完了2000M，文件可以自动增长。 实际上，除了共享表空间还有独立表空间，将参数innodb_file_pre_table设为ON可以开启独立表空空间。在独立表空间中，对于每张表内的数据都单独放在一个表空间中，但是每个表空间只会对应表的数据、索引和插入缓冲Bitmap页，其余数据，例如回滚日志，事务信息，二次缓存等还是存放在共享表空间。 表空间由段(segment)、区(extent)、页(page)组合。 数据页页是InnoDB存储引擎管理数据库的最小磁盘单位。默认一个页的大小是16K,InnoDB 1.0.x后可以通过参数KEY_BLOCK_SIZE设置默认页大小为2K,4K,8K，InnoDB 1.2.x新增参数innodb_page_size可以设置默认页大小为4K,8K。 数据页由File Header、Page Header、Infimun和Supremum Records、User Records、Free Space、Page Directory、File Trailer组合。其中File Header、Page Header和File Trailer的大小是固定的，分别占用38、56、8个字节，记录数据页的信息。而Infimun、Supremum Records、User Records、Free Space、Page Directory存储的信息和实际的行数据有关，因此大小是动态的。 File HeaderFile Header固定38个字节，用来记录页的头信息。 File Header中的FIL_PAGE_PREV和FIL_PAGE_NEXT分别是记录了上一页和下一页在表空间中的位置，因此页与页之间是通过链表的数据结构连接再一起，而且是一个双向链表。 Page HeaderPage Header接着File Header之后，固定56字节，记录数据页的状态信息。 Infimun和Supremum RecordsInfimun和Supremum Records是虚拟的两个行记录，用来限定实际数据行的边界。Infimun是比页中任何主键值都小的值，而Supremum是比任何主键值都要大的值。这两值在页被创建时就被建立，不会被删除。 User Records存储实际行记录的内容。数据库中一行数据对应文件中的一行记录格式。目前InnoDB只要有两种行记录格式：Compact和Redundant，Compacts是mysql 5.1之后的默认行记录格式，Redundant是为了兼容之前的版本而保留。接下来分别介绍这两种行记录格式。 Compact行记录格式Compact行记录格式能够高效的存储行记录，一页中存放的行数据越大，性能就越高。Compact的存储格式如下图： 变成字段长度列表记录了行记录中变长字段(varchar)的长度，其按照列的顺序逆序放置，一个变长字段的长度最大不会超过2个字节，因为varchar类型的最大长度为65535，正好是2的16次方，因此最多两个字节就能记录下该字段的长度。如果该列的长度小于255字节，则用1个字节表示，如果大于255字节，则用2个字节表示。 例如，创建一张表z,包括三个变长字段，一个固定长度字段，则其对对应的变长字段列表如下 12345678910111213CREATE TABLE test(t1 VARCHAR(10),t2 VARCHAR(10),t3 CHAR(10),t4 VARCHAR(10)ENGINE=INNODB CHARSERT=LATIN1 ROW_FORMAT=COMPAT);-- 第一行INSERT INTO test VALUES(&apos;a&apos;, &apos;bb&apos;, &apos;ccc&apos;, &apos;dddd&apos;);-- 第二行INSERT INTO test VALUES(&apos;e&apos;, NULL, &apos;ff&apos;, &apos;gggg&apos;);-- 第三行INSERT INTO test VALUES(&apos;e&apos;, NULL, NULL, &apos;gggg&apos;); 第一行对应的变长字段长度列表为04 03 01(dddd,ccc,a)，第二行04 02 01(gggg,ff,e)，第三行为04 01(gggg,e)，因为t3为固定长度字段，所以不会记录其长度，对已NULL的字段也是不会记录，比如第三行的t2字段。 NULL标志占1个字节，表示该行记录有无NULL值，有则为1，无为0。字段中的NULL值实际上不记录在compact格式中，所以NULL数据实际上除了占有NULL标志位以外不占用任何存储空间。 记录头信息固定占5个字节，详细表示记录的信息如下图 从行记录头中的next_record可以看出行与行之间同样是链表的方式存储，因此一页之间的行与行其实不需要按照顺序存储，实际上行存储顺序可能是无序的，但是通过链表将其按照主键顺序串连在一起。n_owned是和下文要讲的Page Dirextory有关，帮助在页中查找行记录。 接下来分别是事务ID和回滚指针，分别占用6字节和7字节，如果InnoDB表没有指定主键也没有非空唯一索引，则会在事务ID前增加一个自动创建的6字节的主键ID。 最后存储的就是各个字段上实际数据。 Redundant行记录格式Redundant行记录格式是为了兼容之前版本的页格式，其存储格式如下： 地段长度偏移列表表示各个字段（包括主键ID,事务ID,回滚指针，列数据，不包括记录头信息）距离记录头信息开始的偏移量。 redundant记录头信息占6个字节，格式如下： 接下来的信息格式和Compact行记录格式一样，除了对NULL值的处理，在Compact中除了NULL标志外实际上是不存储NULL值，但是redundant中NULL是记录其内容，具体内容就是用00填充其固定字段长度，对于变长字段则同样不占用任何存储空间，即不记录变长字段NULL值。 Free SpaceFree Space指的是页中的空闲空间，同样是链表的数据结构，当一行被删除之后，该空间就会被加入Free Space当中。 Page DirectoryPage Directory也叫页目录，存放的是记录在页中的相对位置。这些记录指针被称为slots（槽）。InnoDB的页中的并不是为每一条记录存放在槽，InnoDB实际上采用的是稀疏目录，即一个槽中可能存放的是多个记录。slots中的记录是按照主键索引值逆序排放的，每个槽占两个字节，通过槽中的指针找到对应行记录的位置，行记录头中的n_owned记录了该记录拥有的记录数，即槽中存放的记录数。 slots中的记录是按照主键索引值逆序排放的，通过槽使用二分查找可以快速的找到页中相应行记录的位置。例如，页中记录的主键值有{g, i, c, k, e, f, a, h, b, j, l, d}，假设一个槽存放4条记录，则按照主键排序的逆序，槽中的记录可能是{a, e, i} 通过槽使用二分查找查找到的结果只是一个粗略的结果，需要获得准确的结果，还需通过next_record顺着链表最多查看n_owned条记录是否符合要求。 实际上通过InnoDB查找记录的顺序是首先通过B+书找到相应的页，接着将页加载到内存中，在页中通过Page Directory利用二分查找找到粗略的位置，最后通过链表找到记录。只不过在内存中二分查找的过程很快，一般忽略这部分的查找时间。 File TrailerFile Trailer是为了检测页是否完整的写入磁盘而设置的，其中包含checksum值，通过相应的checknum函数进行比较，检测页的完整性。 InnoDB数据页与索引聚簇索引InnoDB针对每张表的主键都会构造一颗B+树，即聚簇索引（Clusterd Index），所以InnoDB的每张表都有聚簇索引，就是其在主键上创建的索引。索引结构同B+树的数据结构相同，但与辅助索引不同的是其叶子节点存放的是所有的数据，即聚簇索引叶子节点实际上就是数据页，叶子节点之间通过双向链表有序的连接在一起，即上文每个数据页的File Header都有FIL_PAGE_PREV和FIL_PAGE_NEXT记录上一页和下一页的位置。聚簇索引在物理存储上并不是按照顺序的存放，而是通过其双向链表和数据页中的行记录格式的行链表实现了逻辑上的顺序存放，沿着链表查看是顺序存放的。 因此通过聚簇索引查找实际上分三种查找方式： 根据B+树查找到对应的数据页 在数据页中根据Page Directory的稀疏目录找到粗略的行记录位置 z最后根据next_record在链表上顺序查找 辅助索引在InnoDB表的非主键字段上建立的B+树索引也称为辅助索引（Secondary Index）。辅助索引结构同样是B+树的结构，但是其叶子节点存放的不是数据页，而是索引的键值加上主键值。 通过辅助索引可以查找到相应的主键值，接着利用主键值在聚簇索引上找到实际数据，即我们通过辅助索引查找实际上是通过两颗B+树查找。 与非聚簇索引的比较例如MYISAM存储引擎使用的是非聚簇索引，不同于聚簇索引的是其叶子节点存放的是数据存放的地址。其主索引和辅助索引除了键值不同外并没有什么区别，叶子节点都是使用指针指向真正的数据地址。 对于离散的查找，聚簇索引要比非聚簇索引慢一些，因为聚簇索引要走两颗B+树的I/O。 在数据的更新上，特别是更新影响到物理地址的变化，聚簇索引要比非聚簇索引，因为非聚簇索引需要改变所有索引上相应叶子节点的物理地址，而聚簇索引叶子节点直接存放数据，辅助索引存放的是主键值，无需改变。 对于排序和范围查找，聚簇索引将数据按照逻辑顺序排列，能够通过一行记录的位置快速找到其相应的周围的记录，明显比非聚簇索引好。]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>数据页</tag>
        <tag>聚簇索引</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[布隆过滤器-Bloom Filter]]></title>
    <url>%2F%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8-Bloom-Filter.html</url>
    <content type="text"><![CDATA[简介​ Bloom Filter是由 Burton Howard Bloom在1970提出的，用来判断一个元素是否存在集合中的概率算法。经过Bloom Filter判断过不在集合中的元素就一定不在集合中，若判断结果是在集合中，则可能会误判，即该元素可能不在集合中。换句话说，可能会误判，但绝不可能漏判。元素可以添加到集合中，但不会被删除（尽管可以通过“计数”过滤器来解决）; 添加到集合中的元素越多，误判的概率就越大。Bloom Filter将元素映射到位数组中，所以极大的节省空间。 算法描述​ 通常我们判断一个元素是否在集合中，可以将集合存放在一个列表等数据结构中，通过比对查找的方式判断是否包含该元素，但是当元素的个数越来越大时，列表占用的内存空间会越来越大，可以将其存放在磁盘空间中，但是这样会大大降低查询时间。进一步改进，可以通过散列表来映射元素到二进制位数组中，真正的数据存放磁盘空间中，内存存放散列表，通过元素散列映射的位是否为1判断元素是否存在集合中。但是散列表当元素增加时，发生冲突的概率也不断增大，冲突会降低查询的效率，为了减少冲突，可以通过多个哈希函数解决，当一个元素通过多个哈希函数映射的位都为1时，那么判断元素可能在集合中，否则元素必定不在元素中。Bloom Filter就是使用这种方法。 初始化​ Bloom Filter是通过不同的哈希函数映射到位数组，初始化是一个位数组，数组元素全设置为0，代表目前没有元素在集合中，数组的初始化长度下文会介绍。 插入元素​ 插入的元素需要通过k个哈希函数得到k个对应的位数组上的位置，将这些位置上的位全都设置为1，若已经设置为1，则可以不做任何改变。 如图将集合中的x，y，z通过三个哈希函数得到的位数组上对应的位都设置为1。 判断元素是否在集合中​ 将需要判断的元素同样通过k个哈希函数得到k个对应的位数组上的位置，判断其位置上的位是否全为1，若是则元素可能存在在集合中，否则必定不存在。如上图的w通过哈希函数得到的位置上的位有一个不为1，则w必定不存在该集合中。 参数的选择Bloom Filter主要有四个参数: $k$：哈希函数的个数 $m$：位数组的大小 $n$：集合的元素个数 $p$：假阳性概率（false positive probability），即将不在集合中的元素判断为在集合中，误判的概率 哈希函数的数量$k$必须是正整数。如果不考虑这个约束，则对已给定的$m$和$n$或$p$，当$k$满足以下公式时误判的概率最小：$$k = -\frac{lnp}{ln2} = \frac{m}{n}ln2$$而由$n$和$p$可以得到最佳的$m$的值：$$m = -\frac{nlnp}{(ln2)^2}$$所以每个元素的最佳位数是：$$\frac{m}{n}=-\frac{lnp}{(ln2)^2}\approx-1.44log_2p$$ 实现Bloom Filter的简单实现，参考：https://github.com/MagnusS/Java-BloomFilter 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147import java.io.Serializable;import java.nio.charset.Charset;import java.security.MessageDigest;import java.security.NoSuchAlgorithmException;import java.util.BitSet;import java.util.Collection;public class BloomFilter&lt;E&gt; implements Serializable &#123; int k; //hans函数的个数 int m; //bit的位数 int n; //存储的预期容量 int size; //实际存储的容量 BitSet bitSet; static final Charset CHARSET = Charset.forName("utf-8"); static final String hashName = "MD5"; static final MessageDigest MESSAGE_DIGEST; static &#123; MessageDigest tmp; try &#123; tmp = MessageDigest.getInstance(hashName); &#125;catch (NoSuchAlgorithmException e)&#123; tmp = null; &#125; MESSAGE_DIGEST = tmp; &#125; /** * 根据假阳性概率和预计个数计算bit数组的大小 * @param falsePositiveProbability 假阳性概率 * @param n 预期的集合的个数 * @return */ private static int calculateM(double falsePositiveProbability, int n)&#123; return (int)Math.ceil(-1.44*Math.log(falsePositiveProbability)/Math.log(2.0) * n); &#125; /** * 根据假阳性概率和预计个数计算散列函数的个数 * @param falsePositiveProbability 假阳性概率 * @param n 预期的集合的个数 * @return */ private static int calculateK(double falsePositiveProbability, int n)&#123; return (int) Math.round(calculateM(falsePositiveProbability, n)/ (double)n * Math.log(2.0)); &#125; /** * 根据bit数组的大小和预计个数计算散列函数的个数 * @param m * @param n * @return */ private static int calculateK(int m, int n)&#123; return (int) Math.round(m/(double)n * Math.log(2.0)); &#125; public BloomFilter(double falsePositiveProbability, int n)&#123; this(calculateK(falsePositiveProbability, n), calculateM(falsePositiveProbability, n), n); &#125; public BloomFilter(int m, int n)&#123; this(calculateK(m, n), m, n); &#125; public BloomFilter(int k, int m, int n)&#123; this.k = k; this.m = m; this.n = n; bitSet = new BitSet(this.m); size = 0; System.out.println("bloom filter init success, K: " + k + " m: " + m + " n： " + n); &#125; /** * 得到相应的hash * @param data * @param hashNum * @return */ public static int[] getHashs(byte[] data, int hashNum)&#123; int[] result = new int[hashNum]; int k = 0; byte salt = 0; while (k &lt; hashNum)&#123; byte[] digest; synchronized (MESSAGE_DIGEST)&#123; MESSAGE_DIGEST.update(salt); salt++; digest = MESSAGE_DIGEST.digest(data); &#125; for(int i = 0; i &lt; digest.length/4 &amp;&amp; k &lt; hashNum; i++)&#123; int h = 0; for(int j = i*4; j &lt; (i*4) + 4;j++)&#123; h &lt;&lt;= 8; h |= ((int) digest[j] &amp; 0xFF); &#125; result[k] = h; k++; &#125; &#125; return result; &#125; /** * 添加元素到过滤器中 * @param element */ public void add(E element)&#123; int[] hashCodes = getHashs(element.toString().getBytes(CHARSET), this.k); for(int hashCode: hashCodes)&#123; bitSet.set(Math.abs(hashCode % this.m), true); size ++; &#125; &#125; public void addAll(Collection&lt;E&gt; collection)&#123; for(E element: collection)&#123; add(element); &#125; &#125; /** * 判断元素是否在集合中 * @param element * @return */ public boolean contains(E element)&#123; int[] hashCodes = getHashs(element.toString().getBytes(CHARSET), this.k); for(int hashCode: hashCodes)&#123; if(! bitSet.get(Math.abs(hashCode % this.m)))&#123; return false; &#125; &#125; return true; &#125; public boolean containsAll(Collection&lt;E&gt; collection)&#123; for(E element: collection)&#123; if(! contains(element))&#123; return false; &#125; &#125; return true; &#125;&#125; 应用 爬虫中的url去重 Hbase中通过Bloom Filter来快速确定查询的数据是否在HFile中，加快查询速度]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>Bloom Filter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[超平面]]></title>
    <url>%2F%E8%B6%85%E5%B9%B3%E9%9D%A2.html</url>
    <content type="text"><![CDATA[什么是超平面数学中的超平面以下内容均来自：https://www.cnblogs.com/dengdan890730/p/5554787.html 在数学中，超平面（Hyperplane）是n维欧氏空间中余维度等于1的线性子空间。这是平面中的直线、空间中的平面之推广. $n$维超平面的方程定义为： ​ $a_1x_1+…+a_nx_n=b$，其中$a_1,…,a_n$是不全为0的常熟 ​ 即$w^Tx+b=0，$ 其中，$w$与$x$都是$d$维列向量，$x=(x_1,x_2,…,x_n)$为超平面上的点，$w=(w_1,w_2,…,w_n)$为平面上的法向量,$b$是一个实数, 代表平面与原点之间的距离. 我们最常见的平面概念是在三维空间中定义的:$Ax+By+cZ+D=0$ 超平面有两个性质： 方程是线性的: 是空间点的各分量的线性组合 方程数量为1 $d$维空间中的超平面其实就是维度比所在空间低一维的平面，即$d-1$维。例如3维空间的超平面是二维平面，二维空间的超平面是一条直线，一维空间的超平面是一个点. 点到超平面的距离假设点$x′$为超平面$A:w^Tx+b=0$上的任意一点, 则点$x$到$A$的距离为$x−x′$在超平面法向量$w$上的投影长度:$$d=\frac{|w^T(x−x′)|}{||w||}=\frac{|wTx+b|}{||w||}$$ 超平面的正面与反面一个超平面可以将它所在的空间分为两半, 它的法向量指向的那一半对应的一面是它的正面, 另一面则是它的反面. 判断一个点是在超平面的正面还是反面(面向的空间里)还是要用到它的法向量$w$.仍然假设点$x′$为超平面$A:wTx+b=0A:wTx+b=0$上的任意一点, 点$x$为待判断的点.若$x−x′$与$w$的夹角小于$90^o$, 则$x$在$A$的正面, 否则在反面$$w^T(x−x′)&gt;0→w^Tx+b&gt;0$$所以判定依据为:$$x在A的=\begin{cases}正面,\quad\quad w^Tx+b&gt;0\\平面上,\quad w^Tx+b=0\\反面,\quad\quad wTx+b&lt;0x\\\end{cases}$$若将距离公式中分子的绝对值去掉, 让它可以为正为负. 那么, 它的值正得越大, 代表点在平面的正向且与平面的距离越远. 反之, 它的值负得越大, 代表点在平面的反向且与平面的距离越远. 投影到超平面对于$n$维空间上的向量$x = (x_1,x_2,…,x_n)$投影到一个法向量为$w$的超平面上的投影向量$x’$为：$$x’=x-w^Txw$$]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>超平面</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HBase客户端的写缓存BufferedMutator]]></title>
    <url>%2FHBase%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%9A%84%E5%86%99%E7%BC%93%E5%AD%98BufferedMutator.html</url>
    <content type="text"><![CDATA[客户端的写缓存HBase的每一个put操作实际上是一个RPC操作，将客户端的数据传输到服务器再返回结果，这只适用于小数据量的操作，如果数据量多的话，每次put都需要建立一次RPC的连接（TCP连接），而建立连接传输数据是需要时间的，因此减少RPC的调用可以提高数据传输的效率，减少建立连接的时间和IO消耗。 HBase的客户端API提供了写缓存区，put的数据一开始放在缓存区内，当数量到达指定的容量或者用户强制提交是才将数据一次性提交到HBase的服务器。这个缓冲区可以通过调用 HTable.setAutoFlush(false) 来开启。而新版HBbase的API中使用了BufferedMutator替换了老版的缓冲区，通过BufferedMutator对象提交的数据自动存放在缓冲区中。 BufferedMutatorBufferedMutator通过mutate方法提交数据，flush方法可以强制刷新缓冲区提交数据，在执行close方法之前也会刷新缓冲区。 BufferedMutator是通过设定BufferedMutator.ExceptionListener监听器来异步处理异常，重写onException来实现异常处理，该监听器用来监听接受服务器端发送回来的错误消息。 用户可以通过设定BufferedMutatorParams的来定制符合要求的BufferedMutator。比如缓冲区的大小通过BufferedMutatorParams中的writeBufferSize方法设置（缓冲区的大小也可以通过配置文件的 hbase.client.write.buffer设置，值为long类型，单位为byte），异常监听器也是在BufferedMutatorParams中设置。 官方例子分析官方给出了BufferedMutator的使用例子，通过分析代码可以了解到BufferedMutator的使用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public class BufferedMutatorExample extends Configured implements Tool &#123; private static final Logger LOG = LoggerFactory.getLogger(BufferedMutatorExample.class); //线程池的大小 private static final int POOL_SIZE = 10; //线程的数量 private static final int TASK_COUNT = 100; private static final TableName TABLE = TableName.valueOf("tanle_name"); private static final byte[] FAMILY = Bytes.toBytes("f"); @Override public int run(String[] args) throws InterruptedException, ExecutionException, TimeoutException &#123; //异常监听器的建立,当写入异常是触发该监听器 final BufferedMutator.ExceptionListener listener = new BufferedMutator.ExceptionListener() &#123; @Override public void onException(RetriesExhaustedWithDetailsException e, BufferedMutator mutator) &#123; for (int i = 0; i &lt; e.getNumExceptions(); i++) &#123; LOG.info("Failed to sent put " + e.getRow(i) + "."); &#125; &#125; &#125;; //创建BufferedMutatorParams对象，设置监听器 BufferedMutatorParams params = new BufferedMutatorParams(TABLE) .listener(listener); //可以改动缓冲区的大小,如下面设置缓冲区大小为4M params.writeBufferSize(4*1023*1024); /** 创建连接和根据BufferedMutatorParams创建BufferedMutator * 这里用到java 7的新特性 try-with-resources */ try (final Connection conn = ConnectionFactory.createConnection(getConf()); final BufferedMutator mutator = conn.getBufferedMutator(params)) &#123; /** 线程池的建立，运行线程不断put数据 */ final AtomicInteger count = new AtomicInteger(1); final ExecutorService workerPool = Executors.newFixedThreadPool(POOL_SIZE); List&lt;Future&lt;Void&gt;&gt; futures = new ArrayList&lt;&gt;(TASK_COUNT); for (int i = 0; i &lt; TASK_COUNT; i++) &#123; futures.add(workerPool.submit(new Callable&lt;Void&gt;() &#123; @Override public Void call() throws Exception &#123; Integer value = count.getAndIncrement(); Put p = new Put(Bytes.toBytes("task " + value)); p.addColumn(FAMILY, Bytes.toBytes("someQualifier"), Bytes.toBytes("task " + value + " info")); mutator.mutate(p); return null; &#125; &#125;)); &#125; // 结束线程和线程池 for (Future&lt;Void&gt; f : futures) &#123; f.get(5, TimeUnit.MINUTES); &#125; workerPool.shutdown(); &#125; catch (IOException e) &#123; LOG.info("exception while creating/destroying Connection or BufferedMutator", e); &#125; return 0; &#125; public static void main(String[] args) throws Exception &#123; ToolRunner.run(new BufferedMutatorExample(), args); &#125;&#125; 上面的官方例子就是启动线程不断提交数据，BufferedMutator中缓冲区可以避免频繁的调用RPC，在批处理数据时及其重要，并且BufferedMutator的mutate操作是异步的，所以不会产生阻塞，这在Map-Reduce作业有很好的使用，BufferedMutator接收来自MR作业的puts，异步的批量提交数据，不影响MR作业的运行。 错误处理当通过BufferedMutator批量提交发生错误时触发绑定的BufferedMutator.ExceptionListener监听器实例的onException方法，其中RetriesExhaustedWithDetailsException记录了发生错误的内容及其提交的错误内容等信息，而其余正确的提交的内容则会正确放入HBase表中。 对于提交内容的检查分为客户端的检查和服务器端的检查。 当客户端检查到提交的内容出错（比如Put未添加内容或者未指定列），会抛出客户端的错误，这样错误不会RetriesExhaustedWithDetailsException监听器接受，被其运行的线程会因错误而终止，则在该Put之后的内容都不会提交。 当服务端检查到提交的内容出错（比如指定的列簇不存在），会向客户端传输错误，而这错误会被RetriesExhaustedWithDetailsException监听器接受，不会对后续提交的数据产生影响。 Table的put,get,delete方法提交一个（put,get,delete）列表操作，其中有错误的内容时，也分客户端的检查和服务器端的检查（不同操作检查内容不同），在客户端检查出错会抛出异常终止程序，服务端异常时会传输会错误信息，但是其余正确的操作已将提交到服务端并被正确执行。 try-with-resources的特性不了解可以参考 https://www.jianshu.com/p/3ab87269140c]]></content>
      <categories>
        <category>HBase</category>
      </categories>
      <tags>
        <tag>BufferedMutator</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HBase 简介]]></title>
    <url>%2FHBase%20%E7%AE%80%E4%BB%8B.html</url>
    <content type="text"><![CDATA[数据模型在Hbase中，数据同样是存储在表中，有行和列。但是hbase和关系型数据库（RDBMS）有很大的区别，hbase更像是多维度的map。 hbase的同样有着表（table）, 行（row）,列（Column），根据表、行、列可以定位到一个单元格（cell）上,这样看来hbase和关系型数据库形式一样，其实不是的，hbase的列包括列簇（column family）和列限定符（column qualifier），一般将列限定符成为列，一行有固定的列簇（由表结构决定），一个列簇包含一系列的列，列没有固定的结构，每一行的列簇下的列可以不相同，列由添加数据决定，可以将hbase的表想象成一个Map&lt;row, Map&lt;column family,Map&gt;&gt;,由行、列簇寻找一个key不固定的map。而且相同单元格会存储着不同的版本值，每一次存储新值会添加时间戳Timestamp，并不会覆盖掉上次值，一个hbase表默认能存储一个版本值，若第四次设置新增，则会把第一次的值覆盖掉。因此一个单元格的定位需要row,family,qualifier和timestamp来确定。 存储在HBase表中的行是按照行健的字典顺序排列下来的。 如下为一个hbase表中存储的数据，com.cnn.www的people列簇可以不存储任何列和值，com.cnn.www和com.example.www列簇中的列可以不相同 Row Key Time Stamp ColumnFamily contents ColumnFamily anchor ColumnFamily people “com.cnn.www” t9 anchor:cnnsi.com = “CNN” “com.cnn.www” t8 anchor:my.look.ca = “CNN.com” “com.cnn.www” t6 contents:html = “…” “com.cnn.www” t5 contents:html = “…” “com.cnn.www” t3 contents:html = “…” “com.example.www” t5 contents:html = “…” people:author = “ 实际存储虽然在概念级别，表可以被视为稀疏的行集，但它们是按列族物理存储的。可以随时将新的列限定符（column_family：column_qualifier）添加到现有列族。如下anchor列簇的存储表和contents列簇的存储表。 行键 时间戳 列族 anchor “com.cnn.www” T9 anchor:cnnsi.com = &quot;CNN&quot; “com.cnn.www” T8 anchor:my.look.ca = &quot;CNN.com&quot; 行键 时间戳 列族contents: “com.cnn.www” T6 内容：html =“ ……” “com.cnn.www” T5 内容：html =“ ……” “com.cnn.www” T3 内容：html =“ ……” 概念视图中显示的空单元格根本不存储。因此，contents:html在时间戳处对列的值的请求t8将不返回任何值。同样，对anchor:my.look.ca时间戳记值的请求t9将不返回任何值。但是，如果未提供时间戳，则将返回特定列的最新值。给定多个版本，最新版本也是第一个版本，因为时间戳按降序存储。因此，com.cnn.www如果未指定时间戳，则对行中所有列的值的请求将是：contents:html来自timestamp t6的值，anchor:cnnsi.com来自timestamp t9的值，anchor:my.look.ca来自timestamp t8的值。 存储的数据类型HBase通过Put和Result支持“bytes-in / bytes-out”接口，实际存储的是字节数组， 因此任何可以转换为字节数组的都可以存储为值。输入可以是字符串，数字，复杂对象，甚至是图像，只要它们可以呈现为字节。 值的大小存在实际限制（例如，在HBase中存储10-50MB对象可能太大了）。HBase中的所有行都符合数据模型，包括版本控制。在进行设计时要考虑到这一点，以及ColumnFamily的块大小。 命名空间命名空间是表的逻辑分组，类似于关系型数据库系统中的数据库。命名空间提供了一下几个好处（这里不太理解具体的体现）： 配额管理（HBASE-8410） - 限制命名空间可以使用的资源量（即区域，表）。 命名空间安全管理（HBASE-9206） - 为租户提供另一级别的安全管理。 区域服务器组（HBASE-6721） - 可以将命名空间/表固定到RegionServers的子集上，从而保证粗略的隔离级别。 命名空间管理可以创建，删除或更改命名空间。在表创建期间通过指定表单的完全限定表名来确定命名空间成员身份。 1&lt;table namespace&gt;:&lt;table qualifier&gt; 12345678hbase&gt; #Create a namespacehbase&gt; create_namespace 'my_ns'hbase&gt; #create my_table in my_ns namespacehbase&gt; create 'my_ns:my_table', 'fam'hbase&gt; #drop namespacehbase&gt; drop_namespace 'my_ns'hbase&gt; #alter namespacehbase&gt; alter_namespace 'my_ns', &#123;METHOD =&gt; 'set', 'PROPERTY_NAME' =&gt; 'PROPERTY_VALUE'&#125; 预定义的名称空间有两个预定义的特殊命名空间： hbase - 系统命名空间，用于包含HBase内部表 default - 没有明确指定名称空间的表将自动落入此名称空间 12345hbase&gt; #namespace=foo and table qualifier=barhbase&gt; create 'foo:bar', 'fam'hbase&gt; #namespace=default and table qualifier=barhbase&gt; create 'bar', 'fam' Hbase shell的基本命令（持续更新）==hbase shell命令是对大小写敏感，写入命令要注意区分大小写。== list 命令 列出所有的表名 describe命令 查看表的信息 1describe 'table_name' create命令 例如创建一个名为t1,列簇有f1,f2,f3的表，行健是必须的所以不许指定，每个列簇的列添加数据时指定，因为每一行数据的列都不相同。 12345hbase&gt; create 't1', &#123;NAME =&gt; 'f1'&#125;, &#123;NAME =&gt; 'f2'&#125;, &#123;NAME =&gt; 'f3'&#125;hbase&gt; # The above in shorthand would be the following:hbase&gt; create 't1', 'f1', 'f2', 'f3'hbase&gt; create 't1', &#123;NAME =&gt; 'f1', VERSIONS =&gt; 1, TTL =&gt; 2592000, BLOCKCACHE =&gt; true&#125;hbase&gt; create 't1', &#123;NAME =&gt; 'f1', CONFIGURATION =&gt; &#123;'hbase.hstore.blockingStoreFiles' =&gt; '10'&#125;&#125; enable，disable、is_disabled、disable_all命令 enable，disable分别是解除禁用和禁用表，禁用表之后可以看到该表的存在，但是无法对该表的内容进行操作，is_disabled查看该表是否被禁用，(enable_all)disable_all(解除)禁用所有匹配给定正则表达式的表。 1234hbase&gt;disable 'table_name'hbase&gt;is_disable 'table_name'hbase&gt;# 禁用所有表名前缀为table的表hbase&gt;disable_all 'table*' alter命令 修改表结构 123456789101112131415161718192021222324252627282930313233343536hbase&gt; # 改变或添加列簇的最带版本存储的版本个数为5hbase&gt; alter 't1', NAME =&gt; 'f1', VERSIONS =&gt; 5hbase&gt; # 能同时修改多个列簇hbase&gt; alter 't1', 'f1', &#123;NAME =&gt; 'f2', IN_MEMORY =&gt; true&#125;, &#123;NAME =&gt; 'f3', VERSIONS =&gt; 5&#125;hbase&gt; # 删除ns1命名空间下的t1表的f1列簇hbase&gt; alter 'ns1:t1', NAME =&gt; 'f1', METHOD =&gt; 'delete'hbase&gt; alter 'ns1:t1', 'delete' =&gt; 'f1'hbase&gt; # 能修改表的MAX_FILESIZE, READONLY, MEMSTORE_FLUSHSIZE, DURABILITY等属性，比如我们修改region的最大大小至128Mhbase&gt; alter 't1', MAX_FILESIZE =&gt; '134217728'hbase&gt; # 可以通过设置表协处理器属性来添加表协处理器：hbase&gt; alter 't1','coprocessor'=&gt;'hdfs:///foo.jar|com.foo.FooRegionObserver|1001|arg1=1,arg2=2'hbase&gt; # 由于您可以为表配置多个协处理器，因此序列号将自动附加到属性名称以唯一标识它。hbase&gt; # 协处理器属性必须与下面的模式匹配，以便框架了解如何加载协处理器类：hbase&gt; # [coprocessor jar file location] | class name | [priority] | [arguments]hbase&gt; # 可以设置configuration属性在表或列簇上hbase&gt; alter 't1', CONFIGURATION =&gt; &#123;'hbase.hregion.scan.loadColumnFamiliesOnDemand' =&gt; 'true'&#125;hbase&gt; alter 't1', &#123;NAME =&gt; 'f2', CONFIGURATION =&gt; &#123;'hbase.hstore.blockingStoreFiles' =&gt; '10'&#125;&#125;hbase&gt; # 可以删除表范围属性hbase&gt; alter 't1', METHOD =&gt; 'table_att_unset', NAME =&gt; 'MAX_FILESIZE'hbase&gt; alter 't1', METHOD =&gt; 'table_att_unset', NAME =&gt; 'coprocessor$1'hbase&gt; # 可以设置REGION_REPLICATION:hbase&gt; alter 't1', &#123;REGION_REPLICATION =&gt; 2&#125;hbase&gt; # 可以同时修改多个属性hbase&gt; alter 't1', &#123; NAME =&gt; 'f1', VERSIONS =&gt; 3 &#125;,&#123; MAX_FILESIZE =&gt; '134217728' &#125;, &#123; METHOD =&gt; 'delete', NAME =&gt; 'f2' &#125;,OWNER =&gt; 'johndoe', METADATA =&gt; &#123; 'mykey' =&gt; 'myvalue' &#125; drop命令 删除表，在删除表之前要确保表已经disbale，这样可以防止删除表时对其他使用该表的用户造成的影响 12hbase&gt;disable 'table_name'hbase&gt;drop 'table_name' put命令 例如向表t1的行健为r1的列簇为f1,列名为q1的值设为value,当存在是会设置新的时间戳的值，不存在会添加新的列。（如果不指定列名，则默认列名为空字符串） 123456hbase&gt; put 'ns1:t1', 'r1', 'f1:q1', 'value'hbase&gt; put 't1', 'r1', 'f1:q1', 'value'hbase&gt; put 't1', 'r1', 'f1:q1', 'value', ts1hbase&gt; put 't1', 'r1', 'f1:q1', 'value', &#123;ATTRIBUTES=&gt;&#123;'mykey'=&gt;'myvalue'&#125;&#125;hbase&gt; put 't1', 'r1', 'f1:q1', 'value', ts1, &#123;ATTRIBUTES=&gt;&#123;'mykey'=&gt;'myvalue'&#125;&#125;hbase&gt; put 't1', 'r1', 'f1:q1', 'value', ts1, &#123;VISIBILITY=&gt;'PRIVATE|SECRET'&#125; get 命令 查看表中的数据 123456hbase&gt; # 查看t1表的r1行的相关内容hbase&gt; get 't1', 'r1'hbase&gt; # 查看t1表的r1行的列簇为c1相关内容hbase&gt; get 't1', 'r1', 'f1'hbase&gt; # 查看t1表的r1行的列簇为c1的列为cnam相关内容hbase&gt; get 't1', 'r1', 'f1:q1' scan 命令 扫描表,没有像put和get简便的写法 1234567hbase&gt; # 查看表"t1"中的所有数据hbase&gt; scan 't1'hbase&gt; # scan 命令可以指定 startrow,stoprow 来 scan 多个 rowhbase&gt; scan 'user_test',&#123;COLUMNS =&gt;'info:username',LIMIT =&gt;10, STARTROW =&gt; 'test', STOPROW=&gt;'test2'&#125;hbase&gt; # 查看表"t1"中列族"c1"的所有数据,或者列族"c1"中列"cname"的所有数据hbase&gt; scan 't1', &#123;COLUMN =&gt; 'f1'&#125;hbase&gt; scan 't1', &#123;COLUMN =&gt; 'f1:q1'&#125; delete 命令 1hbase&gt; delete 't1', 'r1', 'f1:q1' 可以将命令写入脚本文件一次性顺序执行，例如在hbase_commands.txt中写入要执行的hbase shell命令,可以使用如下命令执行,在脚本的结尾最好写入exit命令，否则执行完命令之后停留在客户端交互界面。 1hbase shell ./hbase_commands.txt HBase 的API(持续更新)HBase与表操作有关的api主要有 HBaseConfiguration（配置类）， Connection（建立数据库连接类）， Admin（操作表的创建，删除，修改）， TableName（表名类），Table（操作表内容的增删改查）， Put（对应于put命令，存储值，Table.put方法的参数）， Get（对应于get命令，查看值，Table.get方法的参数）， Append（在值后面追加内容，table.append方法的参数，若原本有内容，得到追加后的结果，否则返回null）， Result（get返回的对象）， Scan（对应于scab命令，遍历值，Table.scan方法的参数，scan在指定起始行健和终止行健时，扫描的范围是[startRow, endRow),不包括终止行）， ResultScanner(scan的结果返回ResultScanner对象，扫描不会通过一次RPC请求到所有的结果，而是按行为单位请求返回的，如果请求大量数量，一次请求完会消耗大量系统资源和时间，返回的ResultScanner对象是一个迭代器，迭代得到Result对象，每次调用next方法会进行RPC请求一行数据，即使next(int nbRows)方法内部也是调用多次next()方法) Delete（对应于delete命令，删除值，Table.delete方法的参数，在没有指定时间戳的情况下，deleteColumn方法删除列的最新版本，deleteColumns方法删除所有版本，在指定时间戳的情况下，deleteColumn删除与时间戳匹配的版本，deleteColumns方法删除与时间戳相等和更早的版本）。 Put，Get，Delete， Increment，Append等都是Row的子类，方便Tbale的batch(List&lt;? extends Row&gt; actions, Object[] results)方法批处理增删改查等操作 api的详细使用请查看官方文档http://hbase.apache.org/1.2/apidocs/，这是1.2版本的，目前对于新版本的HBase来说有些过时。 写的简单操作hbase表的类 https://github.com/Yhaij/HadoopLearn/tree/master/src/main/java/com/hbase/learn 行锁HBase提供行锁，但是在0.95版本之后客户端无法显示的得到和使用行锁，该API已经移除，只在服务端有行锁的应用。在客户端只能使用checkAndPut,checkAndDelete等行原子操作 https://issues.apache.org/jira/browse/HBASE-7315 rowkey的设计原则和热点问题 长度原则，最短越好，最大不能超过64K。太长的影响有两点，一是极大影响了HFile的存储效率。二是缓存memstore不能得到有效利用，缓存不能存放太多的信息，造成检索效率的降低。 唯一原则：保证rowkey的唯一性 尽量保证经常一起用的rowkey存储在同一个region上，有助于提升检索效率。但要避免热点问题。 热点问题：即有的region存储大量的行记录，而有些只有少数，这是大量rowkey前缀相同，排序紧紧挨着一起造成 解决方法： 加盐：在rowkey前面加一个冗余信息，这样可以把数据分散到不同的region中 优点：可以有效的防止rowkey集中分配到一个或多个region中。有效避免了热点问题 缺点：无形中增加了rowkey的长度；范围检索得不到有效使用。 字段交换，提升权重：如果rowkey中含有几个信息字段，可以调整信息字段的顺序。 缺点：对于单个信息字段，或者无论怎么调整都会遇到region热点的rowkey是解决不了的 随机键：把rowkey进行hash化，在分配到不同的服务器上。和加盐的方式相似； 原理如何找到数据的Region Server : 通过zookeeper找到.META.的Region Server，cache到客户端，接着在对应的Region Server中找到.META.,同时cache下来，在.META.表中找到对应的数据的RS. HBase写逻辑：先找到要写入的RS，先写入到HLog，在写入到MemStore HBase读逻辑：先找到记录的RS和Region，先顺序遍历MemStore查看是否有该条记录，没有再在HFile中通过布隆过滤器判断是否在文件中，有则在其中查找(根据索引来查找，是多层的，相当于一棵树，多层原因是可以各层加载进内存，不需要加载整个索引) MemStore刷盘触发时机： 全局内存控制：当所有memstore占整个heap的最大比例（默认40%）的时候，会触发刷盘的操作，当刷盘时memstore小于整个heap的某个比例时（默认35%），停止。减少刷盘对业务带来的影响，实现平滑系统负载的目的。 MemStore达到上限：当MemStore的大小达到hbase.hregion.memstore.flush.size大小的时候会触发刷盘，默认128M大小 RegionServer的Hlog数量达到上限：前面说到Hlog为了保证Hbase数据的一致性，那么如果Hlog太多的话，会导致故障恢复的时间太长，因此Hbase会对Hlog的最大个数做限制。当达到Hlog的最大个数的时候，会强制刷盘。这个参数是hase.regionserver.max.logs，默认是32个。 手动触发：可以通过hbase shell或者java api手工触发flush的操作。 关闭RegionServer触发：在正常关闭RegionServer会触发刷盘的操作，全部数据刷盘后就不需要再使用Hlog恢复数据。 Region使用HLOG恢复完数据后触发：当RegionServer出现故障的时候，其上面的Region会迁移到其他正常的RegionServer上，在恢复完Region的数据后，会触发刷盘，当刷盘完成后才会提供给业务访问。 MemStore会按照排序好的结果刷盘进storefile，当storefile过大会触发Compaction， Compaction分为两类：MinorCompaction 和 MajorCompaction。MinorCompaction将小的，相邻的storefile合并，MajorCompaction将所有的storefile合成一个storefile。 为什么要Compaction：因为Hadoop不擅长处理小文件，文件越大性能越好。]]></content>
      <categories>
        <category>HBase</category>
      </categories>
      <tags>
        <tag>HBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简单集群时间同步]]></title>
    <url>%2F%E7%AE%80%E5%8D%95%E9%9B%86%E7%BE%A4%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5.html</url>
    <content type="text"><![CDATA[最近集群的Hbase的其中几个节点总是连接不上，最后发现是集群之间的系统时间不同步导致的(hbase的时间戳决定节点之间的时间必须同步)。决定使用的ntp来解决集群之间的系统时间同步问题。 安装ntp1yum install -y ntp ntp服务器配置集群之间的时间同步同样采用sever/client的方式，将其中一个节点做为ntp的服务器,其余作为客户端通过ntp服务来向ntp服务器同步时间。需要选定一台作为ntp server，修该ntp的配置文件。 1vim /etc/ntp.conf 在restrict内容下，加入一句，限制服务器的访问类型。 123456# Permit all access over the loopback interface. This could# be tightened as well, but to do so would effect some of# the administrative functions.restrict 127.0.0.1restrict -6 ::1restrict 10.1.13.0 mask 255.255.255.0 nomodify 这里加入了restrict 10.1.13.0 mask 255.255.255.0 nomodify，根据子网掩码，表示访问该ntp服务器的客户端ip必须在10.1.13.1-10.1.13.254范围内，nomodify表明客户端不能更改服务端的时间参数，但是客户端可以通过服务端进行网络校时。 restrict 相关语法为：restrict IP地址 mask 子网掩码 参数 其中IP地址也可以是default ，default 就是指所有的IP 参数有以下几个： ignore ：关闭所有的 NTP 联机服务 nomodify：客户端不能更改服务端的时间参数，但是客户端可以通过服务端进行网络校时。 notrust ：客户端除非通过认证，否则该客户端来源将被视为不信任子网 noquery ：不提供客户端的时间查询：用户端不能使用ntpq，ntpc等命令来查询ntp服务器 notrap ：不提供trap远端登陆：拒绝为匹配的主机提供模式 6 控制消息陷阱服务。陷阱服务是 ntpdq 控制消息协议的子系统，用于远程事件日志记录程序。 nopeer ：用于阻止主机尝试与服务器对等，并允许欺诈性服务器控制时钟 kod ： 访问违规时发送 KoD 包。 restrict -6 表示IPV6地址的权限设置。 接着注释掉原来的server内容，加入以下两句 12345678# Use public servers from the pool.ntp.org project.# Please consider joining the pool (http://www.pool.ntp.org/join.html).#server 0.centos.pool.ntp.org iburst#server 1.centos.pool.ntp.org iburst#server 2.centos.pool.ntp.org iburst#server 3.centos.pool.ntp.org iburstserver 127.127.1.0fudge 127.127.1.0 stratum 10 server指定从哪个ntp服务器同步时间，由于这里是ntp服务器，所以只指定同步自己。 ntp客户端配置客户端的配置只需指定向ntp服务器同步时间即可。比如上面配置的ntp服务器地址为10.1.13.111，则只需要加入server 10.1.13.111即可 1234567# Use public servers from the pool.ntp.org project.# Please consider joining the pool (http://www.pool.ntp.org/join.html).#server 0.centos.pool.ntp.org iburst#server 1.centos.pool.ntp.org iburst#server 2.centos.pool.ntp.org iburst#server 3.centos.pool.ntp.org iburstserver 10.1.13.111 启动服务配置好了只需启动服务端和客户端的ntp服务,设置开机启动即可 12service ntpd startchkconfig ntpd on 这里的ntp服务占用UDP的123端口，当服务启动失败可以看看是否端口被占用 1netstat -nulp | grep 123 并且要保证防护墙的UDP的123端口开放 如果不开启ntp服务自动对时的话，也可以自己设置定时任务自动对时，只启动ntp服务器，客户端可以通过crontab -e设置定时任务通过ntpdate对时。 12crontab -e* */1 * * * /usr/sbin/ntpdate 10.1.18.221 &gt;/dev/null 2&gt;&amp;1 但是这种方法不推荐，最好采用上面启动ntp服务自动对时]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>ntp</tag>
        <tag>集群</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MapReduce 多路径输出]]></title>
    <url>%2FMapReduce-%E5%A4%9A%E8%B7%AF%E5%BE%84%E8%BE%93%E5%87%BA.html</url>
    <content type="text"><![CDATA[mapreduce中实现多路径输出主要使用MulitipleOutputs类通过两个例子可以掌握 输入样例 mulitipleInput.txt1234567file1 001file2 002file3 003file2 004file1 005file1 006file3 007 输出：file1和file3开头的记录归到一个文件下file2和file3开头的记录归到一个文件下 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374import java.io.IOException;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.conf.Configured;import org.apache.hadoop.fs.Path;import org.apache.hadoop.io.NullWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Job;import org.apache.hadoop.mapreduce.Mapper;import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;import org.apache.hadoop.mapreduce.lib.output.MultipleOutputs;import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;import org.apache.hadoop.util.GenericOptionsParser;import org.apache.hadoop.util.Tool;import org.apache.hadoop.util.ToolRunner;public class MultipleOutputsExample extends Configured implements Tool&#123; public static class MultipleMapper extends Mapper&lt;Object, Text, Text, NullWritable&gt;&#123; private MultipleOutputs&lt;Text, NullWritable&gt; mos; @Override protected void setup(Mapper&lt;Object, Text, Text, NullWritable&gt;.Context context) throws IOException, InterruptedException &#123; // TODO Auto-generated method stub mos = new MultipleOutputs&lt;Text, NullWritable&gt;(context); &#125; @Override protected void map(Object key, Text value, Mapper&lt;Object, Text, Text, NullWritable&gt;.Context context) throws IOException, InterruptedException &#123; // TODO Auto-generated method stub String[] infos = value.toString().split(" "); if(infos[0].equals("file1"))&#123; mos.write("file1", value, NullWritable.get()); &#125;else if (infos[0].equals("file2")) &#123; mos.write("file2", value, NullWritable.get()); &#125; else &#123; mos.write("file1", value, NullWritable.get()); mos.write("file2", value, NullWritable.get()); &#125; &#125; @Override protected void cleanup(Mapper&lt;Object, Text, Text, NullWritable&gt;.Context context) throws IOException, InterruptedException &#123; // TODO Auto-generated method stub mos.close(); &#125; &#125; @Override public int run(String[] args) throws Exception &#123; // TODO Auto-generated method stub Configuration conf = new Configuration(); String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs(); if (otherArgs.length &lt; 2)&#123; System.err.println("Usage: Data Deduplication &lt;in&gt; &lt;out&gt;"); System.exit(2); &#125; Job job = Job.getInstance(conf); job.setJarByClass(MultipleOutputsExample.class); job.setMapperClass(MultipleMapper.class); job.setOutputKeyClass(Text.class); job.setOutputValueClass(NullWritable.class); MultipleOutputs.addNamedOutput(job, "file1", TextOutputFormat.class, Text.class, NullWritable.class); MultipleOutputs.addNamedOutput(job, "file2", TextOutputFormat.class, Text.class, NullWritable.class); FileInputFormat.addInputPath(job, new Path(otherArgs[0])); FileOutputFormat.setOutputPath(job, new Path(otherArgs[1])); return job.waitForCompletion(true)? 0:1; &#125; public static void main(String[] args) throws Exception &#123; System.exit(ToolRunner.run(new MultipleOutputsExample(), args)); &#125;&#125; 结果12345678910111213$ hadoop fs -cat /user/test/wordTest/mulitipleOutput/file1-m-00000file1 001file3 003file1 005file1 006file3 007$ hadoop fs -cat /user/test/wordTest/mulitipleOutput/file2-m-00000file2 002file3 003file2 004file3 007file2 008 如果想把file1和file2的内容放入不同的目录下，可以通过指定baseOutputPath，将file1开头的文件放在同一个目录中管理。将mos.write(&quot;file1&quot;, value, NullWritable.get());和mos.write(&quot;file2&quot;, value, NullWritable.get());改为mos.write(&quot;file1&quot;, value, NullWritable.get(),&quot;file1/part&quot;);和mos.write(&quot;file2&quot;, value, NullWritable.get()，&quot;file2/part&quot;);或mos.write(value, NullWritable.get(),&quot;file1/part&quot;);和mos.write(value, NullWritable.get()，&quot;file2/part&quot;);可以看到输出结果 123456$ hadoop fs -ls /user/test/wordTest/mulitipleOutputFound 4 items-rw-r--r-- 3 hdfs hdfs 0 2018-06-30 16:18 /user/test/wordTest/mulitipleOutput/_SUCCESSdrwxr-xr-x - hdfs hdfs 0 2018-06-30 16:18 /user/test/wordTest/mulitipleOutput/file1drwxr-xr-x - hdfs hdfs 0 2018-06-30 16:18 /user/test/wordTest/mulitipleOutput/file2-rw-r--r-- 3 hdfs hdfs 0 2018-06-30 16:18 /user/test/wordTest/mulitipleOutput/part-r-00000 指定baseOutputPath输出路径和输出文件名直接按照baseOutPutPath指定，但是默认输出文件名后缀会跟上-r-00000，如果想更改可以继承FileOutputFormat重写RecordWriter实现。]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hadoop 小文件的处理]]></title>
    <url>%2FHadoop-%E5%B0%8F%E6%96%87%E4%BB%B6%E7%9A%84%E5%A4%84%E7%90%86.html</url>
    <content type="text"><![CDATA[hadoop的HDFS和MapReduce本身都是用户处理大量数据的大文件，对于小文件来说，由于namenode会在记录每个block对象，如果存在大量的小文件，会占用namenode的大量内存空间，而且HDFS存储文件是按block来存储，即使一个文件的大小不足一个block的大小，文件还是会占用一个block的存储空间，所以大量的小文件会对HDFS的存储和访问都带来不利的影响。 hadoop对于小文件的处理主要有Hadoop Archive，Sequence file和CombineFileInputFormat三种方式。 Hadoop ArchiveHadoop Archive是hadoop的归档命令，可以将hdfs上的小文件打包成一个har文件，这种方式虽然不会减少小文件占用大量存储空间的问题，但是会减少namenode的内存空间。同时har文件支持hdfs命令对其的访问。 命令：hadoop archive -archiveName 归档名称 -p 父目录 [-r &lt;复制因子&gt;] 原路径（可以多个） 目的路径 -archiveNames设置归档生成文件的名字 -p 需要进行归档的文件的父目录 例子：123456789$ hadoop fs -ls /user/test/yhj/input/Found 3 items-rw-r--r-- 3 root hdfs 760 2018-07-04 11:48 /user/test/yhj/input/word1.txt-rw-r--r-- 3 root hdfs 82 2018-07-04 11:48 /user/test/yhj/input/word2.txt-rw-r--r-- 3 root hdfs 1738 2018-07-04 11:48 /user/test/yhj/input/word3.txt$ hadoop archive -archiveName word.har -p /user/test/yhj/input/ word1.txt word2.txt word3.txt /user/test/yhj/harInput/$ hadoop fs -ls /user/test/yhj/harInput/Found 1 itemsdrwxr-xr-x - hdfs hdfs 0 2018-07-05 20:18 /user/test/yhj/harInput/word.har HAR文件的生成是通过运行一个mapreduce的程序生成，所以需要集群环境中装个mapreduce HAR是在Hadoop file system之上的一个文件系统，因此所有fs shell命令对HAR文件均可用，但使用不同的URI。另外，请注意档案是不可变的。所以，重命名，删除并创建返回一个错误，例如：1234567891011$ hadoop fs -ls /user/test/yhj/harInput/word.harFound 4 items-rw-r--r-- 3 hdfs hdfs 0 2018-07-05 20:18 /user/test/yhj/harInput/word.har/_SUCCESS-rw-r--r-- 5 hdfs hdfs 255 2018-07-05 20:18 /user/test/yhj/harInput/word.har/_index-rw-r--r-- 5 hdfs hdfs 22 2018-07-05 20:18 /user/test/yhj/harInput/word.har/_masterindex-rw-r--r-- 3 hdfs hdfs 2580 2018-07-05 20:18 /user/test/yhj/harInput/word.har/part-0$ hadoop fs -ls har:/user/test/yhj/harInput/word.harFound 3 items-rw-r--r-- 3 hdfs hdfs 760 2018-07-04 11:48 har:///user/test/yhj/harInput/word.har/word1.txt-rw-r--r-- 3 hdfs hdfs 82 2018-07-04 11:48 har:///user/test/yhj/harInput/word.har/word2.txt-rw-r--r-- 3 hdfs hdfs 1738 2018-07-04 11:48 har:///user/test/yhj/harInput/word.har/word3.txt 可以看到Hadoop存档目录包含元数据（采用_index和_masterindex形式）、数据部分data（part- *）文件、归档文件的名称和部分文件中的位置（_index文件）。 HAR文件也可以被mapreduce读取，路径的URI可以使用不同的URI,比如例子中的文件输入的路径URI可以下面两种方式使用12hdfs://10.1.13.111:8020/user/test/yhj/harInput/word.harhar://hdfs-10.1.13.111:8020/user/test/yhj/harInput/word.har 但是这个例子的文件来说，两个输入路径产生map的个数是不同的，har的路径产生的map有三个，对应三个word*.txt,而hdfs的路径只有一个，对应word.har/part-0 如果是文件支持行记录切分使用mapreduce来处理数据（文件的前后数据不相互影响），建议使用hdfs的URI路径,因为存档目录的part-*可能包括多个小文件的数据，这样可以减少map的个数，不会为每个单独的小文件启动一个map。 CombineFileInputFormat将大量小文件做为mapreduce的输入是不合适的，因为FileInputFormat只会分割大文件（文件大小超过设定的分片大小，默认为HDFS的块大小），对于小于分片大小的文件，每个文件作为一个分片，如果文件大小小于一个块的大小，mapreduce会为每个小文件产生一个map，这样会产生大量小文件，而每个map只会处理少量数据，每次map操作都会产生开销。当然可以通过mapred.min.split.size和mapred.max.split.size来控制map数量。 CombineFileInputFormat是mapreduce针对小文件而设计的，CombineFileInputFormat可以将多个小文件打包进一个分片，另外，比直接设置map数量好的在于，CombineFileInputFormat在决定将那些块放入一个分片是会考虑到块所在的节点和机架的位置，避免操作分片是过多的数据传输。 CombineFileInputFormat是一个抽象类，hadoop自带的实现的有CombineTextInputFormat，我们可以通过继承CombineFileInputFormat实现createRecordReader方法，自定义RecordReader类来实现理海量小文件的MapReduce。 InputFormat主要有两个方法，getSplits（计算得到分片），createRecordReader（产生返回RecordReader，RecordReader生成输出map读入的键值对） CombineFileInputFormat中已经实现了getSplits，即将多个小文件打包进一个分片中CombineFileSplit，我们需要实现createRecordReader方法，返回一个可以读取该分片中内容的RecordReader。 MyCombineInputFormat的实现123456789101112public class MyCombineInputFormat extends CombineFileInputFormat&lt;LongWritable, Text&gt;&#123; @Override public RecordReader createRecordReader(InputSplit inputSplit, TaskAttemptContext taskAttemptContext) throws IOException &#123; RecordReader&lt;LongWritable, Text&gt; reader = new CombineFileRecordReader&lt;&gt;((CombineFileSplit) inputSplit, taskAttemptContext, MyCombineFileRecordReader.class); try &#123; reader.initialize(inputSplit, taskAttemptContext); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return reader; &#125;&#125; 这里实际返回了一个CombineFileRecordReader的对象，CombineFileRecordReader通过CombineFileSplit，context和Class&lt;? extends RecordReader&gt;类型构造，MyCombineFileRecordReader是我们对于CombineFileSplit中每一个文件的产生map的输入的方法。CombineFileRecordReader中的nextKeyValue方法，会为每一个打包在CombineFileSplit中的文件构造一个RecordReader方法，读取文件中的记录。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public class CombineFileRecordReader&lt;K, V&gt; extends RecordReader&lt;K, V&gt; &#123; ... public CombineFileRecordReader(CombineFileSplit split, TaskAttemptContext context, Class&lt;? extends RecordReader&lt;K, V&gt;&gt; rrClass) throws IOException &#123; this.split = split; this.context = context; this.idx = 0; this.curReader = null; this.progress = 0L; try &#123; this.rrConstructor = rrClass.getDeclaredConstructor(constructorSignature); this.rrConstructor.setAccessible(true); &#125; catch (Exception var5) &#123; throw new RuntimeException(rrClass.getName() + " does not have valid constructor", var5); &#125; this.initNextRecordReader(); &#125; protected boolean initNextRecordReader() throws IOException &#123; if(this.curReader != null) &#123; this.curReader.close(); this.curReader = null; if(this.idx &gt; 0) &#123; this.progress += this.split.getLength(this.idx - 1); &#125; &#125; if(this.idx == this.split.getNumPaths()) &#123; return false; &#125; else &#123; this.context.progress(); try &#123; Configuration conf = this.context.getConfiguration(); conf.set("mapreduce.map.input.file", this.split.getPath(this.idx).toString()); conf.setLong("mapreduce.map.input.start", this.split.getOffset(this.idx)); conf.setLong("mapreduce.map.input.length", this.split.getLength(this.idx)); this.curReader = (RecordReader)this.rrConstructor.newInstance(new Object[]&#123;this.split, this.context, Integer.valueOf(this.idx)&#125;); if(this.idx &gt; 0) &#123; this.curReader.initialize(this.split, this.context); &#125; &#125; catch (Exception var2) &#123; throw new RuntimeException(var2); &#125; ++this.idx; return true; &#125; public boolean nextKeyValue() throws IOException, InterruptedException &#123; do &#123; if(this.curReader != null &amp;&amp; this.curReader.nextKeyValue()) &#123; return true; &#125; &#125; while(this.initNextRecordReader()); return false; &#125; public K getCurrentKey() throws IOException, InterruptedException &#123; return this.curReader.getCurrentKey(); &#125; public V getCurrentValue() throws IOException, InterruptedException &#123; return this.curReader.getCurrentValue(); &#125; ...&#125; 在nextKeyValue方法中通过自定义的RecordReader的nextKeyValue读取当前文件的对象，当读完当前文件中的信息，后会通过initNextRecordReader返回初始化的下一个文件的RecordReader，所以我们只需实现相应的读取一个文件的RecordReader即可。 MyCombineFileRecordReader的实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class MyCombineFileRecordReader extends RecordReader&lt;LongWritable, Text&gt; &#123; private CombineFileSplit combineFileSplit; private int currentIndex; private LineRecordReader reader = new LineRecordReader(); private int totalNum; public MyCombineFileRecordReader(CombineFileSplit combineFileSplit, TaskAttemptContext context, Integer index)&#123; super(); this.combineFileSplit = combineFileSplit; this.currentIndex = index; this.totalNum = combineFileSplit.getNumPaths(); &#125; @Override public void initialize(InputSplit inputSplit, TaskAttemptContext context) throws IOException, InterruptedException &#123; FileSplit fileSplit = new FileSplit(combineFileSplit.getPath(currentIndex), combineFileSplit.getOffset(currentIndex), combineFileSplit.getLength(currentIndex), combineFileSplit.getLocations()); context.getConfiguration().set("mapreduce.map.input.file.name", fileSplit.getPath().getName()); this.reader.initialize(fileSplit, context); &#125; @Override public boolean nextKeyValue() throws IOException, InterruptedException &#123; if(currentIndex &gt;= 0 &amp;&amp; currentIndex &lt; totalNum)&#123; return reader.nextKeyValue(); &#125;else &#123; return false; &#125; &#125; @Override public LongWritable getCurrentKey() throws IOException, InterruptedException &#123; return reader.getCurrentKey(); &#125; @Override public Text getCurrentValue() throws IOException, InterruptedException &#123; return reader.getCurrentValue(); &#125; @Override public float getProgress() throws IOException, InterruptedException &#123; if(currentIndex &gt;= 0 &amp;&amp; currentIndex &lt; totalNum)&#123; return (float)currentIndex/totalNum; &#125; return 0; &#125; @Override public void close() throws IOException &#123; reader.close(); &#125;&#125; MyCombineFileRecordReader中通过LineRecordReader按行来读取文本记录，在initialize方法中通过CombineFileSplit和index（CombineFileSplit中文件信息的索引位置）来得到相应文件的信息，创建对应的FileSplit，接着创建LineRecordReader对象，在nextKeyValue中委托给LineRecordReader为mapper产生键-值对象。 最后入口函数和map类的实现，将InputFormatClass替换成自定义的MyCombineInputFormat类1234567891011121314151617181920212223242526272829public class CombineInputFromatMain extends Configured implements Tool&#123; public static class CombineInputFormatMap extends Mapper&lt;Object, Text, Text, Text&gt;&#123; private Text outKey = new Text(); @Override protected void map(Object key, Text value, Context context) throws IOException, InterruptedException &#123; outKey.set(context.getConfiguration().get("mapreduce.map.input.file.name")); context.write(outKey, value); &#125; &#125; @Override public int run(String[] args) throws Exception &#123; //设定默认job和设置输入输出路径的函数 Job job = JobDefaultInit.getClusterDefaultJob(this, getConf(), args); job.setJobName("CombineInputFormat Text"); job.setJarByClass(CombineInputFromatMain.class); job.setMapperClass(CombineInputFormatMap.class); job.setOutputKeyClass(Text.class); job.setOutputValueClass(Text.class); job.setNumReduceTasks(0); job.setInputFormatClass(MyCombineInputFormat.class); return job.waitForCompletion(true) ? 0:1; &#125; public static void main(String[] args) throws Exception &#123; System.exit(ToolRunner.run(new CombineInputFromatMain(), args)); &#125;&#125; 在这例子中将三个word*.txt文件打包进一个分片，实际只产生了一个map。 Sequence filesequence file由一系列的二进制key/value组成，如果为key小文件名，value为文件内容，则可以将大批小文件合并成一个大文件。 顺序文件由文件头和随后的记录内容组成，顺序文件的前三个字节为SEQ(顺序文件代码)，紧接着一个字节表示文件的版本号，文件头还包括键和值的类型，数据是否压缩的标志位，是否进行快压缩的标志位， 数据的压缩形式，用户自定义的数据以及同步标识。顺序文件读取内容只能从同步标识开始读取。同步标识位于记录和记录之间，也就是说无法从记录中间开始读取顺序文件的内容。 Sequence file的格式主要有三种，分为未压缩，记录压缩和块压缩。主要格式的存储方式可以查看官方给出的api: http://hadoop.apache.org/docs/current/api/org/apache/hadoop/io/SequenceFile.html 将小文件合并成一个sequence file的实现(代码参考hadoop 权威指南)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117public class SmallFilesToSequenceFileConverter extends Configured implements Tool &#123; public static class WholeFileInputFormat extends FileInputFormat&lt;LongWritable, Text&gt;&#123; /** * 不切分文件，一个split读入整个文件 * @param context * @param filename * @return */ @Override protected boolean isSplitable(JobContext context, Path filename) &#123; return false; &#125; @Override public RecordReader&lt;LongWritable, Text&gt; createRecordReader(InputSplit inputSplit, TaskAttemptContext taskAttemptContext) throws IOException, InterruptedException &#123; RecordReader reader = new WholeFileRecordReader(); reader.initialize(inputSplit, taskAttemptContext); return reader; &#125; &#125; /** * 自定义RecordReader，读取整个小文件内容 */ public static class WholeFileRecordReader extends RecordReader&lt;LongWritable, Text&gt;&#123; private FileSplit fileSplit; private Configuration conf; private LongWritable key = new LongWritable(); private Text value = new Text(); private boolean process = false; @Override public void initialize(InputSplit inputSplit, TaskAttemptContext taskAttemptContext) throws IOException, InterruptedException &#123; this.fileSplit = (FileSplit)inputSplit; this.conf = taskAttemptContext.getConfiguration(); &#125; @Override public boolean nextKeyValue() throws IOException, InterruptedException &#123; if(!process)&#123; FileSystem fs = fileSplit.getPath().getFileSystem(conf); FSDataInputStream in = null; try &#123; in = new FSDataInputStream(fs.open(fileSplit.getPath())); byte[] contextByte = new byte[(int)fileSplit.getLength()]; IOUtils.readFully(in, contextByte, 0, contextByte.length); //等同于 in.read(contextByte, 0, contextByte.length); String context = new String(contextByte, "utf-8"); key.set(fileSplit.getStart()); value.set(context); &#125;finally &#123; IOUtils.closeStream(in); &#125; process = true; return true; &#125; return false; &#125; @Override public LongWritable getCurrentKey() throws IOException, InterruptedException &#123; return key; &#125; @Override public Text getCurrentValue() throws IOException, InterruptedException &#123; return value; &#125; @Override public float getProgress() throws IOException, InterruptedException &#123; return process? 1.0f:1.0f; &#125; @Override public void close() throws IOException &#123; &#125; &#125; public static class SmallFilesToSequenceFileMap extends Mapper&lt;Object, Text, Text, Text&gt;&#123; private Text outKey = new Text(); @Override protected void setup(Context context) throws IOException, InterruptedException &#123; outKey.set(((FileSplit)context.getInputSplit()).getPath().toString()); &#125; @Override protected void map(Object key, Text value, Context context) throws IOException, InterruptedException &#123; context.write(outKey, value); &#125; &#125; @Override public int run(String[] args) throws Exception &#123; //设定默认job和设置输入输出路径的函数 Job job = JobDefaultInit.getClusterDefaultJob(this, getConf(), args); job.setJobName("SmallFiles To SequenceFile"); job.setMapperClass(SmallFilesToSequenceFileMap.class); job.setInputFormatClass(WholeFileInputFormat.class); job.setOutputFormatClass(SequenceFileOutputFormat.class); job.setOutputKeyClass(Text.class); job.setOutputValueClass(Text.class); return job.waitForCompletion(true)? 0:1; &#125; public static void main(String[] args) throws Exception &#123; System.exit(ToolRunner.run(new SmallFilesToSequenceFileConverter(), args)); &#125;&#125; hdfs可以通过命令行hadoop fs -text来显示以文本的方式显示顺序文件 读取SequenceFile简单实现1234567891011121314151617181920212223242526272829public class SequenceFileReadMain extends Configured implements Tool&#123; public static class SequenceFileReadMap extends Mapper&lt;Text, Text, Text, Text&gt;&#123; private Text outKey = new Text(); private Text outValue = new Text(); @Override protected void map(Text key, Text value, Context context) throws IOException, InterruptedException &#123; outKey.set("key : " + key.toString()); outValue.set("value : " + value.toString()); context.write(outKey, outValue); &#125; &#125; @Override public int run(String[] args) throws Exception &#123; Job job = JobDefaultInit.getClusterDefaultJob(this, getConf(), args); job.setJobName("Sequence File Read"); job.setMapperClass(SequenceFileReadMap.class); job.setOutputKeyClass(Text.class); job.setOutputValueClass(Text.class); job.setInputFormatClass(SequenceFileInputFormat.class); job.setOutputFormatClass(TextOutputFormat.class); return job.waitForCompletion(true)?0:1; &#125; public static void main(String[] args) throws Exception&#123; System.exit(ToolRunner.run(new SequenceFileReadMain(), args)); &#125;&#125; 这时候读取SequenceFile的时候，key对应的是小文件的名字，value是一个小文件的所有内容，所以需要在map编写处理整个小文件内容的代码 参考资料：https://blog.csdn.net/u011007180/article/details/52333387 https://www.cnblogs.com/staryea/p/8603112.html http://dongxicheng.org/mapreduce/hdfs-small-files-solution/]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[mapreduce 排序]]></title>
    <url>%2Fmapreduce-%E6%8E%92%E5%BA%8F.html</url>
    <content type="text"><![CDATA[mapreduce的排序主要分部分排序、全排序和辅助排序（二次排序） 可以直接在reduce中在对数据进行排序，但是这对于reduce的负担太重，数据处理的时间消耗也会大大增加 mapreduce机制中排序只会针对键进行排序，所以如果想对某个数据进行排序，一定要将其设置为map输出的键，排序主要发生在map的spill和合并spill file阶段和reduce拉取复制map端的数据后合并成reduce文件时。 排序的设置和调用的顺序排序类及其方法调用主要遵循以下顺序： 如果设置mapreduce.job.output.key.comparator.class或设置了Job类的setSortComparatorClass(),则会使用设置的类的实例进行排序。该类需要继承WritableComparator 如果1中没有设置，键的类型是WritableComparable的子类，就会调用该键的compareTo（)的方法 如果上述都RawComparator将字节流反序列化为WritableComparable对象，再调用其compareTo（)进行比较 从以上可以看出，如果重写RawComparator的compare方法，在字节流的时候就进行所需的键的比较是性能最好的，因为这样无需在排序进行反序列化，但编写的难度相对较高。 部分排序mapreduce根据键的排序使得每个reduce输出的文件都是排序好的 全排序对于全排序最简单的方法是将所有的方法是将reduce的个数设置为1，但是如果数据量太大会对reduce造成过大的负担。 解决的方法可以通过改写partition来调整使得每个reduce之间数据保持有序，即保证一段连续区间内的数据都落在一个分区里，这样只要对reduce的输出文件排好序就可以达到全局排序。但是如果靠人为的划分分区，需要知道键的范围，并且很容易造成数据的倾斜，造成有的reduce分到数据特别多，而有的却很少，理想情况下是个分区记录数大致相等。解决方法是通过多数据进行采样，通过采样一小部分数据得到排序数据的大致分布，从而制定出如何划分分区。 hadoop内置了若干采样器，用于需要实现自定义采样的话需要继承InputSampler类(该类实现了Sampler接口)重写getSample方法，返回采样的键。InputSampler实现了静态方法writePartitionFile()方法来在致指定的hdfs路径下创建一个顺序文件来存储定义分区的键。将顺序文件加入分布式缓存，由TotalOrderPartitioner使用并未排序作业创建分区。 例子，使用采样分区的方式对一系列随机生成的服从正态分布的数据进行全排序。 原始输入数据，满足正态分布，随机生成 1234567891011hadoop fs -cat /user/test/yhj/random/input/random.txt | head12816584491071195471-4229131970634916817-557165-14358191924747-262067 重写InputFormat和RecordReader使直接读入的值是IntWritable类型 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public static class MyFileIntputFormat extends FileInputFormat&lt;LongWritable, IntWritable&gt;&#123; @Override public RecordReader&lt;LongWritable, IntWritable&gt; createRecordReader(InputSplit inputSplit, TaskAttemptContext taskAttemptContext) throws IOException, InterruptedException &#123; RecordReader&lt;LongWritable, IntWritable&gt; reader = new MyRecordReader(); reader.initialize(inputSplit, taskAttemptContext); return reader; &#125; &#125; public static class MyRecordReader extends RecordReader&lt;LongWritable, IntWritable&gt;&#123; private LineRecordReader lineRecordReader; public MyRecordReader()&#123; lineRecordReader = new LineRecordReader(); &#125; @Override public void initialize(InputSplit inputSplit, TaskAttemptContext taskAttemptContext) throws IOException, InterruptedException &#123; lineRecordReader.initialize(inputSplit, taskAttemptContext); &#125; @Override public boolean nextKeyValue() throws IOException, InterruptedException &#123; return lineRecordReader.nextKeyValue(); &#125; @Override public LongWritable getCurrentKey() throws IOException, InterruptedException &#123; return lineRecordReader.getCurrentKey(); &#125; @Override public IntWritable getCurrentValue() throws IOException, InterruptedException &#123; IntWritable value = new IntWritable(Integer.parseInt(lineRecordReader.getCurrentValue().toString())); return value; &#125; @Override public float getProgress() throws IOException, InterruptedException &#123; return lineRecordReader.getProgress(); &#125; @Override public void close() throws IOException &#123; lineRecordReader.close(); &#125; &#125; 由于默认的采样器都是对键进行采样，而我们读入的键是偏移量，真正排序采样的是值，所以需要重写采样器，这里继承了RandomSampler，对值进行随机采样，RandomSampler的初始化需要三个参数RandomSampler(double freq, int numSamples, int maxSplitsSampled) freq代表采样频率，numSamples代表样本最大样本数，maxSplitsSampled代表最大分区数。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public static class MySample extends InputSampler.RandomSampler&lt;Object, IntWritable&gt;&#123; public MySample(double freq, int numSamples) &#123; super(freq, numSamples); &#125; public MySample(double freq, int numSamples, int maxSplitsSampled)&#123; super(freq, numSamples, maxSplitsSampled); &#125; @Override public IntWritable[] getSample(InputFormat&lt;Object, IntWritable&gt; inf, Job job) throws IOException, InterruptedException &#123; List&lt;InputSplit&gt; splits = inf.getSplits(job); List&lt;IntWritable&gt; samples = new ArrayList&lt;&gt;(); int splitToSample = Math.min(this.numSamples, splits.size()); Random random = new Random(); long seed = random.nextLong(); random.setSeed(seed); //随机交换split for(int i = 0; i &lt; splits.size(); i++)&#123; InputSplit tmp = splits.get(i); int index = random.nextInt(splits.size()); splits.set(i, splits.get(index)); splits.set(index, tmp); &#125; //采样 for(int i = 0; i &lt; splitToSample || i &lt; this.numSamples &amp;&amp; samples.size() &lt; this.numSamples ; i++)&#123; TaskAttemptContext sampleContext = new TaskAttemptContextImpl(job.getConfiguration(), new TaskAttemptID()); RecordReader&lt;Object, IntWritable&gt; reader = inf.createRecordReader(splits.get(i), sampleContext); while (reader.nextKeyValue()) &#123; //根据采样频率采样 if (random.nextDouble() &lt; this.freq) &#123; if (samples.size() &lt; this.numSamples) &#123; IntWritable value = new IntWritable(); samples.add(ReflectionUtils.copy(job.getConfiguration(), reader.getCurrentValue(), value)); &#125; else &#123; int index = random.nextInt(this.numSamples); if (index != this.numSamples) &#123; IntWritable value = new IntWritable(); samples.set(index, ReflectionUtils.copy(job.getConfiguration(), reader.getCurrentValue(), value)); &#125; this.freq *= (double) (this.numSamples - 1) / (double) this.numSamples; &#125; &#125; &#125; reader.close(); &#125; IntWritable[] result = new IntWritable[samples.size()]; samples.toArray(result); return result; &#125; &#125; 入口函数和map函数，reduce函数采用默认实现 12345678910111213141516171819202122232425262728293031323334public class SortByTotalPartitioner extends Configured implements Tool &#123; public static class SortByTotalPartitionerMap extends Mapper&lt;LongWritable, IntWritable, IntWritable, NullWritable&gt;&#123; @Override protected void map(LongWritable key, IntWritable value, Context context) throws IOException, InterruptedException &#123; context.write(value, NullWritable.get()); &#125; &#125; @Override public int run(String[] args) throws Exception &#123; Job job = JobDefaultInit.getSubmintDefaultJob(this, getConf(), "E:\\JavaProjects\\hdpWork\\target\\hdpWork.jar", args);// InputSampler.Sampler&lt;&gt; job.setMapperClass(SortByTotalPartitionerMap.class); job.setInputFormatClass(MyFileIntputFormat.class); job.setOutputKeyClass(IntWritable.class); job.setOutputValueClass(NullWritable.class); job.setPartitionerClass(TotalOrderPartitioner.class); job.setNumReduceTasks(3); InputSampler.Sampler&lt;Object, IntWritable&gt; sampler = new MySample(0.1, 1000, 10); //构造采样器 TotalOrderPartitioner.setPartitionFile(job.getConfiguration(), new Path("/partitionFile")); //设置共享分区文件路径 InputSampler.writePartitionFile(job, sampler); //写入分区文件,其中调用了 TotalOrderPartitioner.getPartitionFile获取文件路径 //将共享分区文件加入到分布式缓存中 String partitionFile = TotalOrderPartitioner.getPartitionFile(job.getConfiguration()); URI partitionUri = new URI(partitionFile); job.addCacheFile(partitionUri); return job.waitForCompletion(true) ? 0:1; &#125; public static void main(String[] args) throws Exception&#123; System.exit(ToolRunner.run(new SortByTotalPartitioner(), args)); &#125;&#125; 辅助排序有时候我们需要对键和值一起参与排序或者排序收到两个数据的共同影响，由于mapreduce只能支持对键排序，所以只能自定义Writable类型，支持存储多种数据，并重写compareTo()方法或者通过setSortComparatorClass()设置二次排序的方式。由于reduce的输入是key和value的迭代器，默认reduce是将键相同的值放在一个迭代器中，而由于二次排序修改了键的比较方法，因此有时候需要修改分组排序，job.setGroupingComparatorClass设置分组排序，通过分组比较器判断为相同即返回为0的代表在同一组中，这时候的分组的键将会取组中第一个的键，也就是排好序后组中第一个的键。 例子，选取下面数据中，每一年的最高温度 1234567891011121314151617181920212223242526271990 281995 341992 -121994 21995 121993 341992 321993 11994 81995 231993 241993 421994 321992 301991 221993 261990 281992 111990 181994 161992 151994 41990 281995 51990 281992 31990 28 我们需要将年份和温度都参与排序，因此需要自定义Writable类型，同时存储、序列化年份和温度 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112import org.apache.hadoop.io.IntWritable;import org.apache.hadoop.io.WritableComparable;import org.apache.hadoop.io.WritableComparator;import java.io.DataInput;import java.io.DataOutput;import java.io.IOException;public class IntPairWritable implements WritableComparable&lt;IntPairWritable&gt; &#123; int year; int tempeture; public IntPairWritable()&#123; year = 0; tempeture = 0; &#125; public IntPairWritable(IntWritable year, IntWritable tempeture)&#123; this.year = year.get(); this.tempeture = tempeture.get(); &#125; public IntPairWritable(int year, int tempeture)&#123; this.year = year; this.tempeture = tempeture; &#125; public int getYear() &#123; return year; &#125; public int getTempeture() &#123; return tempeture; &#125; public void setYear(int year) &#123; this.year = year; &#125; public void setTempeture(int tempeture) &#123; this.tempeture = tempeture; &#125; @Override public boolean equals(Object obj) &#123; if(!(obj instanceof IntPairWritable))&#123; return false; &#125; IntPairWritable other = (IntPairWritable)obj; return other.year == year &amp;&amp; other.tempeture == tempeture; &#125; @Override public int compareTo(IntPairWritable o) &#123; int cmp = year - o.getYear(); if(cmp != 0)&#123; return cmp; &#125; return tempeture - o.getTempeture(); &#125; /** * 序列化到输出流中 * @param dataOutput * @throws IOException */ @Override public void write(DataOutput dataOutput) throws IOException &#123; dataOutput.writeInt(year); dataOutput.writeInt(tempeture); &#125; /** * 从输入流中反序列化读入 * @param dataInput * @throws IOException */ @Override public void readFields(DataInput dataInput) throws IOException &#123; year = dataInput.readInt(); tempeture = dataInput.readInt(); &#125; @Override public int hashCode() &#123; return new Integer(year).hashCode()*163 + new Integer(tempeture).hashCode(); &#125; @Override public String toString() &#123; return year + "\t" + tempeture; &#125; /** * 自定义Writable类型的排序比较器 */ public static class Comparator extends WritableComparator&#123; public Comparator()&#123; super(IntPairWritable.class, true); &#125; @Override public int compare(WritableComparable a, WritableComparable b) &#123; int tmp = ((IntPairWritable)a).getYear() - ((IntPairWritable)b).getYear(); if(tmp != 0)&#123; return tmp; &#125; return - (((IntPairWritable)a).getTempeture() - ((IntPairWritable)b).getTempeture()); &#125; &#125;&#125; 按照年份来分区和分组 123456789/** * 只按照年份来分区 */public static class YearPartition extends Partitioner&lt;IntPairWritable, NullWritable&gt;&#123; @Override public int getPartition(IntPairWritable intPairWritable, NullWritable nullWritable, int i) &#123; return Math.abs(intPairWritable.getYear()) % i; &#125;&#125; 12345678910111213/** * 分组只按照年份来比较 */public static class GroupComparator extends WritableComparator&#123; public GroupComparator()&#123; super(IntPairWritable.class, true); &#125; @Override public int compare(WritableComparable a, WritableComparable b) &#123; return ((IntPairWritable)a).getYear() - ((IntPairWritable)b).getYear(); &#125;&#125; 这样同年份的数据会在同个分区中，也就是在一个reduce下，reduce的分组是按照年份来比较的，那么每个分组中的数据的年份是相同的，在年份相同的情况下按照温度从大到下排序，因此每个组的键取的是组中的第一个，也就是该年份下最大温度所在的IntPairWritable map、reduce及其入口函数 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class MaxTemperatureUsingSecondSort extends Configured implements Tool &#123; public static class MaxTemperatureUsingSecondSortMap extends Mapper&lt;LongWritable, Text, IntPairWritable, NullWritable&gt;&#123; IntPairWritable outKey = new IntPairWritable(); @Override protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123; String[] infos = value.toString().split("\t"); outKey.setYear(Integer.parseInt(infos[0])); outKey.setTempeture(Integer.parseInt(infos[1])); context.write(outKey, NullWritable.get()); &#125; &#125; /** * reduce的key存储着该年份下的最高气味 */ public static class MaxTemperatureUsingSecondSortReduce extends Reducer&lt;IntPairWritable, NullWritable, IntPairWritable, NullWritable&gt;&#123; @Override protected void reduce(IntPairWritable key, Iterable&lt;NullWritable&gt; values, Context context) throws IOException, InterruptedException &#123; context.write(key, NullWritable.get()); &#125; &#125; @Override public int run(String[] args) throws Exception &#123; Job job = JobDefaultInit.getSubmintDefaultJob(this, getConf(), "E:\\JavaProjects\\hdpWork\\target\\hdpWork.jar", args); job.setJobName("Max Temperature Using Second Sort"); job.setMapperClass(MaxTemperatureUsingSecondSortMap.class); job.setReducerClass(MaxTemperatureUsingSecondSortReduce.class); job.setPartitionerClass(YearPartition.class); job.setSortComparatorClass(IntPairWritable.Comparator.class); job.setGroupingComparatorClass(GroupComparator.class); job.setOutputKeyClass(IntPairWritable.class); job.setOutputValueClass(NullWritable.class); return job.waitForCompletion(true) ? 1:0; &#125; public static void main(String[] args) throws Exception &#123; System.exit(ToolRunner.run(new MaxTemperatureUsingSecondSort(), args)); &#125;&#125; 程序结果,由于只有一个reduce，因此年份按照排序从小到大，如果想要在多个reduce中保存年份的全局排序，应该按照全区排序编写合适的分区方法 1234561990 281991 221992 321993 421994 321995 34]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>MapReduce</tag>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HDFS扩容]]></title>
    <url>%2Fhdfd%E6%89%A9%E5%AE%B9.html</url>
    <content type="text"><![CDATA[hdfs的存储容量不足，需要放入新磁盘扩容扩容有两种方式，一种是linux层面的，一种是hdfs层面的hdfs的datanode存储的目录可以查看hdfs-site.xml的dfs.datanode.data.dir的值 linux层面linux层面的就是将hdfs的datanode所挂载的分区或逻辑卷扩容 如果是直接挂在固定分区上，而磁盘还有余量可以进行分区扩容 参考：http://blog.51cto.com/wutou/1782931这种直接挂载在分区上的磁盘空间管理方式十分不方便，扩容也很容易出错，而且扩容只有在磁盘还有余量的情况下，无法将两块磁盘的空间结合使用，一块磁盘空间占满，即使加入一块新磁盘也无法对原来磁盘上的分区扩容。所以才会有逻辑卷管理LVM的出现 如果是lvm对磁盘分区进行管理，那么可以方便的创建物理卷，扩容datanode所挂载的逻辑卷所属的卷组接着扩容该逻辑卷，具体操作方式参考: https://linux.cn/article-3218-1.html hdfs层面扩容这种不需要对原来的空间扩容，是修改hdfs-site.xml的dfs.datanode.data.dir的值添加新目录，如 1234567&lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt; /hadoop/hdfs/data, /data/hadoop/hdfs &lt;/value&gt;&lt;/property 将多个目录用逗号隔开，所以只要将新磁盘分区挂载在新目录上（分区方式可以自己决定,最好永久挂载），将需要添加的新目录设置用户权限1chown -R hdfs:hadoop dirPath 修改dfs.datanode.data.dir，重启datanode即可1./bin/hdfs dfsadmin -report 可以查看各个datanode的存储容量 解决数据倾斜但是这种方式只是增加新磁盘到hdfs中，原来的老磁盘空间依旧被占满。如果老磁盘的容量比新磁盘小，当之后hdfs不断添加新数据，老磁盘依旧占满比新磁盘快，为了防止hdfs的存储容量无限扩张占满磁盘，甚至导致系统盘占满，影响这个系统，通过设置dfs.datanode.du.reserved来预留磁盘空间。该参数在hdfs-site.xml中设置。 1234&lt;property&gt; &lt;name&gt;dfs.datanode.du.reserved&lt;/name&gt; &lt;value&gt;32212254720&lt;/value&gt; &lt;/property&gt; 这里设置预留了30G的磁盘空间（参数单位为byte），也就是当磁盘的空间剩余30G及以下时，将不会存放数据副本到该磁盘。 但是这还是没有解决目前刚刚扩容时，老磁盘空间依旧被占满的问题。这里就时需要移动老磁盘的副本到新磁盘，但是目前hdfs并没有提供该功能，因此只能曲线救国，删除一些不必要的文件（一些文件的副本可能存在老磁盘中）。 如果不想动任何数据的情况下，可以采用升降副本的方法，如原来发副本数量为3，降低副本数量为2，这样会删除一些副本，会删除存在老磁盘上从一些副本，接着在升高副本数量到原来发副本数量，这样由于设置了磁盘预留空间，新副本会存放在新磁盘当中,升降副本采用hdfs的setrep -w命令,-R为递归调整整个文件夹下的所有文件。 12hadoop dfs -setrep -w -R 2 pathhadoop dfs -setrep -w -R 3 path 最后使用Hadoop balancer工具来调整各个datanodes的数据平衡。 官方对balancer的描述： The balancer is a tool that balances disk space usage on an HDFS cluster when some datanodes become full or when new empty nodes join the cluster. The tool is deployed as an application program that can be run by the cluster administrator on a live HDFS cluster while applications adding and deleting files. balancer命令详解： 123456789hdfs balancer [-policy &lt;policy&gt;] [-threshold &lt;threshold&gt;] [-exclude [-f &lt;hosts-file&gt; | &lt;comma-separated list of hosts&gt;]] [-include [-f &lt;hosts-file&gt; | &lt;comma-separated list of hosts&gt;]] [-source [-f &lt;hosts-file&gt; | &lt;comma-separated list of hosts&gt;]] [-blockpools &lt;comma-separated list of blockpool ids&gt;] [-idleiterations &lt;idleiterations&gt;] [-runDuringUpgrade] COMMAND_OPTION Description -policy datanode (default): Cluster is balanced if each datanode is balanced. blockpool: Cluster is balanced if each block pool in each datanode is balanced. -threshold Percentage of disk capacity. This overwrites the default threshold. -exclude -f \ Excludes the specified datanodes from being balanced by the balancer. -include -f \ Includes only the specified datanodes to be balanced by the balancer. -source -f \ Pick only the specified datanodes as source nodes. -blockpools The balancer will only run on blockpools included in this list. -idleiterations Maximum number of idle iterations before exit. This overwrites the default idleiterations. -runDuringUpgrade Whether to run the balancer during an ongoing HDFS upgrade. This is usually not desired since it will not affect used space on over-utilized machines. -h --help 这里我只是调小datanode之间的百分比的差 1hdfs balancer -threshold 5 这样可以解决hadoop数据出现不均衡情况。]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>HDFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[非整数0-1背包问题]]></title>
    <url>%2F%E9%9D%9E%E6%95%B4%E6%95%B00-1%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98.html</url>
    <content type="text"><![CDATA[0-1背包问题通常情况下物品的重量是整数的，采用动态规划可以解决，在解决物品重量非整数情况下的背包问题之前，我们先来回顾整数背包问题，并从中寻找解决非整数背包问题的方法。 问题定义：有n种物品和一个容量为$c$的背包，第$i$件物品的重量为$wi$，价格为$vi$,求出哪种物品组合放入背包使物品价值总和最大。 整数0-1背包问题设$p(i,j)$表示在容量为j情况下，将物品$i，i+1…n$组合的放入背包的最优解的值 则其转移方程为 如果 $j&gt;=w_i$ ，$p(i,j) = max(p(i+1,j), p(i+1,j-w_i )+v_i )$ 如果 $j&lt;w_i$ , $p(i,j) = p(i+1,j)$ 可以理解为当$j&lt;w_i$ ,背包无法放下第$i$件物品，所以其最优解和考虑放$i+1$到$n$的物品到容量为j的背包的最优解相同。当$j&gt;=w_i$时，可以选择放和不放第$i$件物品，当不放时背包价值和$p(i+1,j)$相同，当放时背包价值为$p(i+1,j-w_i )$再加上第$i$件物品的价值。 所以整数背包问题可以采用动态规划解决，开辟$n*c$的数组，从下往上不断更新数组的值，得到$p(i,j)$的值，最优解就是$p(0,c)$的值 123456789101112131415161718192021public static int solution(int c, int[] v, int[] w)&#123; if(v.length != w.length)&#123; throw new IllegalArgumentException(); &#125; int n = v.length;int m = c+1; int[][] result = new int[n][m]; for(int i = 0;i &lt; m;i++)&#123; result[n-1][i] = i&gt;=w[n-1]? v[n-1]:0; &#125; for(int i = n-2;i&gt;=0;i--)&#123; for(int j = 0;j &lt; m;j++)&#123; if(j &lt; w[i])&#123; result[i][j] = result[i+1][j]; &#125;else &#123; result[i][j] = Math.max(result[i+1][j], result[i+1][j-w[i]]+v[i]); &#125; &#125; &#125; traceBack(c, v, w, result); return result[0][c];&#125; 路径回溯，找到最优组合 123456789101112131415private static void traceBack(int c, int[]v, int[] w, int[][] p)&#123; int k = c; List&lt;Integer&gt; trace = new ArrayList&lt;&gt;(); int i; for(i = 0;i &lt; p.length-1;i++)&#123; if(p[i][k] == p[i+1][k-w[i]]+v[i])&#123; k = k - w[i]; trace.add(i+1); &#125; &#125; if(p[i][k] == v[i])&#123; trace.add(i+1); &#125; System.out.println(trace);&#125; 整数0-1背包问题的改进例如背包的容量为10，5件物品的重量分别为2，2，6，5，4 ，对应价值分别是6，3，5，4，6，则$p(i,j)​$数组的更新情况如下 weight value 1 2 3 4 5 6 7 8 9 10 2 6 0 6 6 9 9 12 12 15 15 15 2 3 0 3 3 6 6 9 9 9 10 11 6 5 0 0 0 6 6 6 6 6 10 11 5 4 0 0 0 6 6 6 6 6 10 10 4 6 0 0 0 6 6 6 6 6 6 6 当背包的容量很大（即c的值特别大），则这个数组将会异常的庞大，并且数组的每一个数都需要更新，算法需要的计算时间较多。 所以可以进行适当的改进，从上面的表格来看，我们无需记录数组种的每一个数，只需要记录下每行的跳跃点即可，比如最后一行从第4列开始跳跃，我们只需记录{(0,0),(4,6)}即可,倒数第二行只需记录{(0,0),(4,6),(9,10)}即可。接下来的问题是如何更新每行的跳跃点。 p[5] = {(0,0),(4,6)} 将p[5]的跳跃点加上下一个需要放入的物品的重量和价值，则可以得到q[5] = p[5]+(5,4) = {(5,4),(9,10)}, 将p[5]和q[5]合并得到{(0,0),(4,6),(5,4),(9,10)}，之后去除重量大却价值小的点，如(5,4)点，放入背包的物品总重量大于4，价值却只有4小于6，所以通过比较(5,4)和(4,6)需要去掉(5,4)得到p[4] = {(0,0),(4,6),(9,10)} 非整数0-1背包问题非整数0-1背包问题可以转化为整数0-1背包问题，如果非整数可以用保留三位小数来表示的话，那么可以将非整数背包问题的所有值乘上1000,全部转为整数，采用整数背包问题解决，但是这样必须牺牲一定的精度，而且会增加开辟数组的大小（乘上1000，数组的列肯定超过1000以上），这对计算时间也有很大影响，因为需要更新每一个数组中的元素。 有效的解决方法和上述对于整数0-1背包问题的改进是一样的，而且发现上述的跳跃点并不要求是整数，对于实数一样适用，因此可以采用更新跳跃点的动态规划的方式解决非整数0-1背包问题。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public static double solution(double c, double[] v, double[] w)&#123; if(v.length != w.length)&#123; throw new IllegalArgumentException(); &#125; double[][] p = new double[10000][2]; int n = v.length; p[0][0] = 0;p[0][1] = 0; int left = 0, right = 0,next = 1; int[] head = new int[n+2]; head[n+1] = 0; head[n] = 1; for(int i = n-1; i &gt;= 0;i--)&#123; int k = left; for(int j = left; j &lt;= right;j++)&#123; if(p[j][0] + w[i] &gt; c)&#123; break; &#125; double nw = p[j][0] + w[i]; double nv = p[j][1] + v[i]; //放入比nw小的跳跃点，因为重量小的价值无论大小 for(;k&lt;=right &amp;&amp; p[k][0] &lt; nw;k++,next++)&#123; p[next][0] = p[k][0]; p[next][1] = p[k][1]; &#125; //如果重量相等，取价值大的跳跃点 if(k &lt;= right &amp;&amp; p[k][0] == nw)&#123; if(p[k][1] &gt; nv)&#123; nv = p[k][1]; &#125; k++; &#125; //放入更新的跳跃点 if(nv &gt; p[next-1][1])&#123; p[next][0] = nw; p[next][1] = nv; next++; &#125; /*去除比更新的跳跃点重量大却价值小的点， 由于是每一次更新完之后结果都是重量和价值都是递增的跳跃点排列 一旦出现价值超过当前的点，那后续的点一定都是超过的*/ for(;k &lt;= right &amp;&amp; p[k][1] &lt;= nv;k++); &#125; //将后续的点放入 for (;k &lt;= right; k++,next++)&#123; p[next][0] = p[k][0]; p[next][1] = p[k][1]; &#125; left = right+1;right = next - 1;head[i] = next; &#125; traceBack(v, w, p, head); return p[next-1][1];&#125; 路径回溯，找到最优组合 1234567891011121314151617private static void traceBack(double[] v, double[] w, double[][] p, int[] head)&#123; List&lt;Integer&gt; trace = new ArrayList&lt;&gt;(); int k = head[0]-1; int n = w.length; for(int i = 1;i &lt;= n;i++)&#123; int left = head[i+1]; int right = head[i]-1; for(int j = left;j&lt;=right;j++)&#123; if(p[j][0] + w[i-1] == p[k][0] &amp;&amp; p[j][1] + v[i-1] == p[k][1])&#123; k = j; trace.add(i); break; &#125; &#125; &#125; System.out.println(trace);&#125; 如果不考虑放入哪些物品（即不考虑路径回溯），之关心最优解的值，可以只存放当前的跳跃点集和下一步的跳跃点集，无需记录每一步的跳跃点集 12345678910111213141516171819202122232425262728293031323334353637public static double solution2(double c, double[] v, double[] w)&#123; if(v.length != w.length)&#123; throw new IllegalArgumentException(); &#125; int n = v.length; List&lt;double[]&gt; p = new ArrayList&lt;&gt;(); p.add(new double[]&#123;0, 0&#125;); for(int i = n - 1; i &gt;= 0;i--)&#123; int k = 0; List&lt;double[]&gt; q = new ArrayList&lt;&gt;(); for(double[] element: p)&#123; if(w[i] + element[0] &gt; c)&#123; break; &#125; double nw = w[i] + element[0]; double nv = v[i] + element[1]; for(;k &lt; p.size() &amp;&amp; p.get(k)[0] &lt; nw;k++)&#123; q.add(p.get(k)); &#125; if(k &lt; p.size() &amp;&amp; p.get(k)[0] == nw)&#123; if(p.get(k)[1] &gt; nv)&#123; nv = p.get(k)[1]; &#125; k++; &#125; if(nv &gt; q.get(q.size()-1)[1])&#123; q.add(new double[]&#123;nw, nv&#125;); &#125; for(;k &lt; p.size() &amp;&amp; p.get(k)[1] &lt; nv;k++); &#125; for(;k &lt; p.size();k++)&#123; q.add(p.get(k)); &#125; p = q; &#125; return p.get(p.size()-1)[1];&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>背包问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop的RPC分析]]></title>
    <url>%2FHadoop%E7%9A%84RPC%E5%88%86%E6%9E%90.html</url>
    <content type="text"><![CDATA[RPCRPC就是远程过程调用,具体什么是RPC，看一个例子就会明白。比如客户端有一个RPC协议类Protocol。 123interfce Protocol&#123; int add(int a, int b);&#125; 但是客户端没有其实现的具体类，该类在服务端12345Class ProtocolImpl implenets Protocol&#123; int add(int a, int b)&#123; return a + b; &#125;&#125; 则客户端需要调用ProtocolImpl的add方法，需要将调用的方法及其参数等信息发送给服务端，服务端解析信息，调用ProtocolImpl的add方法，将结果在传输给客户端，而RPC的目的就是使客户端仿佛在调用自身的方法来得到该方法的结果。在这其中，Protocol就是一个RPC的协议，这个协议其实就是一个接口类，接口中的方法就是对外提供的远程调用方法。 RPC由四个模块组成：1、通信模块。两个相互协作的通信模块实现请求-应答协议,它们在客户和服务器之间传递请求和应答消息,一般不会对数据包进行任何处理。请求–应答协议的实现方式有同步方式和异步方式两种。同步模式下客户端程序一直阻塞到服务器端发送的应答请求到达本地; 而异步模式不同,客户端将请求发送到服务器端后,不必等待应答返回,可以做其他事情,待服务器端处理完请求后,主动通知客户端。在高并发应用场景中,一般采用异步模式以降低访问延迟和提高带宽利用率。2、Stub 程序（代理程序）。客户端和服务器端均包含Stub程序,可将之看做代理程序。它使得远程函数调用表现得跟本地调用一样,对用户程序完全透明。在客户端,它表现得就像一个本地程序,但不直接执行本地调用,而是将请求信息通过网络模块发送给服务器端。此外,当服务器发送应答后,它会解码对应结果。在服务器端,Stub程序依次进行解码请求消息中的参数、调用相应的服务过程和编码应答结果的返回值等处理。3、调度程序。调度程序接收来自通信模块的请求消息,并根据其中的标识选择一个Stub程序进行处理。通常客户端并发请求量比较大时,会采用线程池提高处理效率。4、客户程序/服务过程。请求的发出者和请求的处理者。 Hadoop RPCHadoop RPC主要分为四个部分,分别是序列化层、函数调用层、网络传输层和服务器端处理框架,具体实现机制如下: 序列化层。序列化主要作用是将结构化对象转为字节流以便于通过网络进行传输或写入持久存储,在RPC框架中,它主要用于将用户请求中的参数或者应答转化成字节流以便跨机器传输。Hadoop2.0之后，主要用Protocol Buffers和Apache Avro，Hadoop本身也提供了一套序列化框架，一个类只要实现Writable接口即可支持对象序列化与反序列化。 函数调用层。函数调用层主要功能是定位要调用的函数并执行该函数，Hadoop RPC采用了Java反射机制（服务器端）与动态代理（客户端）实现了函数调用。 网络传输层。网络传输层描述了Client与Server之间消息传输的方式，Hadoop RPC采用了基于TCP/IP的Socket机制。 服务器端处理框架。服务器端处理框架可被抽象为网络I/O模型，它描述了客户端与服务器端间信息交互方式,它的设计直接决定着服务器端的并发处理能力,常见的网络 I/O 模型有阻塞式 I/O、非阻塞式 I/O、事件驱动 I/O 等,而Hadoop RPC采用了基于Reactor设计模式的事件驱动 I/O 模型（NIO）。 Hadoop RPC的简单使用首先需要定义一个PRC协议，该接口必须继承VersionedProtocol接口1234public interface IProxyProtocol extends VersionedProtocol&#123; long versionID = 1234L; int add(int a, int b);&#125; 接着需要一个类实现PRC的接口用于服务端的调用123456789101112131415161718public class MyProxyProtocol implements IProxyProtocol &#123; @Override public int add(int a, int b) &#123; System.out.println("I am adding"); return a+b; &#125; @Override public long getProtocolVersion(String s, long l) throws IOException &#123; System.out.println("MyProxy.ProtocolVersion = " + IProxyProtocol.versionID ); return IProxyProtocol.versionID ; &#125; @Override public ProtocolSignature getProtocolSignature(String s, long l, int i) throws IOException &#123; return new ProtocolSignature(IProxyProtocol.versionID , null); &#125;&#125; 最后是实现客户端和服务端1234567891011121314public class MyRPCClient &#123; public final static int PORT = 8888; public final static String ADDRESS = "localhost"; public static void main(String[] args) throws Exception&#123; Configuration conf = new Configuration(); IProxyProtocol proxy; proxy = RPC.getProxy(IProxyProtocol.class, 111 , new InetSocketAddress(ADDRESS, PORT), conf); int result = proxy.add(2, 3); System.out.println(result); RPC.stopProxy(proxy); &#125;&#125; 1234567891011121314public class MyRPCServer &#123; public final static int PORT = 8888; public final static String ADDRESS = "localhost"; public static void main(String[] args) throws IOException&#123; RPC.Server server = new RPC.Builder(new Configuration()) .setProtocol(IProxyProtocol.class) .setInstance(new MyProxyProtocol()) .setBindAddress(ADDRESS) .setPort(PORT) .setNumHandlers(10) .build(); server.start(); &#125;&#125; 上述的Hadoop RPC的实现，客户端是调用了 RPC.getProxy方法，生成了IProxyProtocol的动态代理，在调用协议的方法时，代理类会将方法和参数出给服务端，服务端使用具体的实现类来执行方法并返回结果给客户端。需要注意的是RPC协议必须声明versionID这个变量或者定义ProtocolInfo注解（包含看协议的名字和versionID） 客户端的实现首先我们来看Hadoop RPC的客户端代码，调用RPC.getProxy方法，追踪这个方法，可以看到其内部实现1234public static &lt;T&gt; T getProxy(Class&lt;T&gt; protocol,long clientVersion,InetSocketAddress addr, Configuration conf) throws IOException &#123; return getProtocolProxy(protocol, clientVersion, addr, conf).getProxy();&#125; 内部调用了getProtocolProxy，而getProtocolProxy又经过几次重载函数的调用，最后的实现是123456789101112131415161718192021222324252627282930313233/** * Get a protocol proxy that contains a proxy connection to a remote server * and a set of methods that are supported by the server * @param protocol protocol RPC协议 * @param clientVersion client's version * @param addr server address 服务端的地址 ip:port * @param ticket security ticket * @param conf configuration * @param factory socket factory * @param rpcTimeout max time for each rpc; 0 means no timeout * @param connectionRetryPolicy retry policy * @param fallbackToSimpleAuth set to true or false during calls to indicate if * a secure client falls back to simple auth * @return the proxy * @throws IOException if any error occurs */ public static &lt;T&gt; ProtocolProxy&lt;T&gt; getProtocolProxy(Class&lt;T&gt; protocol, long clientVersion, InetSocketAddress addr, UserGroupInformation ticket, Configuration conf, SocketFactory factory, int rpcTimeout, RetryPolicy connectionRetryPolicy, AtomicBoolean fallbackToSimpleAuth) throws IOException &#123; if (UserGroupInformation.isSecurityEnabled()) &#123; SaslRpcServer.init(conf); &#125; return getProtocolEngine(protocol, conf).getProxy(protocol, clientVersion, addr, ticket, conf, factory, rpcTimeout, connectionRetryPolicy, fallbackToSimpleAuth);&#125; 其中ProtocolProxy封装了动态代理类和PRC协议，ProtocolProxy.getProxy会返回生成的动态代理类。而ProtocolProxy类是getProtocolEngine返回的。12345678910111213141516/** * 如果缓存中存在该协议的RpcEngine，则直接调用 * 否则就从Configuration中取出rpc.engine.protocol.getName()的RpeEngine类 * 默认为WritableRpcEngine类 */static synchronized RpcEngine getProtocolEngine(Class&lt;?&gt; protocol, Configuration conf) &#123; RpcEngine engine = PROTOCOL_ENGINES.get(protocol); if (engine == null) &#123; Class&lt;?&gt; impl = conf.getClass(ENGINE_PROP+"."+protocol.getName(), WritableRpcEngine.class); engine = (RpcEngine)ReflectionUtils.newInstance(impl, conf); PROTOCOL_ENGINES.put(protocol, engine); &#125; return engine;&#125; 可以看到RpcEngine从Configuration读取，如果没有，默认设置是WritableRpcEngine。这是Hadoop RPC对序列化方式多样性的支持，目前提供了Writable(WritableRpcEngine)和Protocol Buffer(ProtocolRpcEngine)两种，用户也可以通过RPC.setProtocolEngine()设置。这里我们只分析WritableRpcEngine，跳转到WritableRpcEngine.getProxy方法123456789101112131415public &lt;T&gt; ProtocolProxy&lt;T&gt; getProxy(Class&lt;T&gt; protocol, long clientVersion, InetSocketAddress addr, UserGroupInformation ticket, Configuration conf, SocketFactory factory, int rpcTimeout, RetryPolicy connectionRetryPolicy, AtomicBoolean fallbackToSimpleAuth) throws IOException &#123; //默认为null if (connectionRetryPolicy != null) &#123; throw new UnsupportedOperationException( "Not supported: connectionRetryPolicy=" + connectionRetryPolicy); &#125; T proxy = (T) Proxy.newProxyInstance(protocol.getClassLoader(), new Class[] &#123; protocol &#125;, new Invoker(protocol, addr, ticket, conf, factory, rpcTimeout, fallbackToSimpleAuth)); return new ProtocolProxy&lt;T&gt;(protocol, proxy, true);&#125; 可以看到这里使用了动态代理生成的了代理类，封装进了ProtocolProxy类中，而RPC.getProxy中是返回了ProtocolProxy.getProxy的结果。则调用PRC协议的方法会触发代理类的invoke方法，客户端就是在invoke方法中实现了方法名和参数的传递和结果的接受。因此我们继续看Invoker类，这是WritableRpcEngine的内部类123456789101112131415161718192021222324252627282930313233343536373839404142434445private static class Invoker implements RpcInvocationHandler &#123; //ConnectionId中包括了服务端的地址，协议类，安全令牌等，用来唯一标识Client.Connection类 private Client.ConnectionId remoteId; private Client client; private boolean isClosed = false; private final AtomicBoolean fallbackToSimpleAuth; public Invoker(Class&lt;?&gt; protocol, InetSocketAddress address, UserGroupInformation ticket, Configuration conf, SocketFactory factory, int rpcTimeout, AtomicBoolean fallbackToSimpleAuth) throws IOException &#123; this.remoteId = Client.ConnectionId.getConnectionId(address, protocol, ticket, rpcTimeout, conf); this.client = CLIENTS.getClient(conf, factory); this.fallbackToSimpleAuth = fallbackToSimpleAuth; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; long startTime = 0; if (LOG.isDebugEnabled()) &#123; startTime = Time.now(); &#125; TraceScope traceScope = null; if (Trace.isTracing()) &#123; traceScope = Trace.startSpan(RpcClientUtil.methodToTraceString(method)); &#125; ObjectWritable value; try &#123; value = (ObjectWritable) client.call(RPC.RpcKind.RPC_WRITABLE, new Invocation(method, args), remoteId, fallbackToSimpleAuth); &#125; finally &#123; if (traceScope != null) traceScope.close(); &#125; if (LOG.isDebugEnabled()) &#123; long callTime = Time.now() - startTime; LOG.debug("Call: " + method.getName() + " " + callTime); &#125; return value.get(); &#125; ...&#125; 可以看到invoke中是调用了Client.call方法来进行远程函数调用，Client的获得是先从CLIENTS中的缓存（其实就是内部维护了一个HashMap&lt;SocketFactory, Client&gt;）,如果没有就根据SocketFactory和序列化类型实例化一个并放入其中。call方法的一个参数new Invocation(method, args),其实是用来序列化方法类及其传递的参数的。Invocation类实现了Writable接口，Writable是hadoop用来序列化的接口。12345678910111213141516171819202122232425262728293031323334353637383940private static class Invocation implements Writable, Configurable &#123; private String methodName; //方法名 private Class&lt;?&gt;[] parameterClasses; //参数类型 private Object[] parameters; //参数实例对象 private Configuration conf; private long clientVersion; //客户端version,主要从方法所在类的ProtocolInfo注解中的version或者versionID中获得 private int clientMethodsHash; //方法所在类所有方法的形成的hash private String declaringClassProtocolName; //要从方法所在类的ProtocolInfo注解中的name ... public void readFields(DataInput in) throws IOException &#123; rpcVersion = in.readLong(); declaringClassProtocolName = UTF8.readString(in); methodName = UTF8.readString(in); clientVersion = in.readLong(); clientMethodsHash = in.readInt(); parameters = new Object[in.readInt()]; parameterClasses = new Class[parameters.length]; ObjectWritable objectWritable = new ObjectWritable(); for (int i = 0; i &lt; parameters.length; i++) &#123; parameters[i] = ObjectWritable.readObject(in, objectWritable, this.conf); parameterClasses[i] = objectWritable.getDeclaredClass(); &#125; &#125; @Override @SuppressWarnings("deprecation") public void write(DataOutput out) throws IOException &#123; out.writeLong(rpcVersion); UTF8.writeString(out, declaringClassProtocolName); UTF8.writeString(out, methodName); out.writeLong(clientVersion); out.writeInt(clientMethodsHash); out.writeInt(parameterClasses.length); for (int i = 0; i &lt; parameterClasses.length; i++) &#123; ObjectWritable.writeObject(out, parameters[i], parameterClasses[i], conf, true); &#125; &#125; ...&#125; 继续我们追踪Client.call，来了的Client类中（客户端核心的类），通过重载函数的调用，最后定位到了1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * Make a call, passing &lt;code&gt;rpcRequest&lt;/code&gt;, to the IPC server defined by * &lt;code&gt;remoteId&lt;/code&gt;, returning the rpc response. * @param rpcKind * @param rpcRequest - contains serialized method and method parameters 包含序列化的方法和方法参数 * @param remoteId - the target rpc server * @param serviceClass - service class for RPC * @param fallbackToSimpleAuth - set to true or false during this method to * indicate if a secure client falls back to simple auth * @returns the rpc response */ public Writable call(RPC.RpcKind rpcKind, Writable rpcRequest, ConnectionId remoteId, int serviceClass, AtomicBoolean fallbackToSimpleAuth) throws IOException &#123; final Call call = createCall(rpcKind, rpcRequest); //将序列化的信息封装进Call中 Connection connection = getConnection(remoteId, call, serviceClass, fallbackToSimpleAuth); //获得Connection对象，其中封装了socket，连接到服务端 try &#123; connection.sendRpcRequest(call); // send the rpc &#125; catch (RejectedExecutionException e) &#123; throw new IOException("connection has been closed", e); &#125; catch (InterruptedException e) &#123; Thread.currentThread().interrupt(); LOG.warn("interrupted waiting to send rpc request to server", e); throw new IOException(e); &#125; synchronized (call) &#123; while (!call.done) &#123; try &#123; call.wait(); // wait for the result &#125; catch (InterruptedException ie) &#123; Thread.currentThread().interrupt(); throw new InterruptedIOException("Call interrupted"); &#125; &#125; if (call.error != null) &#123; if (call.error instanceof RemoteException) &#123; call.error.fillInStackTrace(); throw call.error; &#125; else &#123; // local exception InetSocketAddress address = connection.getRemoteAddress(); throw NetUtils.wrapException(address.getHostName(), address.getPort(), NetUtils.getHostname(), 0, call.error); &#125; &#125; else &#123; return call.getRpcResponse(); &#125; &#125; &#125; 从中可以看出首先是实例化一个Call对象，封装了输送的内容,Connection负责连接服务端，接受返回信息，放入对应的Call中，并唤醒Call,读出返回数据。其中一个Connection负责同个服务端地址，同个RPC协议，同个安全令牌的连接下的所有Call中内容的发送和接受，connection维护了Call的集合，通过callid知道对应返回的数据和发送的数据属于哪个Call对象，从后文可以看出。这里主要调用了createCall创造了Call对象，getConnection连接服务端，connection.sendRpcRequest发送请求并接受返回。接下来就深入这三个函数。1234567891011121314151617181920212223242526272829303132333435 Call createCall(RPC.RpcKind rpcKind, Writable rpcRequest) &#123; return new Call(rpcKind, rpcRequest); &#125; static class Call &#123; final int id; // call id final int retry; // retry count final Writable rpcRequest; // the serialized rpc request Writable rpcResponse; // null if rpc has error IOException error; // exception, null if success final RPC.RpcKind rpcKind; // Rpc EngineKind boolean done; // true when call is done private Call(RPC.RpcKind rpcKind, Writable param) &#123; this.rpcKind = rpcKind; this.rpcRequest = param; //生成callId,每一个Call实例对象都有唯一的id,为了connection接受消息后放入对应id的Call中 final Integer id = callId.get(); if (id == null) &#123; this.id = nextCallId(); &#125; else &#123; callId.set(null); this.id = id; &#125; final Integer rc = retryCount.get(); if (rc == null) &#123; this.retry = 0; &#125; else &#123; this.retry = rc; &#125; &#125; ...&#125; 12345678910111213141516171819202122232425262728293031/** Get a connection from the pool, or create a new one and add it to the * pool. Connections to a given ConnectionId are reused. */private Connection getConnection(ConnectionId remoteId, Call call, int serviceClass, AtomicBoolean fallbackToSimpleAuth) throws IOException &#123; if (!running.get()) &#123; // the client is stopped throw new IOException("The client is stopped"); &#125; Connection connection; /* we could avoid this allocation for each RPC by having a * connectionsId object and with set() method. We need to manage the * refs for keys in HashMap properly. For now its ok. */ do &#123; synchronized (connections) &#123; connection = connections.get(remoteId); if (connection == null) &#123; connection = new Connection(remoteId, serviceClass); connections.put(remoteId, connection); &#125; &#125; &#125; while (!connection.addCall(call)); //we don't invoke the method below inside "synchronized (connections)" //block above. The reason for that is if the server happens to be slow, //it will take longer to establish a connection and that will slow the //entire system down. connection.setupIOstreams(fallbackToSimpleAuth); return connection;&#125; 其中维护了一个连接池（其实就是一个HashTable，保证线程安全），remoteId作为其key，当连接池没有连接则会新建一个Connection并将其添加到连接池中，初始化Connection就是一些赋值，可以在Connection中看到Socket，实际上是调用了Socket建立了TCP连接，并且Connection继承了Thread，在建立连接后会启动线程，不断等待结果的相应，在下文中可以看到。在”synchronized (connections)”代码块中是不会开始建立连接的，因为如果在同步代码块中连接会造成阻塞，降低整个系统的效率。真正的建立连接是connection.setupIOstreams中会调用的123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384/** Connect to the server and set up the I/O streams. It then sends * a header to the server and starts * the connection thread that waits for responses. * 建立channle的in和outStream,启动connection的线程接受返回消息 */private synchronized void setupIOstreams( AtomicBoolean fallbackToSimpleAuth) &#123; if (socket != null || shouldCloseConnection.get()) &#123; return; &#125; try &#123; if (LOG.isDebugEnabled()) &#123; LOG.debug("Connecting to "+server); &#125; if (Trace.isTracing()) &#123; Trace.addTimelineAnnotation("IPC client connecting to " + server); &#125; short numRetries = 0; Random rand = null; while (true) &#123; setupConnection(); //建立socket连接 InputStream inStream = NetUtils.getInputStream(socket); //获得输入流 OutputStream outStream = NetUtils.getOutputStream(socket); //获得输出流 writeConnectionHeader(outStream); //传输连接头 ... if (doPing) &#123; inStream = new PingInputStream(inStream); &#125; this.in = new DataInputStream(new BufferedInputStream(inStream)); // SASL may have already buffered the stream if (!(outStream instanceof BufferedOutputStream)) &#123; outStream = new BufferedOutputStream(outStream); &#125; this.out = new DataOutputStream(outStream); writeConnectionContext(remoteId, authMethod); //传输上下文 // update last activity time touch(); if (Trace.isTracing()) &#123; Trace.addTimelineAnnotation("IPC client connected to " + server); &#125; // start the receiver thread after the socket connection has been set // up start(); return; &#125; &#125; catch (Throwable t) &#123; if (t instanceof IOException) &#123; markClosed((IOException)t); &#125; else &#123; markClosed(new IOException("Couldn't set up IO streams", t)); &#125; close(); &#125;&#125;/** * Write the connection header - this is sent when connection is established * +----------------------------------+ * | "hrpc" 4 bytes | * +----------------------------------+ * | Version (1 byte) | * +----------------------------------+ * | Service Class (1 byte) | * +----------------------------------+ * | AuthProtocol (1 byte) | * +----------------------------------+ */private void writeConnectionHeader(OutputStream outStream) throws IOException &#123; DataOutputStream out = new DataOutputStream(new BufferedOutputStream(outStream)); // Write out the header, version and authentication method out.write(RpcConstants.HEADER.array()); out.write(RpcConstants.CURRENT_VERSION); out.write(serviceClass); out.write(authProtocol.callId); out.flush();&#125; 这里的整个过程就是setupConnection方法建立连接，得到输入输出流，再传输Hadoop PRC的连接头和上下文（Configuration中设置的一些RPC的参数）。连接头从注释中可以看到，下文可以看到server端接受解析连接头。最后启动线程，不断等待接收相应结果。主要连接方法是setupConnection方法。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253private synchronized void setupConnection() throws IOException &#123; short ioFailures = 0; short timeoutFailures = 0; while (true) &#123; try &#123; this.socket = socketFactory.createSocket(); this.socket.setTcpNoDelay(tcpNoDelay); this.socket.setKeepAlive(true); /* * Bind the socket to the host specified in the principal name of the * client, to ensure Server matching address of the client connection * to host name in principal passed. */ UserGroupInformation ticket = remoteId.getTicket(); if (ticket != null &amp;&amp; ticket.hasKerberosCredentials()) &#123; KerberosInfo krbInfo = remoteId.getProtocol().getAnnotation(KerberosInfo.class); if (krbInfo != null &amp;&amp; krbInfo.clientPrincipal() != null) &#123; String host = SecurityUtil.getHostFromPrincipal(remoteId.getTicket().getUserName()); // If host name is a valid local address then bind socket to it InetAddress localAddr = NetUtils.getLocalInetAddress(host); if (localAddr != null) &#123; this.socket.bind(new InetSocketAddress(localAddr, 0)); &#125; &#125; &#125; NetUtils.connect(this.socket, server, connectionTimeout); if (rpcTimeout &gt; 0) &#123; pingInterval = rpcTimeout; // rpcTimeout overwrites pingInterval &#125; this.socket.setSoTimeout(pingInterval); return; &#125; catch (ConnectTimeoutException toe) &#123; /* Check for an address change and update the local reference. * Reset the failure counter if the address was changed */ if (updateAddress()) &#123; timeoutFailures = ioFailures = 0; &#125; handleConnectionTimeout(timeoutFailures++, maxRetriesOnSocketTimeouts, toe); &#125; catch (IOException ie) &#123; if (updateAddress()) &#123; timeoutFailures = ioFailures = 0; &#125; handleConnectionFailure(ioFailures++, ie); &#125; &#125;&#125; 12345public class StandardSocketFactory extends SocketFactory &#123; public Socket createSocket() throws IOException &#123; return SocketChannel.open().socket(); &#125;&#125; setupConnection中调用了socketFactory.createSocket()根据具体不同实现大SocketFactory来创建Socket，默认是StandardSocketFactory实现，这里通过SocketChannel来得到socket,socket在setupConnection中设置，建立长连接和超时时间（默认为一分钟，socket.setSoTimeout设置）。最后通过NetUtils.connect建立连接。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103public static void connect(Socket socket, SocketAddress address, int timeout) throws IOException &#123; connect(socket, address, null, timeout); &#125; public static void connect(Socket socket, SocketAddress endpoint, SocketAddress localAddr, int timeout) throws IOException &#123; if (socket == null || endpoint == null || timeout &lt; 0) &#123; throw new IllegalArgumentException("Illegal argument for connect()"); &#125; SocketChannel ch = socket.getChannel(); if (localAddr != null) &#123; Class localClass = localAddr.getClass(); Class remoteClass = endpoint.getClass(); Preconditions.checkArgument(localClass.equals(remoteClass), "Local address %s must be of same family as remote address %s.", localAddr, endpoint); socket.bind(localAddr); &#125; try &#123; if (ch == null) &#123; // let the default implementation handle it. socket.connect(endpoint, timeout); &#125; else &#123; SocketIOWithTimeout.connect(ch, endpoint, timeout); &#125; &#125; catch (SocketTimeoutException ste) &#123; throw new ConnectTimeoutException(ste.getMessage()); &#125; // There is a very rare case allowed by the TCP specification, such that // if we are trying to connect to an endpoint on the local machine, // and we end up choosing an ephemeral port equal to the destination port, // we will actually end up getting connected to ourself (ie any data we // send just comes right back). This is only possible if the target // daemon is down, so we'll treat it like connection refused. if (socket.getLocalPort() == socket.getPort() &amp;&amp; socket.getLocalAddress().equals(socket.getInetAddress())) &#123; LOG.info("Detected a loopback TCP socket, disconnecting it"); socket.close(); throw new ConnectException( "Localhost targeted connection resulted in a loopback. " + "No daemon is listening on the target port."); &#125; &#125; /** * SocketIOWithTimeout.connect方法 */ static void connect(SocketChannel channel, SocketAddress endpoint, int timeout) throws IOException &#123; boolean blockingOn = channel.isBlocking(); if (blockingOn) &#123; channel.configureBlocking(false); &#125; try &#123; if (channel.connect(endpoint)) &#123; return; &#125; long timeoutLeft = timeout; long endTime = (timeout &gt; 0) ? (Time.now() + timeout): 0; while (true) &#123; // we might have to call finishConnect() more than once // for some channels (with user level protocols) int ret = selector.select((SelectableChannel)channel, SelectionKey.OP_CONNECT, timeoutLeft); if (ret &gt; 0 &amp;&amp; channel.finishConnect()) &#123; return; &#125; if (ret == 0 || (timeout &gt; 0 &amp;&amp; (timeoutLeft = (endTime - Time.now())) &lt;= 0)) &#123; throw new SocketTimeoutException( timeoutExceptionString(channel, timeout, SelectionKey.OP_CONNECT)); &#125; &#125; &#125; catch (IOException e) &#123; // javadoc for SocketChannel.connect() says channel should be closed. try &#123; channel.close(); &#125; catch (IOException ignored) &#123;&#125; throw e; &#125; finally &#123; if (blockingOn &amp;&amp; channel.isOpen()) &#123; channel.configureBlocking(true); &#125; &#125; &#125; 可以看到实际上就是socket或socketChannel（设置为不阻塞）的连接。和服务端的连接建立连接之后就是发送Call中的内容到服务端，并接收其相应结果，返回到了Client中的call方法，通过Connection.sendRpcRequest来发送方法信息和实际参数，并在其中启动Connection对象的线程，等待接收服务端响应消息。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public void sendRpcRequest(final Call call) throws InterruptedException, IOException &#123; if (shouldCloseConnection.get()) &#123; return; &#125; // Serialize the call to be sent. This is done from the actual // caller thread, rather than the sendParamsExecutor thread, // so that if the serialization throws an error, it is reported // properly. This also parallelizes the serialization. // // Format of a call on the wire: // 0) Length of rest below (1 + 2) // 1) RpcRequestHeader - is serialized Delimited hence contains length // 2) RpcRequest // // Items '1' and '2' are prepared here. final DataOutputBuffer d = new DataOutputBuffer(); RpcRequestHeaderProto header = ProtoUtil.makeRpcRequestHeader( call.rpcKind, OperationProto.RPC_FINAL_PACKET, call.id, call.retry, clientId); header.writeDelimitedTo(d); call.rpcRequest.write(d); synchronized (sendRpcRequestLock) &#123; Future&lt;?&gt; senderFuture = sendParamsExecutor.submit(new Runnable() &#123; @Override public void run() &#123; try &#123; synchronized (Connection.this.out) &#123; if (shouldCloseConnection.get()) &#123; return; &#125; if (LOG.isDebugEnabled()) LOG.debug(getName() + " sending #" + call.id); byte[] data = d.getData(); int totalLength = d.getLength(); out.writeInt(totalLength); // Total Length out.write(data, 0, totalLength);// RpcRequestHeader + RpcRequest out.flush(); &#125; &#125; catch (IOException e) &#123; // exception at this point would leave the connection in an // unrecoverable state (eg half a call left on the wire). // So, close the connection, killing any outstanding calls markClosed(e); &#125; finally &#123; //the buffer is just an in-memory buffer, but it is still polite to // close early IOUtils.closeStream(d); &#125; &#125; &#125;); try &#123; senderFuture.get(); &#125; catch (ExecutionException e) &#123; Throwable cause = e.getCause(); // cause should only be a RuntimeException as the Runnable above // catches IOException if (cause instanceof RuntimeException) &#123; throw (RuntimeException) cause; &#125; else &#123; throw new RuntimeException("unexpected checked exception", cause); &#125; &#125; &#125;&#125; 将call中的消息写入到输出流中，写入的格式可以从注释中看到，首先是报文的长度，接着是报文头，最后是发送的请求内容。其中先将消息写入到临时的DataOutputBuffer，最后将其放入线程池中发送，避免了阻塞。前文讲到我们在建立连接之后启动了Connection的线程，不断从服务端接受响应消息。接下来我们看如何接受服务端返回的函数结果，即Connection的run方法。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485public void run() &#123; if (LOG.isDebugEnabled()) LOG.debug(getName() + ": starting, having connections " + connections.size()); try &#123; while (waitForWork()) &#123;//wait here for work - read or close connection receiveRpcResponse(); &#125; &#125; catch (Throwable t) &#123; ...&#125;/* Receive a response. * Because only one receiver, so no synchronization on in. */private void receiveRpcResponse() &#123; if (shouldCloseConnection.get()) &#123; return; &#125; touch(); try &#123; int totalLen = in.readInt(); RpcResponseHeaderProto header = RpcResponseHeaderProto.parseDelimitedFrom(in); checkResponse(header); int headerLen = header.getSerializedSize(); headerLen += CodedOutputStream.computeRawVarint32Size(headerLen); int callId = header.getCallId(); if (LOG.isDebugEnabled()) LOG.debug(getName() + " got value #" + callId); Call call = calls.get(callId); RpcStatusProto status = header.getStatus(); if (status == RpcStatusProto.SUCCESS) &#123; Writable value = ReflectionUtils.newInstance(valueClass, conf); value.readFields(in); // read value calls.remove(callId); call.setRpcResponse(value); // verify that length was correct // only for ProtobufEngine where len can be verified easily if (call.getRpcResponse() instanceof ProtobufRpcEngine.RpcWrapper) &#123; ProtobufRpcEngine.RpcWrapper resWrapper = (ProtobufRpcEngine.RpcWrapper) call.getRpcResponse(); if (totalLen != headerLen + resWrapper.getLength()) &#123; throw new RpcClientException( "RPC response length mismatch on rpc success"); &#125; &#125; &#125; else &#123; // Rpc Request failed // Verify that length was correct if (totalLen != headerLen) &#123; throw new RpcClientException( "RPC response length mismatch on rpc error"); &#125; final String exceptionClassName = header.hasExceptionClassName() ? header.getExceptionClassName() : "ServerDidNotSetExceptionClassName"; final String errorMsg = header.hasErrorMsg() ? header.getErrorMsg() : "ServerDidNotSetErrorMsg" ; final RpcErrorCodeProto erCode = (header.hasErrorDetail() ? header.getErrorDetail() : null); if (erCode == null) &#123; LOG.warn("Detailed error code not set by server on rpc error"); &#125; RemoteException re = ( (erCode == null) ? new RemoteException(exceptionClassName, errorMsg) : new RemoteException(exceptionClassName, errorMsg, erCode)); if (status == RpcStatusProto.ERROR) &#123; calls.remove(callId); call.setException(re); &#125; else if (status == RpcStatusProto.FATAL) &#123; // Close the connection markClosed(re); &#125; &#125; &#125; catch (IOException e) &#123; markClosed(e); &#125;&#125; 可以看到首先是获得消息的长度，再是解析消息头，根据callId将发消息内容放入对应的Call中，将call.done赋值为true，并唤醒对应的Call。最后回到Client.call方法，返回call.getRpcResponse();到此hadoop 客户端的代码分析完毕。 服务端的实现服务端首先是使用build模式创建一个RPC.Server对象 12345678910111213141516public Server build() throws IOException, HadoopIllegalArgumentException &#123; if (this.conf == null) &#123; throw new HadoopIllegalArgumentException("conf is not set"); &#125; if (this.protocol == null) &#123; throw new HadoopIllegalArgumentException("protocol is not set"); &#125; if (this.instance == null) &#123; throw new HadoopIllegalArgumentException("instance is not set"); &#125; return getProtocolEngine(this.protocol, this.conf).getServer( this.protocol, this.instance, this.bindAddress, this.port, this.numHandlers, this.numReaders, this.queueSizePerHandler, this.verbose, this.conf, this.secretManager, this.portRangeConfig);&#125; 可以看到和客户端一样是通过getProtocolEngine得到不同的ProtocolEngine类来生成不同的Server对象，同样我们来看默认的ProtocolEngine类WritableRpcEngine。调用了WritableRpcEngine的getServer的方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103public RPC.Server getServer(Class&lt;?&gt; protocolClass, Object protocolImpl, String bindAddress, int port, int numHandlers, int numReaders, int queueSizePerHandler, boolean verbose, Configuration conf, SecretManager&lt;? extends TokenIdentifier&gt; secretManager, String portRangeConfig) throws IOException &#123;return new Server(protocolClass, protocolImpl, conf, bindAddress, port, numHandlers, numReaders, queueSizePerHandler, verbose, secretManager, portRangeConfig);&#125;public static class Server extends RPC.Server &#123; ... /** * Construct an RPC server. * @param protocolClass - the protocol being registered * can be null for compatibility with old usage (see below for details) * @param protocolImpl the protocol impl that will be called * @param conf the configuration to use * @param bindAddress the address to bind on to listen for connection * @param port the port to listen for connections on * @param numHandlers the number of method handler threads to run * @param verbose whether each call should be logged */ public Server(Class&lt;?&gt; protocolClass, Object protocolImpl, Configuration conf, String bindAddress, int port, int numHandlers, int numReaders, int queueSizePerHandler, boolean verbose, SecretManager&lt;? extends TokenIdentifier&gt; secretManager, String portRangeConfig) throws IOException &#123; super(bindAddress, port, null, numHandlers, numReaders, queueSizePerHandler, conf, classNameBase(protocolImpl.getClass().getName()), secretManager, portRangeConfig); this.verbose = verbose; Class&lt;?&gt;[] protocols; if (protocolClass == null) &#123; // derive protocol from impl /* * In order to remain compatible with the old usage where a single * target protocolImpl is suppled for all protocol interfaces, and * the protocolImpl is derived from the protocolClass(es) * we register all interfaces extended by the protocolImpl */ protocols = RPC.getProtocolInterfaces(protocolImpl.getClass()); &#125; else &#123; if (!protocolClass.isAssignableFrom(protocolImpl.getClass())) &#123; throw new IOException("protocolClass "+ protocolClass + " is not implemented by protocolImpl which is of class " + protocolImpl.getClass()); &#125; // register protocol class and its super interfaces registerProtocolAndImpl(RPC.RpcKind.RPC_WRITABLE, protocolClass, protocolImpl); protocols = RPC.getProtocolInterfaces(protocolClass); &#125; for (Class&lt;?&gt; p : protocols) &#123; if (!p.equals(VersionedProtocol.class)) &#123; registerProtocolAndImpl(RPC.RpcKind.RPC_WRITABLE, p, protocolImpl); &#125; &#125; &#125;&#125; // Register protocol and its impl for rpc calls void registerProtocolAndImpl(RpcKind rpcKind, Class&lt;?&gt; protocolClass, Object protocolImpl) &#123; String protocolName = RPC.getProtocolName(protocolClass); long version; try &#123; version = RPC.getProtocolVersion(protocolClass); &#125; catch (Exception ex) &#123; LOG.warn("Protocol " + protocolClass + " NOT registered as cannot get protocol version "); return; &#125; getProtocolImplMap(rpcKind).put(new ProtoNameVer(protocolName, version), new ProtoClassProtoImpl(protocolClass, protocolImpl)); LOG.debug("RpcKind = " + rpcKind + " Protocol Name = " + protocolName + " version=" + version + " ProtocolImpl=" + protocolImpl.getClass().getName() + " protocolClass=" + protocolClass.getName()); &#125; Map&lt;ProtoNameVer, ProtoClassProtoImpl&gt; getProtocolImplMap(RPC.RpcKind rpcKind) &#123; if (protocolImplMapArray.size() == 0) &#123;// initialize for all rpc kinds for (int i=0; i &lt;= RpcKind.MAX_INDEX; ++i) &#123; protocolImplMapArray.add( new HashMap&lt;ProtoNameVer, ProtoClassProtoImpl&gt;(10)); &#125; &#125; return protocolImplMapArray.get(rpcKind.ordinal()); &#125; WritableRpcEngine是继承自RPC.Server，而RPC.Server是继承ipc的Server的，getServer直接初始化了WritableRpcEngine.Server对象，可以看到在初始化的过程中，首先是调用了父类的构造函数，接着将协议的具体实现类根据RPC_WRITABLE和协议接口名放入到缓存中。接着我们来看父类的构造函数。 12345678910111213141516171819202122232425public abstract static class Server extends org.apache.hadoop.ipc.Server &#123; ... protected Server(String bindAddress, int port, Class&lt;? extends Writable&gt; paramClass, int handlerCount, int numReaders, int queueSizePerHandler, Configuration conf, String serverName, SecretManager&lt;? extends TokenIdentifier&gt; secretManager, String portRangeConfig) throws IOException &#123; super(bindAddress, port, paramClass, handlerCount, numReaders, queueSizePerHandler, conf, serverName, secretManager, portRangeConfig); initProtocolMetaInfo(conf); &#125; private void initProtocolMetaInfo(Configuration conf) &#123; RPC.setProtocolEngine(conf, ProtocolMetaInfoPB.class, ProtobufRpcEngine.class); ProtocolMetaInfoServerSideTranslatorPB xlator = new ProtocolMetaInfoServerSideTranslatorPB(this); BlockingService protocolInfoBlockingService = ProtocolInfoService .newReflectiveBlockingService(xlator); addProtocol(RpcKind.RPC_PROTOCOL_BUFFER, ProtocolMetaInfoPB.class, protocolInfoBlockingService); &#125; ...&#125; 123456789101112131415161718192021222324252627282930313233public abstract class Server &#123; protected Server(String bindAddress, int port, Class&lt;? extends Writable&gt; rpcRequestClass, int handlerCount, int numReaders, int queueSizePerHandler, Configuration conf, String serverName, SecretManager&lt;? extends TokenIdentifier&gt; secretManager, String portRangeConfig) throws IOException &#123; this.bindAddress = bindAddress; this.conf = conf; this.portRangeConfig = portRangeConfig; this.port = port; this.rpcRequestClass = rpcRequestClass; this.handlerCount = handlerCount; this.socketSendBufferSize = 0; ... listener = new Listener(); this.port = listener.getAddress().getPort(); connectionManager = new ConnectionManager(); this.rpcMetrics = RpcMetrics.create(this, conf); this.rpcDetailedMetrics = RpcDetailedMetrics.create(this.port); this.tcpNoDelay = conf.getBoolean( CommonConfigurationKeysPublic.IPC_SERVER_TCPNODELAY_KEY, CommonConfigurationKeysPublic.IPC_SERVER_TCPNODELAY_DEFAULT); this.setLogSlowRPC(conf.getBoolean( CommonConfigurationKeysPublic.IPC_SERVER_LOG_SLOW_RPC, CommonConfigurationKeysPublic.IPC_SERVER_LOG_SLOW_RPC_DEFAULT)); // Create the responder here responder = new Responder(); ... &#125;&#125; 可以看到父类的初始化主要是对一些变量的赋值，最主要的是初始化了listener和responder对象。 123456789101112131415161718192021222324252627282930313233343536373839/** Listens on the socket. Creates jobs for the handler threads*/ private class Listener extends Thread &#123; private ServerSocketChannel acceptChannel = null; //the accept channel private Selector selector = null; //the selector that we use for the server private Reader[] readers = null; private int currentReader = 0; private InetSocketAddress address; //the address we bind at private int backlogLength = conf.getInt( CommonConfigurationKeysPublic.IPC_SERVER_LISTEN_QUEUE_SIZE_KEY, CommonConfigurationKeysPublic.IPC_SERVER_LISTEN_QUEUE_SIZE_DEFAULT); public Listener() throws IOException &#123; address = new InetSocketAddress(bindAddress, port); // Create a new server socket and set to non blocking mode acceptChannel = ServerSocketChannel.open(); acceptChannel.configureBlocking(false); // Bind the server socket to the local host and port bind(acceptChannel.socket(), address, backlogLength, conf, portRangeConfig); port = acceptChannel.socket().getLocalPort(); //Could be an ephemeral port // create a selector; selector= Selector.open(); //如果没有指定值，readThreads默认为1 readers = new Reader[readThreads]; for (int i = 0; i &lt; readThreads; i++) &#123; Reader reader = new Reader( "Socket Reader #" + (i + 1) + " for port " + port); readers[i] = reader; reader.start(); &#125; // Register accepts on the server socket with the selector. acceptChannel.register(selector, SelectionKey.OP_ACCEPT); this.setName("IPC Server listener on " + port); this.setDaemon(true); &#125; ... &#125; Listener初始化了ServerSocketChannel，绑定了指定的一个或者一串中的一个端口，初始化了Selector,向其中注册了”连接就绪“的事件。并定义启动了几个读线程（Reader类）。Reader类主要用于读取客户端发送的信息，范序列化，生成相应的Call对象。每个Reader类中都有一个Selector，用于监听“读就绪”事件。在Listener的选择器中收到连接就绪的事件就会socketChannel封装进Connection中，将读事件注册给Reader的选择器，有相应的reader来负责读取信息。（下文会详细看到）现在先大致看一下responder类。 12345678910111213141516171819202122232425262728293031 // Sends responses of RPC back to clients.private class Responder extends Thread &#123; private final Selector writeSelector; private int pending; // connections waiting to register final static int PURGE_INTERVAL = 900000; // 15mins Responder() throws IOException &#123; this.setName("IPC Server Responder"); this.setDaemon(true); writeSelector = Selector.open(); // create a selector pending = 0; &#125; @Override public void run() &#123; LOG.info(Thread.currentThread().getName() + ": starting"); SERVER.set(Server.this); try &#123; doRunLoop(); &#125; finally &#123; LOG.info("Stopping " + Thread.currentThread().getName()); try &#123; writeSelector.close(); &#125; catch (IOException ioe) &#123; LOG.error("Couldn't close write selector in " + Thread.currentThread().getName(), ioe); &#125; &#125; &#125; ... &#125; 可以看到responder也是一个线程类，这个线程类主要是将RPC的相应信息传给客户端，可以看到其内部也有一个selector对象，主要是一些写事件会注册在其中。在初始化Listener和Responder对象，生成Server实例之后，就需要调用Server.start()来启动服务端。 12345678910public synchronized void start() &#123; responder.start(); listener.start(); handlers = new Handler[handlerCount]; for (int i = 0; i &lt; handlerCount; i++) &#123; handlers[i] = new Handler(i); handlers[i].start(); &#125;&#125; 分别启动了listener、responder和handlers的线程。接下来看listener的run方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public void run() &#123; LOG.info(Thread.currentThread().getName() + ": starting"); SERVER.set(Server.this); connectionManager.startIdleScan(); while (running) &#123; SelectionKey key = null; try &#123; getSelector().select(); //阻塞直到注册的socket管道有事件触发为止 Iterator&lt;SelectionKey&gt; iter = getSelector().selectedKeys().iterator(); while (iter.hasNext()) &#123; key = iter.next(); iter.remove(); try &#123; if (key.isValid()) &#123; if (key.isAcceptable()) doAccept(key); &#125; &#125; catch (IOException e) &#123; &#125; key = null; &#125; &#125; catch (OutOfMemoryError e) &#123; // we can run out of memory if we have too many threads // log the event and sleep for a minute and give // some thread(s) a chance to finish LOG.warn("Out of Memory in server select", e); closeCurrentConnection(key, e); connectionManager.closeIdle(true); try &#123; Thread.sleep(60000); &#125; catch (Exception ie) &#123;&#125; &#125; catch (Exception e) &#123; closeCurrentConnection(key, e); &#125; &#125; LOG.info("Stopping " + Thread.currentThread().getName()); synchronized (this) &#123; try &#123; acceptChannel.close(); selector.close(); &#125; catch (IOException e) &#123; &#125; selector= null; acceptChannel= null; // close all connections connectionManager.stopIdleScan(); connectionManager.closeAll(); &#125;&#125;void doAccept(SelectionKey key) throws InterruptedException, IOException, OutOfMemoryError &#123; ServerSocketChannel server = (ServerSocketChannel) key.channel(); SocketChannel channel; while ((channel = server.accept()) != null) &#123; channel.configureBlocking(false); channel.socket().setTcpNoDelay(tcpNoDelay); channel.socket().setKeepAlive(true); Reader reader = getReader(); //数组递增，获取下一个reader Connection c = connectionManager.register(channel); //构造Connection对象并放入connectionManager管理，如果connectionManager的最大连接数将无法建立连接 // If the connectionManager can't take it, close the connection. if (c == null) &#123; if (channel.isOpen()) &#123; IOUtils.cleanup(null, channel); &#125; connectionManager.droppedConnections.getAndIncrement(); continue; &#125; //将其添加到SelectionKey中，当发生错误时可以从SelectionKey中获得Connection将其关闭 key.attach(c); // so closeCurrentConnection can get the object reader.addConnection(c); &#125;&#125; listener线程等待注册的连接事件触发，调用doAccept函数，doAccept中获得连接的socket,构造一个Connection对象放入connectionManager的缓存中（内部有一个Set connections变量），这个Connection类是ipc.Server的内部类，和上述Client中的内部类不同。接着在递增的取出一个reader将connection放入reader内部的阻塞队列中。 123456public void addConnection(Connection conn) throws InterruptedException &#123; //pendingConnections为阻塞队列 BlockingQueue&lt;Connection&gt; pendingConnections.put(conn); //唤醒readSelector readSelector.wakeup();&#125; 接着我们来看Reader的run方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public void run() &#123; LOG.info("Starting " + Thread.currentThread().getName()); try &#123; doRunLoop(); &#125; finally &#123; try &#123; readSelector.close(); &#125; catch (IOException ioe) &#123; LOG.error("Error closing read selector in " + Thread.currentThread().getName(), ioe); &#125; &#125;&#125;private synchronized void doRunLoop() &#123; while (running) &#123; SelectionKey key = null; try &#123; // consume as many connections as currently queued to avoid // unbridled acceptance of connections that starves the select int size = pendingConnections.size(); for (int i=size; i&gt;0; i--) &#123; Connection conn = pendingConnections.take(); conn.channel.register(readSelector, SelectionKey.OP_READ, conn); &#125; readSelector.select(); //不用经过判断，如果没有channel触发事件，阻塞直到有一个注册的事件就绪为止或者调用weakup() Iterator&lt;SelectionKey&gt; iter = readSelector.selectedKeys().iterator(); while (iter.hasNext()) &#123; key = iter.next(); iter.remove(); try &#123; if (key.isReadable()) &#123; doRead(key); &#125; &#125; catch (CancelledKeyException cke) &#123; // something else closed the connection, ex. responder or // the listener doing an idle scan. ignore it and let them // clean up. LOG.info(Thread.currentThread().getName() + ": connection aborted from " + key.attachment()); &#125; key = null; &#125; &#125; catch (InterruptedException e) &#123; if (running) &#123; // unexpected -- log it LOG.info(Thread.currentThread().getName() + " unexpectedly interrupted", e); &#125; &#125; catch (IOException ex) &#123; LOG.error("Error in Reader", ex); &#125; catch (Throwable re) &#123; LOG.fatal("Bug in read selector!", re); ExitUtil.terminate(1, "Bug in read selector!"); &#125; &#125;&#125; 从阻塞队列中取出connection，在readSelector注册读事件，选择器响应，调用doRead方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227void doRead(SelectionKey key) throws InterruptedException &#123; int count = 0; Connection c = (Connection)key.attachment(); if (c == null) &#123; return; &#125; c.setLastContact(Time.now()); try &#123; count = c.readAndProcess(); &#125; catch (InterruptedException ieo) &#123; ... &#125;&#125; public int readAndProcess() throws WrappedRpcServerException, IOException, InterruptedException &#123; while (true) &#123; /* Read at most one RPC. If the header is not read completely yet * then iterate until we read first RPC or until there is no data left. */ int count = -1; //dataLengthBuffer为四个字节，可能是接受报头，也可能是数据的长度 if (dataLengthBuffer.remaining() &gt; 0) &#123; count = channelRead(channel, dataLengthBuffer); if (count &lt; 0 || dataLengthBuffer.remaining() &gt; 0) return count; &#125; /** * 如果connectionHeaderRead是true, * 表示已经读过连接头，那么不需要读取头部数据，dataLengthBuffer存储的数据的长度。 * 如果connectionHeaderRead是false, * 表示dataLengthBuffer读取的是hrpc * +----------------------------------+ * | "hrpc" 4 bytes | * +----------------------------------+ * | Version (1 byte) | * +----------------------------------+ * | Service Class (1 byte) | * +----------------------------------+ * | AuthProtocol (1 byte) | * +----------------------------------+ */ if (!connectionHeaderRead) &#123; //Every connection is expected to send the header. //connectionHeaderBuf主要存放后三个字节 if (connectionHeaderBuf == null) &#123; connectionHeaderBuf = ByteBuffer.allocate(3); &#125; count = channelRead(channel, connectionHeaderBuf); if (count &lt; 0 || connectionHeaderBuf.remaining() &gt; 0) &#123; return count; &#125; int version = connectionHeaderBuf.get(0); // TODO we should add handler for service class later this.setServiceClass(connectionHeaderBuf.get(1)); dataLengthBuffer.flip(); // Check if it looks like the user is hitting an IPC port // with an HTTP GET - this is a common error, so we can // send back a simple string indicating as much. if (HTTP_GET_BYTES.equals(dataLengthBuffer)) &#123; setupHttpRequestOnIpcPortResponse(); return -1; &#125; //RpcConstants.HEADER为“hrpc” if (!RpcConstants.HEADER.equals(dataLengthBuffer) || version != CURRENT_VERSION) &#123; //Warning is ok since this is not supposed to happen. LOG.warn("Incorrect header or version mismatch from " + hostAddress + ":" + remotePort + " got version " + version + " expected version " + CURRENT_VERSION); setupBadVersionResponse(version); return -1; &#125; // this may switch us into SIMPLE authProtocol = initializeAuthContext(connectionHeaderBuf.get(2)); dataLengthBuffer.clear(); connectionHeaderBuf = null; connectionHeaderRead = true; continue; &#125; //分配空间为dataLength的长度 if (data == null) &#123; dataLengthBuffer.flip(); dataLength = dataLengthBuffer.getInt(); checkDataLength(dataLength); data = ByteBuffer.allocate(dataLength); &#125; //读取数据 count = channelRead(channel, data); //第一次是读取PRC的context，connectionContextRead为false,读取完context后为true if (data.remaining() == 0) &#123; dataLengthBuffer.clear(); data.flip(); boolean isHeaderRead = connectionContextRead; //如果是context,则读取context,否则读取其数据 processOneRpc(data.array()); data = null; if (!isHeaderRead) &#123; continue; &#125; &#125; return count; &#125;&#125;/** * Process an RPC Request - handle connection setup and decoding of * request into a Call * @param buf - contains the RPC request header and the rpc request * @throws IOException - internal error that should not be returned to * client, typically failure to respond to client * @throws WrappedRpcServerException - an exception to be sent back to * the client that does not require verbose logging by the * Listener thread * @throws InterruptedException */ private void processOneRpc(byte[] buf) throws IOException, WrappedRpcServerException, InterruptedException &#123; int callId = -1; int retry = RpcConstants.INVALID_RETRY_COUNT; try &#123; final DataInputStream dis = new DataInputStream(new ByteArrayInputStream(buf)); final RpcRequestHeaderProto header = decodeProtobufFromStream(RpcRequestHeaderProto.newBuilder(), dis); callId = header.getCallId(); retry = header.getRetryCount(); if (LOG.isDebugEnabled()) &#123; LOG.debug(" got #" + callId); &#125; checkRpcHeaders(header); //这里通过callId来判数据是context还是实际数据，如果是context,callId为CONNECTION_CONTEXT_CALL_ID = -3，否则callId &gt; 0 if (callId &lt; 0) &#123; // callIds typically used during connection setup //connectionContextRead在该方法中赋值为true processRpcOutOfBandRequest(header, dis); &#125; else if (!connectionContextRead) &#123; throw new WrappedRpcServerException( RpcErrorCodeProto.FATAL_INVALID_RPC_HEADER, "Connection context not established"); &#125; else &#123; //读取数据 processRpcRequest(header, dis); &#125; &#125; catch (WrappedRpcServerException wrse) &#123; // inform client of error Throwable ioe = wrse.getCause(); final Call call = new Call(callId, retry, null, this); setupResponse(authFailedResponse, call, RpcStatusProto.FATAL, wrse.getRpcErrorCodeProto(), null, ioe.getClass().getName(), ioe.getMessage()); call.sendResponse(); throw wrse; &#125;&#125;/** * Process an RPC Request - the connection headers and context must * have been already read * @param header - RPC request header * @param dis - stream to request payload * @throws WrappedRpcServerException - due to fatal rpc layer issues such * as invalid header or deserialization error. In this case a RPC fatal * status response will later be sent back to client. * @throws InterruptedException */private void processRpcRequest(RpcRequestHeaderProto header, DataInputStream dis) throws WrappedRpcServerException, InterruptedException &#123; Class&lt;? extends Writable&gt; rpcRequestClass = getRpcRequestWrapper(header.getRpcKind()); if (rpcRequestClass == null) &#123; LOG.warn("Unknown rpc kind " + header.getRpcKind() + " from client " + getHostAddress()); final String err = "Unknown rpc kind in rpc header" + header.getRpcKind(); throw new WrappedRpcServerException( RpcErrorCodeProto.FATAL_INVALID_RPC_HEADER, err); &#125; Writable rpcRequest; try &#123; //Read the rpc request //利用反射实例化对象，并读取信息，得到调用方法和参数的数据。如果是WritableRpcEngine，对应的是Invocation rpcRequest = ReflectionUtils.newInstance(rpcRequestClass, conf); rpcRequest.readFields(dis); &#125; catch (Throwable t) &#123; // includes runtime exception from newInstance LOG.warn("Unable to read call parameters for client " + getHostAddress() + "on connection protocol " + this.protocolName + " for rpcKind " + header.getRpcKind(), t); String err = "IPC server unable to read call parameters: "+ t.getMessage(); throw new WrappedRpcServerException( RpcErrorCodeProto.FATAL_DESERIALIZING_REQUEST, err); &#125; Span traceSpan = null; if (header.hasTraceInfo()) &#123; // If the incoming RPC included tracing info, always continue the trace TraceInfo parentSpan = new TraceInfo(header.getTraceInfo().getTraceId(), header.getTraceInfo().getParentId()); traceSpan = Trace.startSpan(rpcRequest.toString(), parentSpan).detach(); &#125; //将信息封装成Call对象，包括callId,调用对象信息的等，和Client的Call相对应 Call call = new Call(header.getCallId(), header.getRetryCount(), rpcRequest, this, ProtoUtil.convert(header.getRpcKind()), header.getClientId().toByteArray(), traceSpan); if (callQueue.isClientBackoffEnabled()) &#123; // if RPC queue is full, we will ask the RPC client to back off by // throwing RetriableException. Whether RPC client will honor // RetriableException and retry depends on client ipc retry policy. // For example, FailoverOnNetworkExceptionRetry handles // RetriableException. queueRequestOrAskClientToBackOff(call); &#125; else &#123; callQueue.put(call); // queue the call; maybe blocked here &#125; incRpcCount(); // Increment the rpc count&#125; 内部调用了Connection.readAndProcess方法，dataLengthBuffer可能读取到连接头，如果是连接头则dataLengthBuffer里的内容是“hrpc”,否则dataLengthBuffer读取的是数据的长度，这里有分context和实际的数据，这个都由processOneRpc处理，这里通过callId是否小于0来判断是否是context（context的callId为-3），如果是context，则会将connectionContextRead设置true，最后通过processRpcRequest方法读取实际数据。通过反射机制创建具体的Writable子类，通过ReadFile的发序列化得到内容，最后将CallId，Wriable等封装进Call中（和Client的Call相对应），放入callQueue这个队列值，而callQueue中的Call的处理是交给Handler处理。我们来看Handler的run方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384private class Handler extends Thread &#123; public Handler(int instanceNumber) &#123; this.setDaemon(true); this.setName("IPC Server handler "+ instanceNumber + " on " + port); &#125; @Override public void run() &#123; LOG.debug(Thread.currentThread().getName() + ": starting"); SERVER.set(Server.this); ByteArrayOutputStream buf = new ByteArrayOutputStream(INITIAL_RESP_BUF_SIZE); while (running) &#123; TraceScope traceScope = null; try &#123; //从阻塞队列中取出一个Call对象 final Call call = callQueue.take(); // pop the queue; maybe blocked here if (LOG.isDebugEnabled()) &#123; LOG.debug(Thread.currentThread().getName() + ": " + call + " for RpcKind " + call.rpcKind); &#125; if (!call.connection.channel.isOpen()) &#123; LOG.info(Thread.currentThread().getName() + ": skipped " + call); continue; &#125; String errorClass = null; String error = null; RpcStatusProto returnStatus = RpcStatusProto.SUCCESS; RpcErrorCodeProto detailedErr = null; Writable value = null; //放入ThreadLocal，以便获取当前处理的call等信息 CurCall.set(call); if (call.traceSpan != null) &#123; traceScope = Trace.continueSpan(call.traceSpan); &#125; try &#123; // Make the call as the user via Subject.doAs, thus associating // the call with the Subject //调用call调用对应的方法 if (call.connection.user == null) &#123; value = call(call.rpcKind, call.connection.protocolName, call.rpcRequest, call.timestamp); &#125; else &#123; value = call.connection.user.doAs (new PrivilegedExceptionAction&lt;Writable&gt;() &#123; @Override public Writable run() throws Exception &#123; // make the call return call(call.rpcKind, call.connection.protocolName, call.rpcRequest, call.timestamp); &#125; &#125; ); &#125; &#125; catch (Throwable e) &#123; ... &#125; CurCall.set(null); synchronized (call.connection.responseQueue) &#123; setupResponse(buf, call, returnStatus, detailedErr, value, errorClass, error); // Discard the large buf and reset it back to smaller size // to free up heap. if (buf.size() &gt; maxRespSize) &#123; LOG.warn("Large response size " + buf.size() + " for call " + call.toString()); buf = new ByteArrayOutputStream(INITIAL_RESP_BUF_SIZE); &#125; call.sendResponse(); &#125; &#125; catch (InterruptedException e) &#123; ... &#125; finally &#123; ... &#125; &#125; LOG.debug(Thread.currentThread().getName() + ": exiting"); &#125;&#125; 可以看到handler的run方法，从callQueue阻塞队列中取出Call对象，接着调用call方法来执行指定的方法，我们接着来看call方法。 123456789101112131415161718/** Called for each call. * call的接口方法 */public abstract Writable call(RPC.RpcKind rpcKind, String protocol, Writable param, long receiveTime) throws Exception;//具体实现@Overridepublic Writable call(RPC.RpcKind rpcKind, String protocol, Writable rpcRequest, long receiveTime) throws Exception &#123; return getRpcInvoker(rpcKind).call(this, protocol, rpcRequest, receiveTime);&#125;public static RpcInvoker getRpcInvoker(RPC.RpcKind rpcKind) &#123; RpcKindMapValue val = rpcKindMap.get(rpcKind); return (val == null) ? null : val.rpcInvoker; &#125; 可以看到实际到最好是调用看RpcInvoker的具体实现类的call方法，而该类是从rpcKindMap中通过rpcKind取出的，那么这个RpcInvoker的具体实现类是什么时候放进去的，具体是什么。追踪rpcKindMap使用的地方可以看到。 12345678910111213141516171819202122232425public class WritableRpcEngine implements RpcEngine &#123; /** * Register the rpcRequest deserializer for WritableRpcEngine */ private static synchronized void initialize() &#123; org.apache.hadoop.ipc.Server.registerProtocolEngine(RPC.RpcKind.RPC_WRITABLE, Invocation.class, new Server.WritableRpcInvoker()); isInitialized = true; &#125;&#125;public static void registerProtocolEngine(RPC.RpcKind rpcKind, Class&lt;? extends Writable&gt; rpcRequestWrapperClass, RpcInvoker rpcInvoker) &#123; RpcKindMapValue old = rpcKindMap.put(rpcKind, new RpcKindMapValue(rpcRequestWrapperClass, rpcInvoker)); if (old != null) &#123; rpcKindMap.put(rpcKind, old); throw new IllegalArgumentException("ReRegistration of rpcKind: " + rpcKind); &#125; LOG.debug("rpcKind=" + rpcKind + ", rpcRequestWrapperClass=" + rpcRequestWrapperClass + ", rpcInvoker=" + rpcInvoker);&#125; 可以看出在当初WritableRpcEngine类加载时就已经将对应的初始化的Server.WritableRpcInvoker类放入rpcKindMap中，所以如果是采用WritableRpcEngine类的，那现在从rpcKindMap取出的就是Server.WritableRpcInvoker类。具体看该类下的call方法如果通过反射技术调用过程得到具体的值。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120static class WritableRpcInvoker implements RpcInvoker &#123; @Override public Writable call(org.apache.hadoop.ipc.RPC.Server server, String protocolName, Writable rpcRequest, long receivedTime) throws IOException, RPC.VersionMismatch &#123; //得到当初客户端序列化的Invocation对象 Invocation call = (Invocation)rpcRequest; if (server.verbose) log("Call: " + call); // Verify writable rpc version if (call.getRpcVersion() != writableRpcVersion) &#123; // Client is using a different version of WritableRpc throw new RpcServerException( "WritableRpc version mismatch, client side version=" + call.getRpcVersion() + ", server side version=" + writableRpcVersion); &#125; long clientVersion = call.getProtocolVersion(); final String protoName; ProtoClassProtoImpl protocolImpl; if (call.declaringClassProtocolName.equals(VersionedProtocol.class.getName())) &#123; // VersionProtocol methods are often used by client to figure out // which version of protocol to use. // // Versioned protocol methods should go the protocolName protocol // rather than the declaring class of the method since the // the declaring class is VersionedProtocol which is not // registered directly. // Send the call to the highest protocol version VerProtocolImpl highest = server.getHighestSupportedProtocol( RPC.RpcKind.RPC_WRITABLE, protocolName); if (highest == null) &#123; throw new RpcServerException("Unknown protocol: " + protocolName); &#125; protocolImpl = highest.protocolTarget; &#125; else &#123; protoName = call.declaringClassProtocolName; // Find the right impl for the protocol based on client version. //根据协议名和客户端的版本号，RpcKind来找到具体实现类 ProtoNameVer pv = new ProtoNameVer(call.declaringClassProtocolName, clientVersion); protocolImpl = server.getProtocolImplMap(RPC.RpcKind.RPC_WRITABLE).get(pv); if (protocolImpl == null) &#123; // no match for Protocol AND Version VerProtocolImpl highest = server.getHighestSupportedProtocol(RPC.RpcKind.RPC_WRITABLE, protoName); if (highest == null) &#123; throw new RpcServerException("Unknown protocol: " + protoName); &#125; else &#123; // protocol supported but not the version that client wants throw new RPC.VersionMismatch(protoName, clientVersion, highest.version); &#125; &#125; &#125; // Invoke the protocol method long startTime = Time.now(); int qTime = (int) (startTime-receivedTime); Exception exception = null; try &#123; //根据方法名来找到方法，利用反射来调用该方法得到结果 Method method = protocolImpl.protocolClass.getMethod(call.getMethodName(), call.getParameterClasses()); method.setAccessible(true); server.rpcDetailedMetrics.init(protocolImpl.protocolClass); Object value = method.invoke(protocolImpl.protocolImpl, call.getParameters()); if (server.verbose) log("Return: "+value); //封装进ObjectWritable类中返回 return new ObjectWritable(method.getReturnType(), value); &#125; catch (InvocationTargetException e) &#123; Throwable target = e.getTargetException(); if (target instanceof IOException) &#123; exception = (IOException)target; throw (IOException)target; &#125; else &#123; IOException ioe = new IOException(target.toString()); ioe.setStackTrace(target.getStackTrace()); exception = ioe; throw ioe; &#125; &#125; catch (Throwable e) &#123; if (!(e instanceof IOException)) &#123; LOG.error("Unexpected throwable object ", e); &#125; IOException ioe = new IOException(e.toString()); ioe.setStackTrace(e.getStackTrace()); exception = ioe; throw ioe; &#125; finally &#123; int processingTime = (int) (Time.now() - startTime); if (LOG.isDebugEnabled()) &#123; String msg = "Served: " + call.getMethodName() + " queueTime= " + qTime + " procesingTime= " + processingTime; if (exception != null) &#123; msg += " exception= " + exception.getClass().getSimpleName(); &#125; LOG.debug(msg); &#125; String detailedMetricsName = (exception == null) ? call.getMethodName() : exception.getClass().getSimpleName(); server.rpcMetrics.addRpcQueueTime(qTime); server.rpcMetrics.addRpcProcessingTime(processingTime); server.rpcDetailedMetrics.addProcessingTime(detailedMetricsName, processingTime); if (server.isLogSlowRPC()) &#123; server.logSlowRpcCalls(call.getMethodName(), processingTime); &#125; &#125; &#125;&#125; WritableRpcInvoker的call方法中将rpcRequest转型为Invocation对象，取出其中的协议名和版本号，根据其从server.getProtocolImplMap中得到协议具体实现类对象，从而通过方法名利用反射调用相应的方法，返回结果封装进ObjectWritable中。至于是如何得到协议具体实现类对象的，可以从以下方法中看出。 12345678910 Map&lt;ProtoNameVer, ProtoClassProtoImpl&gt; getProtocolImplMap(RPC.RpcKind rpcKind) &#123; if (protocolImplMapArray.size() == 0) &#123;// initialize for all rpc kinds for (int i=0; i &lt;= RpcKind.MAX_INDEX; ++i) &#123; protocolImplMapArray.add( new HashMap&lt;ProtoNameVer, ProtoClassProtoImpl&gt;(10)); &#125; &#125; return protocolImplMapArray.get(rpcKind.ordinal()); &#125; 根据rpcKind从protocolImplMapArray取出Map&lt;ProtoNameVer, ProtoClassProtoImpl&gt;对象，再根据ProtoNameVer取出具体实例对象。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public Server(Class&lt;?&gt; protocolClass, Object protocolImpl, Configuration conf, String bindAddress, int port, int numHandlers, int numReaders, int queueSizePerHandler, boolean verbose, SecretManager&lt;? extends TokenIdentifier&gt; secretManager, String portRangeConfig) throws IOException &#123; super(bindAddress, port, null, numHandlers, numReaders, queueSizePerHandler, conf, classNameBase(protocolImpl.getClass().getName()), secretManager, portRangeConfig); this.verbose = verbose; Class&lt;?&gt;[] protocols; if (protocolClass == null) &#123; // derive protocol from impl /* * In order to remain compatible with the old usage where a single * target protocolImpl is suppled for all protocol interfaces, and * the protocolImpl is derived from the protocolClass(es) * we register all interfaces extended by the protocolImpl */ protocols = RPC.getProtocolInterfaces(protocolImpl.getClass()); &#125; else &#123; if (!protocolClass.isAssignableFrom(protocolImpl.getClass())) &#123; throw new IOException("protocolClass "+ protocolClass + " is not implemented by protocolImpl which is of class " + protocolImpl.getClass()); &#125; // register protocol class and its super interfaces //将protocolClass和protocolImpl放入map中 registerProtocolAndImpl(RPC.RpcKind.RPC_WRITABLE, protocolClass, protocolImpl); //得到protocolClass的所有接口 protocols = RPC.getProtocolInterfaces(protocolClass); &#125; //将protocolClass的所有接口和protocolImpl放入map中 for (Class&lt;?&gt; p : protocols) &#123; if (!p.equals(VersionedProtocol.class)) &#123; // registerProtocolAndImpl(RPC.RpcKind.RPC_WRITABLE, p, protocolImpl); &#125; &#125;&#125;void registerProtocolAndImpl(RpcKind rpcKind, Class&lt;?&gt; protocolClass, Object protocolImpl) &#123; String protocolName = RPC.getProtocolName(protocolClass); long version; try &#123; version = RPC.getProtocolVersion(protocolClass); &#125; catch (Exception ex) &#123; LOG.warn("Protocol " + protocolClass + " NOT registered as cannot get protocol version "); return; &#125; //放入map中 getProtocolImplMap(rpcKind).put(new ProtoNameVer(protocolName, version), new ProtoClassProtoImpl(protocolClass, protocolImpl)); LOG.debug("RpcKind = " + rpcKind + " Protocol Name = " + protocolName + " version=" + version + " ProtocolImpl=" + protocolImpl.getClass().getName() + " protocolClass=" + protocolClass.getName()); &#125; 可以从上面看出，在初始化Server对象时，就已经将协议具体类和其所有接口类放入一个Map中，而这个map根据rpcKind放在了列表的rpcKind位置处。 现在回到Handler的run方法中，在调用call方法获得结果值后，调用setupResponse和call.sendResponse()方法，我们来具体看看这两个方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273/*** Setup response for the IPC Call.* * @param responseBuf buffer to serialize the response into* @param call &#123;@link Call&#125; to which we are setting up the response* @param status of the IPC call* @param rv return value for the IPC Call, if the call was successful* @param errorClass error class, if the the call failed* @param error error message, if the call failed* @throws IOException*/private static void setupResponse(ByteArrayOutputStream responseBuf, Call call, RpcStatusProto status, RpcErrorCodeProto erCode, Writable rv, String errorClass, String error) throws IOException &#123; responseBuf.reset(); DataOutputStream out = new DataOutputStream(responseBuf); //构造响应数据头 RpcResponseHeaderProto.Builder headerBuilder = RpcResponseHeaderProto.newBuilder(); headerBuilder.setClientId(ByteString.copyFrom(call.clientId)); headerBuilder.setCallId(call.callId); headerBuilder.setRetryCount(call.retryCount); headerBuilder.setStatus(status); headerBuilder.setServerIpcVersionNum(CURRENT_VERSION); if (status == RpcStatusProto.SUCCESS) &#123; RpcResponseHeaderProto header = headerBuilder.build(); final int headerLen = header.getSerializedSize(); int fullLength = CodedOutputStream.computeRawVarint32Size(headerLen) + headerLen; try &#123; if (rv instanceof ProtobufRpcEngine.RpcWrapper) &#123; ProtobufRpcEngine.RpcWrapper resWrapper = (ProtobufRpcEngine.RpcWrapper) rv; fullLength += resWrapper.getLength(); out.writeInt(fullLength); header.writeDelimitedTo(out); rv.write(out); &#125; else &#123; // Have to serialize to buffer to get len //写入数据长度，数据头，数据内容（序列化响应返回的内容） final DataOutputBuffer buf = new DataOutputBuffer(); rv.write(buf); byte[] data = buf.getData(); fullLength += buf.getLength(); out.writeInt(fullLength); header.writeDelimitedTo(out); out.write(data, 0, buf.getLength()); &#125; &#125; catch (Throwable t) &#123; LOG.warn("Error serializing call response for call " + call, t); // Call back to same function - this is OK since the // buffer is reset at the top, and since status is changed // to ERROR it won't infinite loop. setupResponse(responseBuf, call, RpcStatusProto.ERROR, RpcErrorCodeProto.ERROR_SERIALIZING_RESPONSE, null, t.getClass().getName(), StringUtils.stringifyException(t)); return; &#125; &#125; else &#123; // Rpc Failure headerBuilder.setExceptionClassName(errorClass); headerBuilder.setErrorMsg(error); headerBuilder.setErrorDetail(erCode); RpcResponseHeaderProto header = headerBuilder.build(); int headerLen = header.getSerializedSize(); final int fullLength = CodedOutputStream.computeRawVarint32Size(headerLen) + headerLen; out.writeInt(fullLength); header.writeDelimitedTo(out); &#125; //将其设置在Call对象中 call.setResponse(ByteBuffer.wrap(responseBuf.toByteArray()));&#125; setupResponse中主要是序列化响应的对象，并将其放入Call对象的rpcResponse中。接着就需要将Call传递给Responder来处理了。可以从Call.sendResponse()看到。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131//Call.sendResponse()@InterfaceStability.Unstable@InterfaceAudience.LimitedPrivate(&#123;"HDFS"&#125;)public void sendResponse() throws IOException &#123; int count = responseWaitCount.decrementAndGet(); assert count &gt;= 0 : "response has already been sent"; if (count == 0) &#123; connection.sendResponse(this); &#125;&#125;//Connection.sendResponse(Call call)private void sendResponse(Call call) throws IOException &#123; responder.doRespond(call);&#125;//// Enqueue a response from the application.//void doRespond(Call call) throws IOException &#123; synchronized (call.connection.responseQueue) &#123; // must only wrap before adding to the responseQueue to prevent // postponed responses from being encrypted and sent out of order. if (call.connection.useWrap) &#123; ByteArrayOutputStream response = new ByteArrayOutputStream(); wrapWithSasl(response, call); call.setResponse(ByteBuffer.wrap(response.toByteArray())); &#125; //放入responseQueue中 call.connection.responseQueue.addLast(call); if (call.connection.responseQueue.size() == 1) &#123; processResponse(call.connection.responseQueue, true); &#125; &#125;&#125;// Processes one response. Returns true if there are no more pending// data for this channel.//private boolean processResponse(LinkedList&lt;Call&gt; responseQueue, boolean inHandler) throws IOException &#123; boolean error = true; boolean done = false; // there is more data for this channel. int numElements = 0; Call call = null; try &#123; synchronized (responseQueue) &#123; // // If there are no items for this channel, then we are done // numElements = responseQueue.size(); if (numElements == 0) &#123; error = false; return true; // no more data for this channel. &#125; // // Extract the first call // 从列表中取出第一个元素 // call = responseQueue.removeFirst(); SocketChannel channel = call.connection.channel; if (LOG.isDebugEnabled()) &#123; LOG.debug(Thread.currentThread().getName() + ": responding to " + call); &#125; // // Send as much data as we can in the non-blocking fashion // 尝试一次性发送结果 // int numBytes = channelWrite(channel, call.rpcResponse); if (numBytes &lt; 0) &#123; return true; &#125; //如果没有余留，则表示发送成功 if (!call.rpcResponse.hasRemaining()) &#123; //Clear out the response buffer so it can be collected call.rpcResponse = null; call.connection.decRpcCount(); if (numElements == 1) &#123; // last call fully processes. done = true; // no more data for this channel. &#125; else &#123; done = false; // more calls pending to be sent. &#125; if (LOG.isDebugEnabled()) &#123; LOG.debug(Thread.currentThread().getName() + ": responding to " + call + " Wrote " + numBytes + " bytes."); &#125; &#125; else &#123; // // If we were unable to write the entire response out, then // insert in Selector queue. // 否则需要放入列表中，向responser的writeSelector注册写事件 // call.connection.responseQueue.addFirst(call); if (inHandler) &#123; // set the serve time when the response has to be sent later call.timestamp = Time.now(); incPending(); try &#123; // Wakeup the thread blocked on select, only then can the call // to channel.register() complete. writeSelector.wakeup(); //向选择器注册 channel.register(writeSelector, SelectionKey.OP_WRITE, call); &#125; catch (ClosedChannelException e) &#123; //Its ok. channel might be closed else where. done = true; &#125; finally &#123; decPending(); &#125; &#125; if (LOG.isDebugEnabled()) &#123; LOG.debug(Thread.currentThread().getName() + ": responding to " + call + " Wrote partial " + numBytes + " bytes."); &#125; &#125; error = false; // everything went off well &#125; &#125; finally &#123; if (error &amp;&amp; call != null) &#123; LOG.warn(Thread.currentThread().getName()+", call " + call + ": output error"); done = true; // error. no more data for this channel. closeConnection(call.connection); &#125; &#125; return done;&#125; 可以看到，最后放到了responseQueue中，responseQueue是一个列表，不是一个阻塞对列，每个Call封装了从客户端反序列化的对象信息，发送回客户端的数据还有Connection(每一个客户端和服务端维持一个Connection，因此call.connection.responseQueue代表着连接着同个客户端的响应消息发送队列，发送到同个客户端的call存放在同一个responseQueue中)。当responseQueue的长度为1时会调用processResponse，但如果存在一些特殊情况（返回的结果数量太大或者网络缓慢），没能一次性将结果发送，则会向Responser的selector注册写事件，由Responser将响应结果采用异步的方式继续发送未发送完的数据。来看Responser的run方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117@Overridepublic void run() &#123; LOG.info(Thread.currentThread().getName() + ": starting"); SERVER.set(Server.this); try &#123; doRunLoop(); &#125; finally &#123; LOG.info("Stopping " + Thread.currentThread().getName()); try &#123; writeSelector.close(); &#125; catch (IOException ioe) &#123; LOG.error("Couldn't close write selector in " + Thread.currentThread().getName(), ioe); &#125; &#125;&#125;private void doRunLoop() &#123; long lastPurgeTime = 0; // last check for old calls. while (running) &#123; try &#123; waitPending(); // If a channel is being registered, wait. writeSelector.select(PURGE_INTERVAL); Iterator&lt;SelectionKey&gt; iter = writeSelector.selectedKeys().iterator(); while (iter.hasNext()) &#123; SelectionKey key = iter.next(); iter.remove(); try &#123; if (key.isWritable()) &#123; doAsyncWrite(key); &#125; &#125; catch (CancelledKeyException cke) &#123; // something else closed the connection, ex. reader or the // listener doing an idle scan. ignore it and let them clean // up Call call = (Call)key.attachment(); if (call != null) &#123; LOG.info(Thread.currentThread().getName() + ": connection aborted from " + call.connection); &#125; &#125; catch (IOException e) &#123; LOG.info(Thread.currentThread().getName() + ": doAsyncWrite threw exception " + e); &#125; &#125; //等待时间设置，如果消息超过该时间还没有发送成功，则会执行后面的代码，关闭管道 long now = Time.now(); if (now &lt; lastPurgeTime + PURGE_INTERVAL) &#123; continue; &#125; lastPurgeTime = now; // // If there were some calls that have not been sent out for a // long time, discard them. // if(LOG.isDebugEnabled()) &#123; LOG.debug("Checking for old call responses."); &#125; ArrayList&lt;Call&gt; calls; // get the list of channels from list of keys. // 搜集超过时间还未发送的call synchronized (writeSelector.keys()) &#123; calls = new ArrayList&lt;Call&gt;(writeSelector.keys().size()); iter = writeSelector.keys().iterator(); while (iter.hasNext()) &#123; SelectionKey key = iter.next(); Call call = (Call)key.attachment(); if (call != null &amp;&amp; key.channel() == call.connection.channel) &#123; calls.add(call); &#125; &#125; &#125; //逐个关闭 for(Call call : calls) &#123; doPurge(call, now); &#125; &#125; catch (OutOfMemoryError e) &#123; // // we can run out of memory if we have too many threads // log the event and sleep for a minute and give // some thread(s) a chance to finish // LOG.warn("Out of Memory in server select", e); try &#123; Thread.sleep(60000); &#125; catch (Exception ie) &#123;&#125; &#125; catch (Exception e) &#123; LOG.warn("Exception in Responder", e); &#125; &#125;&#125;private void doAsyncWrite(SelectionKey key) throws IOException &#123; Call call = (Call)key.attachment(); if (call == null) &#123; return; &#125; if (key.channel() != call.connection.channel) &#123; throw new IOException("doAsyncWrite: bad channel"); &#125; synchronized(call.connection.responseQueue) &#123; if (processResponse(call.connection.responseQueue, false)) &#123; try &#123; key.interestOps(0); &#125; catch (CancelledKeyException e) &#123; /* The Listener/reader might have closed the socket. * We don't explicitly cancel the key, so not sure if this will * ever fire. * This warning could be removed. */ LOG.warn("Exception while changing ops : " + e); &#125; &#125; &#125;&#125; Responser异步继续发送在选择器中注册的写事件中的响应消息（还是调用），并设定超时时间，超过时间还未发送则对其进行关闭。 总体流程客户端客户端实际时使用了动态代理在在Invoker方法中发送了远程过程调用的请求到服务端，并等待接受结果。 服务端服务端采用reactor基于事件驱动的设计模式，利用JDK自带的socket通信机制和线程池完成。 参考http://bigdatadecode.club/Hadoop%20RPC%20%E8%A7%A3%E6%9E%90.html 《Hadoop技术内幕：深入解析YARN架构设计与实现原理》,图片也来自此。]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>RPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字符串编辑距离]]></title>
    <url>%2F%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%BC%96%E8%BE%91%E8%B7%9D%E7%A6%BB.html</url>
    <content type="text"><![CDATA[编辑距离（Edit Distance），这里指的是Levenshtein距离，也就是字符串S1通过插入、修改、删除三种操作最少能变换成字符串S2的次数。接下来介绍利用动态规划来求解字符串的编辑距离。 定义：$s_1$和$s_2$表示两字符串，$dist(i, j)$表示字符串$s_1$的前$i$个字符串和$s_2$的前$j$个字符串的编辑距离，$s_1(i)$和$s_2(j)$分别表示$s1$的第$i$个字符和$s2$的第$j$字符。 若$s_1(i) = s_2(j)$,则$dist(i, j)$就等于$s_1$的前$i-1$个字符串和$s_2$的前$j-1$个字符串的编辑距离即 $dist(i, j) = dist(i-1,j-1) $ 若$s_1(i) \neq s_2(j)$,则为了使$s_1(i) = s_2(j)$,可以通过在$s_1$的第$i$个字符处插入$s_2$的第$j$个字符，或替换$s_1$的第$i$个字符为$s_2$的第$j$个字符,或删除$s_1(s_2)$的第$i(j)$个字符(即使删除之后还是会出现不同),但是上述都是在进行了一次字符的操作之后,将转化为字问题求解，如上述的替换使$s_1(i) = s_2(j)$，则 $dist(i, j) = dist(i-1,j-1) + 1$ ，插入和删除使 $dist(i, j) = dist(i-1,j) +1$或者 $dist(i, j) = dist(i,j-1) +1$ 。 基于上述的情况可以得出递推公式：$$dist(i,j) = \begin{equation}\left\{ \begin{array}{lr} i, &amp; j = 0 \\ j, &amp; i = 0 \\ dist(i-1,j-1), &amp; s_1(i) = s_2(j) \\ min(d(i-1,j), d(i,j-1),d(i-1,j-1)), &amp; s_1(i) \neq s_2(j) \\ \end{array}\right.\end{equation}$$例如：$s_1 = “abcd”$,$s_2 = “abfce”$,则利用动态规划求解的矩阵为 a b f c e 0 1 2 3 4 5 a 1 0 1 2 3 4 b 2 1 0 1 2 3 c 3 2 1 1 1 2 d 4 3 2 2 2 2 代码实现1234567891011121314151617181920212223242526272829public static int levenshtein(String s1, String s2)&#123; if(s1 == null)&#123; return s2 == null? 0:s2.length(); &#125; if(s2 == null)&#123; return s1 == null? 0:s1.length(); &#125; int n = s1.length(); int m = s2.length(); int[][] matrix = new int[n+1][m+1]; for(int i = 0;i &lt;= n;i++)&#123; matrix[i][0] = i; &#125; for(int j = 0;j &lt;= m;j++)&#123; matrix[0][j] = j; &#125; for(int i = 1;i &lt;= n;i++)&#123; for(int j = 1;j &lt;= m;j++)&#123; if(s1.charAt(i-1) == s2.charAt(j-1))&#123; matrix[i][j] = matrix[i-1][j-1]; &#125;else &#123; matrix[i][j] = Math.min(Math.min(matrix[i-1][j], matrix[i][j-1]), matrix[i-1][j-1]) + 1; &#125; &#125; &#125; return matrix[n][m];&#125; 上述的方法其中有一个不足之处是当两个字符串太长时，则对应申请的数组占用的空间也变大。而上述的算法中，在更新$dist(i,j)$的过程中只用到了$dist(i-1,j)$、$dist(i,j-1)$、$dist(i-1,j-1)$这三个数，因此我们可以只存储更新的上一行的数据，这样就可以得到$dist(i-1,j)$，$dist(i-1,j-1)$这两个数，而$d(i,0) = i$,可以在此基础上根据上一行的$d(i-1,0)$和$d(i-1,1)$推出$d(i-1,1)$,在结合上一行的$d(i-1,1)$和$d(i-1,2)$推出$d(i-1,2)$…以此类推得到第$i$行的数据。接下来是改进后的代码实现 1234567891011121314151617181920212223242526public static int levenshteinImprove(String s1, String s2)&#123; if(s1 == null) return s2 == null? 0:s2.length(); if(s2 == null) return s1 == null? 0:s1.length(); int n = s1.length(),m = s2.length(); int[] matrix = new int[m+1]; for(int i = 0;i &lt;= m;i++)&#123; matrix[i] = i; &#125; for(int i = 1;i &lt;= n;i++)&#123; int pre = matrix[0]; matrix[0] = i; for(int j = 1;j &lt;= m;j++)&#123; int tmp = matrix[j]; if(s1.charAt(i-1) == s2.charAt(j-1))&#123; matrix[j] = pre; &#125;else &#123; matrix[j] = Math.min(Math.min(pre, matrix[j-1]), matrix[j]) + 1; &#125; pre = tmp; &#125; &#125; return matrix[m];&#125; 上述代码还可以改进一个小细节，当比较的字符串长短一个很长，一个很短时，我们可以比较其长短，取较短的字符串长度作为开辟的数组的长度。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>字符串</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
</search>
